{"meta":{"title":"黃爸爸狗園","subtitle":"本園只有sanitizer，沒有狗籠","description":"","author":"0rzgg","url":"https://GGORZ10227216.github.io","root":"/"},"pages":[{"title":"categories","date":"2022-08-09T10:01:14.000Z","updated":"2022-08-09T10:01:14.853Z","comments":true,"path":"categories/index.html","permalink":"https://ggorz10227216.github.io/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2022-08-08T18:24:49.000Z","updated":"2022-08-08T18:54:45.327Z","comments":true,"path":"about/index.html","permalink":"https://ggorz10227216.github.io/about/index.html","excerpt":"","text":"歡迎來到我的狗園! 這裡基本上是我放各種技術筆記的地方，目前有以下幾個系列 線性代數筆記 GBA模擬器開發 稀奇古怪的C++筆記 CPP weekly筆記 關於園長 你可以用黃志傑這個名字在facebook上找到我(你現在知道為何這個網站叫做黃爸爸狗園了)，雖然我並不叫這個名字 大部分的時間都在寫C++，最近都在研究C++20跟C++23的新東西 熱衷於研究各種中大型軟體系統，特別是模擬器 最近正在寫GBA的圖形邏輯模擬 最喜歡的遊戲是Silent hill 2"},{"title":"Resume","date":"2022-08-09T10:13:33.000Z","updated":"2022-08-10T16:10:02.790Z","comments":true,"path":"resume/index.html","permalink":"https://ggorz10227216.github.io/resume/index.html","excerpt":"","text":"Education National Central University, M.E. in Software Engineering, Sept. 2017 - Aug. 2019 Chung Yuan Christian University, B.S. in Computer Science and Information Engineering, Sep. 2013 - June. 2017 Experience ASUSTeK Computer Inc, Camera BSP Engineer., Taiwan, Taipei Sep.2020-Jun.2022 C++/C/Python/System programming/Performance tuning Developed a high-performance and low-power consumption gyro sampling system for zenfone9 image stabilization function. Optimized and maintained the zenfone9 kernel driver to ensure robustness. Developed a python-based, automated, and scriptable camera system stress testing tool for ASUS mobile devices. Maintained HDR10+ recording feature and SELinux module for ROG Phone and Zenfone Competition Mediatek Connectivity Innovation Challenge, Team Leader, Jun.2016 - Nov.2016 C++/Qt/Video streaming/Networking Honorable Mention Developed a low-cost and scalable Location-Based Service(LBS) solution. Developed a high-throughput TCP server/client architecture on Mediatek's Linkit 7688 embedded system. Designed a Qt based, high performance MJPEG video streaming program. Projects Ggboy! Developed a Gameboy emulator with cycle accurate LR35902 CPU emulation written in C++. Implemented Retro-style grayscale LCD display. Ported sound emulation function. GgAdv2 Developed a Gameboy Advance(GBA) emulator written in C++. Designed a full functional ARM7TDMI CPU emulation with a high performance O(1) instruction decoder. Designed a robust MMU emulation mechanism. Implemented peripheral emulation: DMA controller, timer, EEPROM on cartridge. Libggafx Developed an experimental GBA PPU emulation library with an ImGui frontend. Developed debugging tools to display the actual state of the PPU in-game. Designed as a concise interface to be easily embedded. OurScheme Developed a portable Scheme interpreter written in C++. Designed for correctness and robustness."},{"title":"實用連結","date":"2022-08-09T10:01:57.000Z","updated":"2022-08-10T17:01:13.857Z","comments":true,"path":"links/index.html","permalink":"https://ggorz10227216.github.io/links/index.html","excerpt":"","text":"本頁紀錄著一些我覺得很有用的網站，有興趣可以看看 Website, blog Hamilton Chang's Blog 我的一個主攻機器學習的朋友Hamiton的blog LearnCPP 個人相當推薦的C++學習資源，如果你對C++有興趣但不知從何下手，這會是一個不錯的選擇 Tools Compiler explorer 及時編譯C++的工具，可以快速的檢查出來的ASM是否符合預期 C++ Insights 線上展開C++語法糖以及template，用來分析複雜的C++ code很好用 Quick C++ Benchmark 用於對某一段程式碼做benchmark，有圖形化的介面可以分析效能差距 Youtube channel Cᐩᐩ Weekly With Jason Turner 每週會更新一集與C++特性相關的影片，是學習C++新特性or了解效能優化手段的好地方 Gamefromscratch 與遊戲設計較為相關，基本上圍繞著引擎還有工具相關的主題 偶爾會有一些asset store限時特價的消息 GamesWithGabe 有提及一些opengl跟glsl的內容，有一段時間沒更新了...... mCoding Python以及C++的相關內容，比較沒有特定方向 The Cherno 自幹遊戲引擎的大老，最近有一些Ray tracing的教學"}],"posts":[{"title":"C++在編譯期做出多重型別物件","slug":"compile-time-multi-type","date":"2022-08-09T09:18:03.000Z","updated":"2022-08-09T15:53:36.247Z","comments":true,"path":"compile-time-multi-type/","link":"","permalink":"https://ggorz10227216.github.io/compile-time-multi-type/","excerpt":"詳細的解說如何在編譯期做出一個具有多重型別的物件 神偷小吉從在S社工作的朋友K那裡幹來的程式碼","text":"詳細的解說如何在編譯期做出一個具有多重型別的物件 神偷小吉從在S社工作的朋友K那裡幹來的程式碼 Code在此，本文要來一步一步拆解這段code在幹嘛 123456789let i = 11;let b = false;let s = std::string{\"oh yes\"};let v = Multi{ [&amp;] { return i; }, [&amp;] { return b; }, [&amp;] { return s; },}; 首先我們可以看到本文主角Multi，一個神祕物件，初始化的時候吃了一個塞了三個不同return type的lambda的initialize list let的定義是#define let const auto 這個Multi是何方神聖? 12345678910111213template &lt;typename T&gt;struct To { template &lt;typename F&gt; To(F f) : f(std::move(f)) {} operator T() const { return f(); }; private: const std::function&lt;T()&gt; f;};template &lt;typename... Ts&gt;struct Multi : public To&lt;Ts&gt;... {}; Multi是一個struct，繼承了To 等等，這個如同財哥專業檳榔的繼承是怎麼回事? Keyword: variadic template 我們來看個範例 123456789101112131415161718192021struct A {};struct B { };struct C { };template &lt;typename... Ts&gt;struct Multi : public Ts... {};int main() { Multi&lt;A, B, C&gt; m ; return 0 ;} 基本上Ts...表示你可以給很多個type，他會幫你自動補上\",\"，like this 1234template&lt;&gt;struct Multi&lt;A, B, C&gt; : public A, public B, public C{}; 所以struct Multi : public To&lt;Ts&gt;...被轉換成了 struct Multi : public To&lt;Ts#1&gt;, To&lt;Ts#2&gt;, ...... 在這個例子中，Ts#n這些東西會變成什麼? struct Multi: public To&lt;lambda#A&gt;, To&lt;lambda#B&gt;嗎? 仔細看看To內部 12345template &lt;typename T&gt; struct To { // ... operator T() const { return f(); }; // ... T是一個return type，看起來絕對不會是lambda 中間似乎差了一個步驟......? User-defined deduction guides 我們仔細看一下有一段code 12template &lt;typename... Ts&gt;Multi(Ts...) -&gt; Multi&lt;std::invoke_result_t&lt;Ts&gt;...&gt;; 這到底是什麼東西? function prototype? 非也! 這個可是C++17的新特性Class template argument deduction (CTAD) 其中的一個概念:User-defined deduction guides 人為的去教compiler如何實例化你的type 所以上面那段code是什麼意思? 這段code的意思是如果今天出現了一個type Multi(Ts#1, Ts#2, ......)，我們會引導compiler把它變成 12345Multi&lt; std::invoke_result_t&lt;Ts#1&gt;, std::invoke_result_t&lt;Ts#2&gt;, ...&gt; invoke_result_t會在compile tile推導callable的return type 統整一下上面所述，整個轉換的流程為(對應我們範例程式碼的行數) const auto v = Multi { lambda, lambda, lambda } ; [30.] Multi(lambda, lambda, lambda) -&gt; Multi&lt;std::invoke_result_t, std::invoke_result_t, std::invoke_result_t&gt; [23.] Multi(lambda, lambda, lambda) -&gt; Multi&lt;int, bool, std::string&gt;[23.] Multi&lt;int, bool, std::string&gt; -&gt; struct Multi : public To&lt;int&gt;, To&lt;bool&gt;, To&lt;std::string&gt;[20.] 接下來情況就很明朗了，我們得到了一個有多重繼承的物件，最後就是看static_cast&lt;&gt;轉成誰，就會變成誰，Magic! 延伸閱讀 Class template argument deduction (CTAD) TJSW大師的好讀版 Parameter pack 比較多範例的版本 小結 我說完了，我說 完了","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://ggorz10227216.github.io/tags/C/"},{"name":"CTAD","slug":"CTAD","permalink":"https://ggorz10227216.github.io/tags/CTAD/"},{"name":"Variadic template","slug":"Variadic-template","permalink":"https://ggorz10227216.github.io/tags/Variadic-template/"}]},{"title":"Stop Using `constexpr` (And Use This Instead!)","slug":"constexpr-1","date":"2022-08-08T18:14:31.000Z","updated":"2022-08-09T09:35:09.908Z","comments":true,"path":"constexpr-1/","link":"","permalink":"https://ggorz10227216.github.io/constexpr-1/","excerpt":"這標題，真的很clickbait..... 這份筆記會針對constexpr與編譯期初始化的關聯做說明","text":"這標題，真的很clickbait..... 這份筆記會針對constexpr與編譯期初始化的關聯做說明 constexpr，一般來說會用在標示某個變數需要於編譯期(compile time)就完成初始化 12345678int get_val(int i) { return i*2;}int main() { int value = get_val(2) ; return value ;} 讓我們來看一看這個很簡單的範例出來的asm(x86_64 gcc -O0) 123456789101112131415161718get_val(int): push rbp mov rbp, rsp mov DWORD PTR [rbp-4], edi mov eax, DWORD PTR [rbp-4] add eax, eax pop rbp retmain: push rbp mov rbp, rsp sub rsp, 16 mov edi, 2 call get_val(int) mov DWORD PTR [rbp-4], eax mov eax, DWORD PTR [rbp-4] leave ret 基本上就是很老實地把數值算出來，但是如果啟用最佳化又會是什麼情況(x86_64 gcc -O3) 123456get_val(int): lea eax, [rdi+rdi] retmain: mov eax, 4 ret 數值直接在編譯的時候算出來，寫進code了 在影片裡頭提到constexpr到底會不會被編譯期初始化這一點永遠是不確定的，他會受到最佳化等級還有編譯器本身的影響 我自己的經驗是，多半都會，唯一你必須要確保你有加上constexpr 123456789101112131415#include &lt;array&gt;constexpr std::array&lt;int, 100&gt; get_val() {std::array&lt;int, 100&gt; result{}; for (int n = 0 ; n &lt; result.size() ; ++n) { result[ n ] = n ; } // for return result;}int main() { constexpr auto value = get_val()[45] ; return value ;} 此範例中的value，無論最佳化等級開多少，都會是編譯期求解 我們現在要來進一步探討constexpr variable的storage duration，我把影片中的例子人肉OCR出來了 here 看似沒什麼問題的程式碼，居然觸發了ASAN，到底是怎麼回事? 我們前面提到constexpr會讓變數在編譯期初始化但我們仔細看一下asm(in main()，為了簡潔我把ASAN關掉了) 1234lea rdi, [rbp - 4016]movabs rsi, offset .L__const.main.valuesmov edx, 4000call memcpy@PLT 驚人的事實是，array本身的確是constexpr，但是我們用了另外一個指標p去取他的值 然後還在scope裏頭，這下可好，p會指向我們從executable搬到stack上的array 你是不是發現了，即便宣告成constexpr，但她的storage duration依然不是static，這個constexpr的array居然是automatic(我指它的storage duration) 這個程式在-O3的時候，最佳化直接編譯求值了，所以不會被ASAN抓到 但是在-O0的時候我們有去做搬移的動作，然後就華麗的爆炸 所以結論是，我們原本所想的constexpr跟實際上的constexpr是有差異的 最接近我們所想的應該是static constexpr，我們把先前的範例改一改 在constexpr前加上static，你就會看到剛剛提到的那個搬移動作不見了 因為現在values的storage duration是static 我的老天鵝阿 延伸閱讀 Storage class specifiers constexpr specifier","categories":[],"tags":[{"name":"cpp_weekly_note","slug":"cpp-weekly-note","permalink":"https://ggorz10227216.github.io/tags/cpp-weekly-note/"},{"name":"c++","slug":"c","permalink":"https://ggorz10227216.github.io/tags/c/"}]},{"title":"Orthogonality","slug":"orthogonality","date":"2022-08-07T07:42:03.000Z","updated":"2022-08-08T02:10:34.023Z","comments":true,"path":"orthogonality/","link":"","permalink":"https://ggorz10227216.github.io/orthogonality/","excerpt":"有關於正交的一些筆記，放在這裡以備不時之需","text":"有關於正交的一些筆記，放在這裡以備不時之需 Orthogonal vector &amp; subspace Inner Product given two vector , , we can say the inner product of x, y is: Since is a scalar, that means The length of vector x = Orthogonal vecotrs x &amp; y are orthogonal iff recall Pythagoras theorem Orthogonal subspace Suppose &amp; are subspaces in &amp; are orthogonal if for every in , in Orthogonal complement Suppose is a subspace in The orthogonal complement of () is the set of all vecotrs orthogonal to Orthogonal subspaces of four subspace of , , 假設有一個向量，且，則 , ( in , in ) 對於所有在中的向量，在中只有唯一一個能夠滿足 我們可以假設還有另一個在中的向量滿足條件 也就是說，, 但同時 一個向量要同時存在於列空間與零空間只有一個可能 他自己是零向量 結論， Projection Projection onto a line find the vector on the line through , where is minimum Let's say 因為我們要找能夠產生最短長度的，上面那個長度方程式又剛好是二次方程式 最小值會在微分之後，斜率為零的位置 從上面的結論可以看出 p的長度只與跟夾角有關 整理一下式子 ()裡頭的是純量，但是[]裏頭的會是一個矩陣，我們給這個矩陣一個名字 的幾點性質 is another projection matrix, 假設現在，另有一向量，我們要找一向量，使得與距離最短 最短距離代表 is n by n, ，換言之對稱 if , let, But is also in ,因為y是A的線性組合 ， 講這麼多，我們只是要證明是full rank，可逆! projected vector projection matrix , , , ，只要滿足這兩個條件的矩陣就是投影矩陣 ，因為是的線性組合 Least-squares approximations A is (m is usually greater than n in pratice) has solutions if b in otherwise, the error vector We need to find s.t. is minimum is called the least squares solution We know that The normal equation: 如果無解 就代表b並不在中 但我們可以用投影(利用投影矩陣)的投過去，找到一個向量 也就是說 我們的誤差向量，重點是，因為我們希望要最小! 想像一下的正交互補空間是誰? ，所以我們的其實就在裡面 回想一下前面講的，所以 所以我們現在的等式變成 is our least squares solution Orthogonal matrices Orthonormal vectors The set of vecotrs is orthonormal if: Orthogonal matirces An orthogonal matrix is square and has orthonormal columns, such that: for example: Reflection matrix u到底是啥? 鏡射軸的法向量! 假設今天我們要對一個正交矩陣求解 The projected vecotr note only if Q is square The projection matrix is 檢查一下有沒有滿足投影矩陣的定義 P^T=P 有滿足 Gram-Schmidt process Suppose we have some vectors in ，and these vectors are linear independent we want to make these vectors orthonormal，is it possible? yes, by Gram-Schmidt process , is orthogonal and is our goal - orthonormal 先來看，我們鎖定作為，然後將投影到上，藉此來找出與垂直的, 我們可以整理一下計算的式子，因為跟都是純量，我們把它提出來 現在我們有兩個相互垂直的，接著處理 我們要把投影到上 因此我們的投影矩陣為: 所以 整理一下我們會得到通用式 用剛剛用過的那個抽出純量那招，我們可以得出一個結論 就是的線性組合 最後再把除上它的長度就會得到 經過Gram-Schmidt之後，我們有了就可以瘋狂內積求解了 還記得嗎? 我們剛剛有提到，是一個的線性組合 u跟q只有長度不一樣，換言之 這咚咚叫做QR factorization，也就是說 R is nn，and可逆 Least-squares solution 噫!又是你 前情提要，我們想解，但發現解不開，於是改找近似 error vector 與A裡面的所有向量垂直時，誤差最小 現在Gram-Schmidt超人幫你把A轉好了 ，謝謝你我D超人 R是上三角矩陣，可逆，所以我們消去，最後得到 ，因為R是上三角矩陣，所以超級好解開","categories":[],"tags":[{"name":"linear Algebra","slug":"linear-Algebra","permalink":"https://ggorz10227216.github.io/tags/linear-Algebra/"},{"name":"math","slug":"math","permalink":"https://ggorz10227216.github.io/tags/math/"}]},{"title":"Lambda vs std::function vs Function Pointer","slug":"cpp-callable-compare","date":"2022-08-06T13:44:14.000Z","updated":"2022-08-06T14:15:10.657Z","comments":true,"path":"cpp-callable-compare/","link":"","permalink":"https://ggorz10227216.github.io/cpp-callable-compare/","excerpt":"本文為C++ Weekly Ep 332的note","text":"本文為C++ Weekly Ep 332的note 這次我們要來看C++下三種傳遞function的方法: 1. function pointer 2. lambda 3. std::function function pointer 從原古C語言時代就存在的傳遞手段，基本上就是把function所在的address存起來，要呼叫的時候直接跳過去，我們來看個code: 12345678910// Type your code here, or load an example.int square(int num) { return num * num;}int main() { int (*func)(int) = square ; func(12) ; return 0 ;} // main() 上面的程式展示了最基本的function pointer使用方法，我們再進一步來看出來的asm長怎樣: 123456789101112131415161718192021square(int): # @square(int) push rbp mov rbp, rsp mov dword ptr [rbp - 4], edi mov eax, dword ptr [rbp - 4] imul eax, dword ptr [rbp - 4] pop rbp retmain: # @main push rbp mov rbp, rsp sub rsp, 16 mov dword ptr [rbp - 4], 0 movabs rax, offset square(int) mov qword ptr [rbp - 16], rax mov edi, 12 call qword ptr [rbp - 16] xor eax, eax add rsp, 16 pop rbp ret 上面的程式我為了方便說明原理，使用-O0編譯，我們不難看出function pointer的行為其實很簡單: 把square()的address放進rax 再放進[rbp - 16] call [rbp - 16] Cool, 基本上這就是最簡單的型態了，我們接著再來看看lambda會讓問題變複雜多少 lambda lambda是C++11引入的新功能，我們可以把它想像成一種匿名函數(Anonymous Function)，而且最酷的是lambda可以做到capture，不過我們先來看一個最基礎的lambda: 12345678int main() { auto func = [](int num) { return num*num; } ; func(12) ; return 0 ;} // main() 不過想要搞清楚到底發生了什麼，我們可以先從cpp insight的輸出開始看起: 12345678910111213141516171819202122232425int main() { class __lambda_2_17 { public: inline /*constexpr */ int operator()(int num) const { return num * num; } using retType_2_17 = int (*)(int); inline constexpr operator retType_2_17 () const noexcept { return __invoke; }; private: static inline /*constexpr */ int __invoke(int num) { return __lambda_2_17{}.operator()(num); } public: // /*constexpr */ __lambda_2_17() = default; }; __lambda_2_17 func = __lambda_2_17{}; func.operator()(12); return 0;} // main() 我們可以發現一件很酷的事情，lambda實際上是被轉換成一個class，我們去call一個lambda實際上是兩個步驟: 先宣告一個lambda物件func 去呼叫func的method \"operator()\" OK, 那實際上出來的asm會長怎樣? 123456789101112131415161718192021main: # @main push rbp mov rbp, rsp sub rsp, 16 mov dword ptr [rbp - 4], 0 lea rdi, [rbp - 8] mov esi, 12 call main::$_0::operator()(int) const xor eax, eax add rsp, 16 pop rbp retmain::$_0::operator()(int) const: # @\"main::$_0::operator()(int) const\" push rbp mov rbp, rsp mov qword ptr [rbp - 8], rdi mov dword ptr [rbp - 12], esi mov eax, dword ptr [rbp - 12] imul eax, dword ptr [rbp - 12] pop rbp ret 看起來與function pointer版本差不多，但這是因為我們沒有使用到capture的原因，那用了會怎樣? 我們來稍微修改一下lambda的內容 12345678910int main() { int num = 12 ; auto func = [&amp;]() { num += 1 ; return num*num; } ; func() ; return num ;} // main() 然後再看看出來的asm長怎樣: 1234567891011121314151617181920212223242526272829main: # @main push rbp mov rbp, rsp sub rsp, 16 mov dword ptr [rbp - 4], 0 mov dword ptr [rbp - 8], 12 lea rax, [rbp - 8] mov qword ptr [rbp - 16], rax lea rdi, [rbp - 16] call main::$_0::operator()() const mov eax, dword ptr [rbp - 8] add rsp, 16 pop rbp ret main::$_0::operator()() const: # @\"main::$_0::operator()() const\" push rbp mov rbp, rsp mov qword ptr [rbp - 8], rdi mov rcx, qword ptr [rbp - 8] mov rax, qword ptr [rcx] mov edx, dword ptr [rax] add edx, 1 mov dword ptr [rax], edx mov rax, qword ptr [rcx] mov eax, dword ptr [rax] mov rcx, qword ptr [rcx] imul eax, dword ptr [rcx] pop rbp ret 仔細看(8.)的mov，之所以會多出這一道指令是因為capture的實現方式是這樣的，我們來看cpp insight: 12345678910111213141516171819202122int main() {int num = 12; class __lambda_3_17 { public: inline /*constexpr */ int operator()() const { return num * num; } private: int &amp; num; // &lt;&lt; HERE! public: __lambda_3_17(int &amp; _num) : num{_num} // AND HERE! {} }; __lambda_3_17 func = __lambda_3_17{num}; func.operator()(); return 0;} // main() 原來capture是透過class member variable實現的，所以才會多出一個mov指令 另外，一個沒有capture的lambda是可以被隱式轉型成function pointer的，見以下範例: 1234567891011121314151617int main() { int (*fptr)(int) = nullptr ; auto func = [](int num) { num += 1 ; return num*num; } ; auto func_cap = [&amp;](int num) { num += 1 ; return num*num; } ; fptr = func ; // OK fptr = func_cap; // ERROR: cannot convert 'main()::&lt;lambda(int)&gt;' to 'int (*)(int)' in assignment return func(1) ;} // main() std::function std::function與上面提到的兩個東西有一個根本上的不同，std::function是一個function wrapper，實現原理可參見A Simplified std::function Implementation，這裡要提的是std::function可以包裝上面的兩個東西之外，任何具有operator()的牛鬼蛇神都可以包，為程式開發提供了極大的彈性 But, 如果我們沒有給std::function綁定一個callable就直接call他會怎樣? 123456789101112#include &lt;functional&gt;int main() { std::function&lt;int (int)&gt; func; auto numnum = [](int num) { num += 1 ; return num*num; } ; return func(1) ;} // main() 執行結果是直接拋出例外: terminate called after throwing an instance of 'std::bad_function_call' what(): bad_function_call 為了提供開發彈性，std::function背地裡做了很多......非常多的努力 確保你提供的callable的return type與std::function預期的相同 確保你提供的callable不會遇到生命週期的問題 根據實作的不同，有可能是把你的callable直接複製一份到heap上...... 可能比較厲害一點的實作會動用到SOO(small object optimization) 那到底用不用? 有需要就用，好比說...... 你在寫一個遊戲引擎，你需要用std::function來存你的script engine產生出的function(lua:叫我嗎?) 我要塞function進去container(vector, stack, std::array.....) 各種彈性 &gt; 效能的場景 延伸閱讀 First-class function What is the performance overhead of std::function? 結語","categories":[],"tags":[{"name":"cpp_weekly_note","slug":"cpp-weekly-note","permalink":"https://ggorz10227216.github.io/tags/cpp-weekly-note/"},{"name":"c++","slug":"c","permalink":"https://ggorz10227216.github.io/tags/c/"}]},{"title":"A Simplified std::function Implementation","slug":"simple-std-function","date":"2022-08-06T13:35:02.000Z","updated":"2022-08-06T14:12:42.380Z","comments":true,"path":"simple-std-function/","link":"","permalink":"https://ggorz10227216.github.io/simple-std-function/","excerpt":"本文為C++ Weekly Ep 333的note","text":"本文為C++ Weekly Ep 333的note 首先先來看code: - Compiler Explorer 這次的目標是要土炮一個精神上與std::function差不多的function class，就如同裏頭的std::function一樣，可以把任何callable都包起來 OK，讓我們一步一步來看這段code Primary template 首先我們必須先定義Primary template，後面會對function做partial template specialization 12template &lt;typename T&gt;class function; 也就是說一開始的typename T，在之後會被specialization成callable obj的type(好比說int (int,int)) class function 再來是我們的function物件 12345678910111213template &lt;typename Ret, typename ... Param&gt; class function&lt;Ret (Param...)&gt;{ public: template&lt;typename FunctionObject&gt; function(FunctionObject fo) : callable(std::make_unique&lt;callable_impl&lt;FunctionObject&gt;(std::move(fo))) {} Ret operator()(Param... param) {return callable-&gt;call(param...);} private: /*下面再講，這裡先不看*/ std::unique_ptr&lt;callable_interface&gt; callable ;}; 我們可以看到Ret (Param...)會被展開成int (int, int)，我們寫在main裏頭的: 12function&lt;int (int, int)&gt; func{f};// ^here typename FunctionObject會被換成你傳進去的callable object的type()，然後用你給的fo去初始化那個unique_ptr(為什麼要用unique_ptr等等會講) callable_interface &amp; callable_impl 然後整個class function最精華的地方來了，我們先定義一個pure virtual(又稱interface) callable_interface作為我們的base 123456789101112struct callable_interface { virtual Ret call(Param...) = 0; virtual ~callable_interface() = default;};template &lt;typename Callable&gt;struct callable_impl : callable_interface { callable_impl(Callable callable_) : callable(std::move(callable_)){} Ret call(Param... param) { return std::invoke(callable, param...);} Callable callable;}; 接下來讓callable_impl去繼承callable_interface，使其變成callable_interface的derived class，現在讓我們注意callable_impl的call()，讓我們來看一下cpp_insight的輸出 123456789101112131415161718192021222324252627282930313233343536373839404142template&lt;typename Callable&gt;struct callable_impl;/* First instantiated from: type_traits:1392 */#ifdef INSIGHTS_USE_TEMPLATEtemplate&lt;&gt;struct callable_impl&lt;int (*)(int, int)&gt; : public callable_interface{ inline callable_impl(int (*callable_)(int, int)) : callable_interface() , callable{std::move(callable_)} { } inline virtual int call(int __param0, int __param1) { return std::invoke(this-&gt;callable, __param0, __param1); } int (*callable)(int, int); // inline virtual constexpr ~callable_impl() noexcept = default;};#endif/* First instantiated from: type_traits:1392 */#ifdef INSIGHTS_USE_TEMPLATEtemplate&lt;&gt;struct callable_impl&lt;__lambda_39_36&gt; : public callable_interface{ inline callable_impl(__lambda_39_36 callable_) : callable_interface() , callable{__lambda_39_36(std::move(callable_))} { } inline virtual int call(int __param0, int __param1) { return std::invoke(this-&gt;callable, __param0, __param1); } __lambda_39_36 callable; // inline virtual constexpr ~callable_impl() noexcept = default;}; 我們可以發現: struct callable_impl&lt;int (*)(int, int)&gt; struct callable_impl&lt;__lambda_39_36&gt; 編譯器幫我們生出了一個raw function pointer，一個lambda的callable_impl，又因為call()是一個virtual，然後我們還使用了unique_ptr來記錄實際callable_impl的 ptr(所以這些物件都在heap上，吃的到virtual table) 這就代表無論我的FunctionObject最後是什麼，只要他能夠被call，callable_impl裏頭的call()一定就能夠透過std::invoke()產生出正確的呼叫程式碼 至此整個function object的原理就說明完了 結語 你各位要hold住阿","categories":[],"tags":[{"name":"cpp_weekly_note","slug":"cpp-weekly-note","permalink":"https://ggorz10227216.github.io/tags/cpp-weekly-note/"},{"name":"c++","slug":"c","permalink":"https://ggorz10227216.github.io/tags/c/"}]},{"title":"boost::asio + boost::fiber之上下文切換機制","slug":"autoecho","date":"2022-08-05T17:25:20.000Z","updated":"2022-08-08T04:13:55.309Z","comments":true,"path":"autoecho/","link":"","permalink":"https://ggorz10227216.github.io/autoecho/","excerpt":"最近剛好在研究boost::asio，在研究官方範例的時候發現與fiber連動的code，感覺有點玄妙，來寫篇筆記","text":"最近剛好在研究boost::asio，在研究官方範例的時候發現與fiber連動的code，感覺有點玄妙，來寫篇筆記 Autoecho autoecho.cpp 這個範例基本上就是在同一個process內開一個tcp server跟數個client，client會發送一個字串給server，然後server會把該字串echo回去 乍看之下蠻無聊的，但關鍵是這個程式只有一條thread在工作，所有的concurrency都是靠fiber在做 萬事起頭難，我們先來很快地審視過main()在幹嘛 1234567891011121314151617181920212223242526272829303132int main( int argc, char* argv[]) { try {//[asio_rr_setup std::shared_ptr&lt; boost::asio::io_context &gt; io_ctx = std::make_shared&lt; boost::asio::io_context &gt;(); boost::fibers::use_scheduling_algorithm&lt; boost::fibers::asio::round_robin &gt;( io_ctx);//] print( \"Thread \", thread_names.lookup(), \": started\");//[asio_rr_launch_fibers // server tcp::acceptor a( * io_ctx, tcp::endpoint( tcp::v4(), 9999) ); boost::fibers::fiber( server, io_ctx, std::ref( a) ).detach(); // client const unsigned iterations = 2; const unsigned clients = 3; boost::fibers::barrier b( clients); for ( unsigned i = 0; i &lt; clients; ++i) { boost::fibers::fiber( client, io_ctx, std::ref( a), std::ref( b), iterations).detach(); }//]//[asio_rr_run io_ctx-&gt;run();//] print( tag(), \": io_context returned\"); print( \"Thread \", thread_names.lookup(), \": stopping\"); std::cout &lt;&lt; \"done.\" &lt;&lt; std::endl; return EXIT_SUCCESS; } catch ( std::exception const&amp; e) { print(\"Exception: \", e.what(), \"\\n\"); } return EXIT_FAILURE;} 一開始先初始化io_context與設定fiber排成所用的algo為round robin，這沒有太大的問題 再來是把server fiber跟client fiber都建立好，detach()出來 最後是io_ctx-&gt;run()讓目前主fiber把執行權讓出來，排程器就會抓剛剛排入的fiber出來跑 async_something()的奧秘 我們可以從server()來切入問題 123456789101112131415161718192021void server( std::shared_ptr&lt; boost::asio::io_context &gt; const&amp; io_ctx, tcp::acceptor &amp; a) { print( tag(), \": echo-server started\"); try { for (;;) { socket_ptr socket( new tcp::socket( * io_ctx) ); boost::system::error_code ec; a.async_accept( * socket, boost::fibers::asio::yield[ec]); if ( ec) { throw boost::system::system_error( ec); //some other error } else { boost::fibers::fiber( session, socket).detach(); } } } catch ( std::exception const&amp; ex) { print( tag(), \": caught exception : \", ex.what()); } io_ctx-&gt;stop(); print( tag(), \": echo-server stopped\");} 我們的server fiber實體長這樣，但實際上只有做一個accept()動作而已 所以server()幹了啥? 使用我們在main裏頭準備好的acceptor a去等待client的連線，async_accept() 喔齁!? 來看一下async_accept()的signature，看看他是何方神聖 12345678template&lt; typename Protocol1, typename Executor1, typename AcceptToken = DEFAULT&gt;DEDUCED async_accept( basic_socket&lt; Protocol1, Executor1 &gt; &amp; peer, AcceptToken &amp;&amp; token = DEFAULT, typename constraint&lt; is_convertible&lt; Protocol, Protocol1 &gt;::value &gt;::type = 0); 所以async_accept()要一個socket跟一個AcceptToken socket沒問題，重點是那個AcceptToken到底是什麼咚咚? 簡單來說AcceptToken可以是一個callable，在未來的某一個時間點真的accept到東西的時候，接收來自kernel的error code來做後續處理 就是async_accept()的callback拉 但很顯然的，這個例子不是這樣 1a.async_accept(* socket, boost::fibers::asio::yield[ec]); 媽的貢丸，boost::fibers::asio::yield[ec]是啥玩意? 持續trace code，找到其定義 123456789101112131415161718namespace boost {namespace fibers {namespace asio { class yield_t { public: yield_t() = default; yield_t operator[]( boost::system::error_code &amp; ec) const { yield_t tmp; tmp.ec_ = &amp; ec; return tmp; } boost::system::error_code * ec_{ nullptr }; };thread_local yield_t yield{};}}} 好樣的，我們觸發了他的operator[]，具體只是把我們server()中的ec的addr綁到位於thread_local的yield上 然後作為AcceptToken傳遞給async_accept()，我的老天鵝，yield_t又沒有operator()，到底是怎麼樣變出callback的? 讓我們繼續往更深層跳...... 我們一路step in，會看到一個關鍵位置 1234567891011typedef typename boost::asio::async_result&lt; typename decay&lt;CompletionToken&gt;::type, Signature&gt;::completion_handler_type completion_handler_type; /*一些其他的code*/ explicit async_completion(CompletionToken&amp; token) : completion_handler(static_cast&lt;typename conditional&lt; is_same&lt;CompletionToken, completion_handler_type&gt;::value, completion_handler_type&amp;, CompletionToken&amp;&amp;&gt;::type&gt;(token)), result(completion_handler) { } 哇，酷喔，因為我們給的AcceptToken是yield_t，導致上面的completion_handler_type被推導成async_result&lt; boost::fibers::asio::yield_t, void(boost::system::error_code) &gt;::completion_handler_type 還真的有一個partial specialization長這樣 12345678910template&lt;&gt;class async_result&lt; boost::fibers::asio::yield_t, void(boost::system::error_code) &gt; : public boost::fibers::asio::detail::async_result_base { public: using return_type = void; using completion_handler_type = fibers::asio::detail::yield_handler&lt;void&gt;; explicit async_result( boost::fibers::asio::detail::yield_handler&lt; void &gt; &amp; h): boost::fibers::asio::detail::async_result_base{ h } {}}; 你，看到了嗎.....?那個潛伏在陰暗角落，蠢蠢欲動的completion_handler_type 講了那麼多，最後發現傳入yield_t之後，completion_handler最後會初始化成一個yield_handler 這個咚咚可就厲害了，它可是有operator()的!! 但不要忘記，他還有個base class，一樣也有一個operator() 先來看一下yield_handler的operator() 12345678void operator()(boost::system::error_code const&amp; ec, T t) { BOOST_ASSERT_MSG( value_, \"Must inject value ptr \" \"before caling yield_handler&lt;T&gt;::operator()()\"); * value_ = std::move( t); yield_handler_base::operator()(ec);} 我們可以看到value_(就是我們的socket)，會被assign t，這個t就是當async_accept()完成之後會得到的socket 接下來就會繼續call yield_handler_base的operator() 所以我們現在知道，AcceptToken給yield_t，最後async_accept()完事之後會呼叫的callback來自這裡 我們接著來看yield_handler_base的operator()做了啥? 12345678910111213141516171819202122232425262728293031class yield_handler_base { public: yield_handler_base( yield_t const&amp; y) : ctx_{ boost::fibers::context::active() }, yt_( y ) {} void operator()( boost::system::error_code const&amp; ec) { BOOST_ASSERT_MSG( ycomp_, \"Must inject yield_completion* \" \"before calling yield_handler_base::operator()()\"); BOOST_ASSERT_MSG( yt_.ec_, \"Must inject boost::system::error_code* \" \"before calling yield_handler_base::operator()()\"); yield_completion::lock_t lk{ ycomp_-&gt;mtx_ }; yield_completion::state_t state = ycomp_-&gt;state_; ycomp_-&gt;state_ = yield_completion::complete; * yt_.ec_ = ec; lk.unlock(); if ( yield_completion::waiting == state) { // wake the fiber fibers::context::active()-&gt;schedule( ctx_); } } boost::fibers::context * ctx_; yield_t yt_; yield_completion::ptr_t ycomp_{};}; 兩個重點 * yt_.ec_ = ec;會把真正的error code寫回我們給的yield_t yield_completion::waiting == state如果我們的server fiber在async_accept()之後沒有馬上就accept到連線(正常來說都是這樣)，那麼這個state就會是waiting，我們此時就會把server fiber的context排進排程裏頭，讓他盡快被跑起來 跑起來之後就會把已經accept的socket交遊session fiber去執行工作 但還有一個問題，我們在呼叫async_accept()之後，在我們正式accept到連線之前的這段時間內，執行權在誰手上 async_開頭的function都是non-blocking的，所以不會卡在原地 但看起來也不像是回到server fiber...... 我們可以在往下看，我們的async_accept()事實上背後接著一個async_initiate()，這個東西內部有一個玄機 12345678910111213141516171819template &lt;typename CompletionToken, BOOST_ASIO_COMPLETION_SIGNATURE Signature, typename Initiation, typename... Args&gt; inline typename enable_if&lt; !detail::async_result_has_initiate_memfn&lt;CompletionToken, Signature&gt;::value, BOOST_ASIO_INITFN_RESULT_TYPE(CompletionToken, Signature)&gt;::type async_initiate(BOOST_ASIO_MOVE_ARG(Initiation) initiation, BOOST_ASIO_NONDEDUCED_MOVE_ARG(CompletionToken) token, BOOST_ASIO_MOVE_ARG(Args)... args) { async_completion&lt;CompletionToken, Signature&gt; completion(token); BOOST_ASIO_MOVE_CAST(Initiation)(initiation)( BOOST_ASIO_MOVE_CAST(BOOST_ASIO_HANDLER_TYPE(CompletionToken, Signature))(completion.completion_handler), BOOST_ASIO_MOVE_CAST(Args)(args)...); return completion.result.get(); } 最後的那個completion.result.get()是關鍵，我們一個step進去看一看 123456789101112131415void get() { ycomp_-&gt;wait(); if ( ec_) { throw_exception( boost::system::system_error{ ec_ } ); }}/*再來直接看ycomp-&gt;wait()*/void wait() { lock_t lk{ mtx_ }; if ( complete != state_) { state_ = waiting; fibers::context::active()-&gt;suspend( lk); // !! }} 不看不知道，一看不得了，上面這段code說了啥? 假設我們呼叫get()的時候，ycomp的state不是complete(換言之，callback還沒有被跑過)，那基本上進去wait()就會觸發fibers::context::active()-&gt;suspend() 這個動作相當於是直接yield控制權，換言之，我們的async_accept()在呼叫後如果沒有馬上accept到連線的話，就會把控制權yield出來給其他fiber!! 一旦async_accept()讓出執行權後，在他完成之前，就會有其他的fiber被拉起來跑(client or session)，而當這兩個fiber各自也執行async action的時候，就會如同上面async_accept()一樣讓出執行權 如此我們就能只靠一條thread達到concurrency了 延伸閱讀 Then There’s Boost.Asio Boost.Asio overview Boost.fiber 愛麗絲與鮑伯 結論 想不到吧，Alice居然就是Bob!","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://ggorz10227216.github.io/tags/C/"},{"name":"networking","slug":"networking","permalink":"https://ggorz10227216.github.io/tags/networking/"},{"name":"Boost","slug":"Boost","permalink":"https://ggorz10227216.github.io/tags/Boost/"},{"name":"asynchronous_IO","slug":"asynchronous-IO","permalink":"https://ggorz10227216.github.io/tags/asynchronous-IO/"}]},{"title":"GBA圖形處理邏輯模擬(二) - Tile mode","slug":"Tile-mode","date":"2022-08-03T17:38:07.000Z","updated":"2022-08-03T17:54:44.088Z","comments":true,"path":"Tile-mode/","link":"","permalink":"https://ggorz10227216.github.io/Tile-mode/","excerpt":"cover 前文提到GBA的圖形繪製總共有兩種模式: Tile mode與Bitmap mode，這兩種繪圖模式雖然使用相同的記憶體區段但是工作原理大不相同，因此我們可以將其視為兩個獨立的邏輯分別開發 我們緊接著就要來探討GBA tile mode的基礎知識","text":"cover 前文提到GBA的圖形繪製總共有兩種模式: Tile mode與Bitmap mode，這兩種繪圖模式雖然使用相同的記憶體區段但是工作原理大不相同，因此我們可以將其視為兩個獨立的邏輯分別開發 我們緊接著就要來探討GBA tile mode的基礎知識 如何生成一幀畫面 背景與物件 先來看一個在Tile mode下繪製而成的遊戲畫面 Castlevania-Aria of sorrow, render by NO$GBA 畫面中所有看的到的東西基本上是由兩種東西疊合而成: 1. 背景(background, BG) 2. 物件(Object, OBJ) 他們之間的關係看起來會像是這樣: bg_and_sprite 你會注意到背景與物件各有四層圖層，我們可以將剛剛的遊戲畫面分層來看 BG_0 BG_1 BG_2 BG_3 OBJ(我疊合成一層了) Tile &amp; map 我們現在知道在Tile mode下，每一個畫面都是由背景跟物件所組成的了，那這些背景和物件又是如何被建構的呢? 要回答這個問題，我們必須從兩個方向來做分析: 用什麼東西組合 Tile mode下所有的東西基本上都是由Tile所組合而成的，我們這裡所說的tile，是一塊一塊由8*8個pixel所組成的圖形資料，類似這種(仔細看，這是骷髏騎士的劍柄) Tile的格式請參閱GBA圖形處理邏輯模擬 - Tile format 如何組合 另外一個需要釐清的問題是，我們該如何組合這些8*8的tile來產生我們想要的圖形，這就牽涉到我們現在是要繪製背景圖層還是物件，兩者的組合邏輯有些差異，詳細說明請參閱以下文章: GBA圖形處理邏輯模擬 - Background Map GBA圖形處理邏輯模擬 - Object Attribute Memory(OAM) Mode 0, Mode 1, Mode 2 Tile mode實質意義上指的是Mode 0, 1, 2這三個模式，因為這三種模式都使用tile建構畫面的基礎，因此統稱為tile mode 那這些mode有哪些特點呢，讓我們來仔細看一下這個表格: mode_table 根據表格，我們可以得知以下數點不同之處: 是否有支援Affine(Rotation &amp; Scaling)功能 詳細請參考GBA圖形處理邏輯模擬 - Affine background 最大可支援的Screen數量以及尺寸 詳細請參考GBA圖形處理邏輯模擬 - Background Map 最大可使用的Character(就是Tile)以及調色盤格式(palette) 詳細請參考GBA圖形處理邏輯模擬 - Tile format BG control register 前面有提到Tile mode下總共會有4層背景圖層，這四層圖層會受到當前的mode number影響，決定是否能夠被使用 layer_info text與rotation/scaling是? 如表格所示，BG0與BG1這兩個圖層僅支援Text mode 換言之就是沒有旋轉跟縮放的mode 而BG2與BG3則除了text mode之外，還可支援旋轉縮放 我會將rotation/scaling稱呼為affine 另外，這四層背景繪製時也會有一些可控的參數，描述如下，你可以依照下面給出的連結查閱他們的詳細資訊 bgcnt_info 對應四層圖層的register分別被mapping在(2 bytes each): BG0CNT(0x0400'0008) BG1CNT(0x0400'000A) BG2CNT(0x0400'000C) BG3CNT(0x0400'000E) 各欄位的詳細說明請參照: Priority Specification GBA圖形處理邏輯模擬 - Graphics effect(WIP) # blending Character Base Block GBA圖形處理邏輯模擬 - Tile format Mosaic GBA圖形處理邏輯模擬 - Graphics effect(WIP) #Mosaic Color Mode GBA圖形處理邏輯模擬 - Tile format Screen Base Block GBA圖形處理邏輯模擬 - Background Map Area Overflow Processing Flag 要注意這個flag對BG0與BG1無效 詳細請參考GBA圖形處理邏輯模擬 - Affine background Screen Size GBA圖形處理邏輯模擬 - Background Map","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"}]},{"title":"GBA圖形處理邏輯模擬 - Tile format","slug":"Tile-format","date":"2022-08-03T16:10:55.000Z","updated":"2022-08-03T16:14:58.355Z","comments":true,"path":"Tile-format/","link":"","permalink":"https://ggorz10227216.github.io/Tile-format/","excerpt":"cover 本文會專門針對GBA tile mode下所使用的tile format做詳細的說明","text":"cover 本文會專門針對GBA tile mode下所使用的tile format做詳細的說明 VRAM layout GBA的視訊記憶體VRAM總共有96KBytes，但是其中的佈局會根據當前的BG mode而有所改變，見下圖: 本系列文會以map data來稱呼任天堂官方手冊上的screen data，tile data稱呼character data 我們可以看到總共有四種不同的data: OBJ Character data 為存放組成obj所用的tile的記憶體位置，要注意的是tile mode下與bitmap mode下的OBJ tile area大小並不相同，這將會影響到最多能夠使用的tile數量 BG Screen data 描述一個背景圖層中所有tile的組成以及屬性，要注意此區域與BG tile共用，詳細規則見下方描述 BG Character data 存放組成BG圖層所用的tile的記憶體位置 Frame buffer bitmap mode下的繪製區域 VRAM layout under tile mode BG tile data以及BG map data在VRAM中的排列規則如下圖所述: tile_data_layout 我們可以看到除了OBJ tile data之外，BG的map data跟tile data是混在一起的，而每一個BG layer的tile data base address為 - 0x0600'0000 + BGXCNT中的Character base block欄位數值 0x4000 Tile data layout 讓我們使用一個8 8的tile來當作範例 tile_sample 這個tile的pixel在GBA中會有兩種可能的色彩表示方式: 16色模式 在這個模式下，1 byte可以表示2個pixel，也就是說每個pixel的palette color index範圍是種，而每個完整的tile為32 bytes 在此模式下可以透過修改Map data(或者是OAM)中的Color Palette field來實現調色盤切換，也就是各位十分熟悉的-2P色 256色模式 在此模式下，每一個pixel所佔的記憶體空間為1 byte，也就是說可以有 = 256種顏色，另外一個完整的tile為64 bytes 由於每一個pixel的color index都完全覆蓋住palette，因此不能夠調整palette number了 Palette memory 上面有提到tile data中存放的是color index，用於在調色盤(palette)中索引出正確的顏色，palette memory的特性如下: 位於0x0500'0000，共0x400(1024 bytes) 被分為兩部分，各512 bytes 前512 bytes為BG palette，bg tile data中的color index會對應到此 後512 bytes為OBJ palette, OBJ tile data的color index會對應到此 每一個顏色為2 bytes，故兩個palette都是512/2 = 256色，其色彩格式如下所述 Pixel format 眾所周知，如果你想要在電腦系統中顯示顏色，必定要利用一些格式來描述你最終顯示在螢幕上的每一個pixel的顏色，常見的格式有RGB、YUV、HSV等系統 而GBA所使用的色彩系統為RGB，讓我們從binary的角度來觀察每一個pixel的資料: pixel format 上圖很清楚地描述了GBA所使用的色彩格式，R、G、B是如何被儲存的，我們可以得出以下數點結論: 1. 每個顏色(我們叫他Color channel)的寬度為5bit，總共可以有種變化 2. 每個pixel為了記錄RGB，會消耗2 bytes的空間，並且最高位元是沒有作用的 3. 這種RGB各占5bit的格式有一個特殊的名字-BGR555 這裡一定要特別提，我沒有打錯!! 是BGR沒有錯 我們講RGB***指的是從MSB到LSB的排列方式為RGB，反之亦然 附上RGB565的示意圖以供參考 RGB565","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"}]},{"title":"GBA圖形處理邏輯模擬 - Background Map","slug":"Background-map","date":"2022-08-03T16:10:00.000Z","updated":"2022-08-05T18:03:37.190Z","comments":true,"path":"Background-map/","link":"","permalink":"https://ggorz10227216.github.io/Background-map/","excerpt":"cover GBA的VRAM中有數塊特殊的區域用來描述在一個BG中如何排列tile，我們將其稱呼為BG map memory，本文將會詳細說明其格式與特點","text":"cover GBA的VRAM中有數塊特殊的區域用來描述在一個BG中如何排列tile，我們將其稱呼為BG map memory，本文將會詳細說明其格式與特點 Map data format Map data內部紀錄了渲染一塊tile所需要知道的資訊，其格式根據BG為Text或者Affine會有所不同: Text BG 欄位功能描述如下: Character name 雖然叫做name，但實際上是一個offset，當你從BG_CNT上計算出tile block base之後，假設BG_CNT上標明這是一個4bpp tile，則此map data所對應的tile data的address為: base block addr + chara. name * 0x20(4bpp的一個完整tile size) 假若是8bpp，則tile data會位於 base block addr + chara. name * 0x40(8bpp的一個完整tile size) 有關tile data詳見GBA圖形處理邏輯模擬 - Tile format Affine BG 對，沒錯，真的就只有Character name，Affine BG的tile是強制256色的，考慮到Affine BG是利用仿射矩陣直接將screen pixel映射到map memory上，這樣的設計是最合理的 因為tile一定是0x40，所以tile data的位置算法就是8bpp算法 Horizontal flip flag 此tile在渲染時是否要左右顛倒，我這裡是直接將讀出來的tile data做inverse 考慮tile是4bpp的情況 12345678910111213if (xInverse) { // Swap the nibbles of each byte. buf = (buf &amp; 0x0F0F0F0F) &lt;&lt; 4 | (buf &amp; 0xF0F0F0F0) &gt;&gt; 4; // Swap the bytes of each byte pair. buf = (buf &amp; 0x00FF00FF) &lt;&lt; 8 | (buf &amp; 0xFF00FF00) &gt;&gt; 8; // Swap the byte pairs. buf = (buf &amp; 0x0000FFFF) &lt;&lt; 16 | (buf &amp; 0xFFFF0000) &gt;&gt; 16;} // if 8bpp會比較簡單 123456789if (xInverse) { // Swap the bytes of each byte pair. buf = (buf &amp; 0x00FF00FF) &lt;&lt; 8 | (buf &amp; 0xFF00FF00) &gt;&gt; 8; // Swap the byte pairs. buf = (buf &amp; 0x0000FFFF) &lt;&lt; 16 | (buf &amp; 0xFFFF0000) &gt;&gt; 16;} // if Vertical flip flag 此tile在渲染時是否要上下顛倒 Color palette 如果BG_CNT有聲明是4bpp，則最後tile在繪製時所參考的palette number就會是這個欄位所描述的 你可以把此欄位理解成row number，假設palette number是4，那tile就會變成全黑(因為tile 4所有16色都是黑色) Virtual screen Map memory基本上就是一塊由map data以二維排列而成的記憶體區塊，我們可以回顧一下這張表格: 其中我們可以注意到Character format BG screen下有一個size的欄位，裏頭描述幾種螢幕大小組合，但可以確定的是都與我們所知道的GBA螢幕大小240*160不同 這就是所謂的Virtual screen機制，我們可以把他想像成我們利用一個240*160的取景視窗，在一個很大的虛構區域內移動，接下來我們要來討論兩個重點: 虛構區域的大小 我們能夠移動的虛構區域大小是依靠BG_CNT中的Screen size控制的，其大小如下表所述: 圖表中明確提到了Text/Affine的狀態下，map data的尺寸與記憶體占用皆不同 如何移動可視範圍 我們在確認Virtual screen的大小後，下一步自然就是要把取景範圍移動到我們想要的地方，這一個步驟在Text BG與Affine BG下的操作方式並不相同: Text BG: 我們需要調整HOFS以及VOFS兩個register來移動取景範圍的左上角座標，如果這兩個暫存器的數值超過的virtual screen的尺寸的話，真正對應到的數值將會被 %screen size 不同的Screen size，移動時看起來會像是這樣 Affine BG:Affine模式下是直接依靠仿射矩陣來決定每一個螢幕上的pixel對應到的tile data，因此並不需要依靠HOFS以及VOFS，詳細請見GBA圖形處理邏輯模擬 - Affine background Address formula 最後附上一個Text BG計算某一個screen pixel，其所在的tile對應到那一個map data的計算公式: Physical screen X, Y = Sx, Sy Virtual Screen Width, Height = Vw, Vh Viewing area X = (Sx + HOFS) % Vw = S_vx, Viewing area Y = (Sy + VOFS) % Vh = S_vy Screen Base Block in BG_CNT = Sb map data address = 0x0600'0000 + (0x800 * Sb) + {((Vw / 8)*(S_vy / 8)) + (S_vx / 8)} * 2 每一個tile為8*8，所以S_v(x|y) / 8是為了把pixel XY轉換為tile XY 最後*2是因為Text BG每一個map data為2 bytes","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"}]},{"title":"GBA圖形處理邏輯模擬 - Affine background","slug":"Affine-background","date":"2022-08-03T16:08:15.000Z","updated":"2022-08-09T15:58:55.002Z","comments":true,"path":"Affine-background/","link":"","permalink":"https://ggorz10227216.github.io/Affine-background/","excerpt":"cover GBA除了能夠依照Map memory的排列，由左至右、由上到下的產生畫面外，還能夠使用矩陣運算，產生縮放&amp;旋轉過後的背景圖案，本文將會描述其原理，並且這部分的知識將與Affine object共通","text":"cover GBA除了能夠依照Map memory的排列，由左至右、由上到下的產生畫面外，還能夠使用矩陣運算，產生縮放&amp;旋轉過後的背景圖案，本文將會描述其原理，並且這部分的知識將與Affine object共通 仿射矩陣 根據維基百科的對仿射變換的定義: ::: success 仿射轉換（Affine transformation），又稱仿射映射，是指在幾何中，對一個向量空間進行一次線性轉換並接上一個平移，轉換為另一個向量空間。 ::: 言下之意，對於GBA的2D顯示來說，我們會需要一個矩陣來幫我們做這個轉換，這個矩陣會長得像是這樣，讓我們假設我們要逆時鐘旋轉然後X軸縮放倍，Y軸縮放倍，最後平移(x, y)，讓我們先來討論線性轉換的部分(旋轉與縮放) 這個矩陣其實就是由一個旋轉矩陣跟一個縮放矩陣組合而成 忘記怎麼計算矩陣了嗎? 請參考Matrix calculation rules 逆矩陣 酷，所以GBA的圖形硬體就是用上面的方式來實現旋轉縮放的囉? 很遺憾並不是，正確來說是完全相反 字面上意思的相反 我們剛剛所提及的方式，是將VRAM中的tile旋轉並縮放後，投射到螢幕上，但你仔細想想就會發現不太可行 我們可以思考一個問題，你放大之後，8*8的tile變成16*16，中間的插值是不是需要另外處理? 所以GBA的作法是將螢幕座標乘上仿射矩陣的逆矩陣，反著映射回VRAM，這下就保證每一個pixel都會有屬於它的data了 可想而知的，只要一轉下去，品質一定糟糕到受不了，不過GBA嘛......你也不能要求太多 因為上面的矩陣沒有平移(平移不是線性轉換)，所以可逆 實際上的渲染流程 我們的渲染流程並不難，先讓我們來看一下幾個重要的register 由於能支援仿射功能的圖層有兩個(BG2、BG3)，所以以下的register都會是兩組 1.BGX_L, BGX_H, BGY_L, BGY_H 用來定義texture space的起始點(Starting point)，因為格式不是integer而是fixed-point，因此長度會比較長，需要分兩塊來存 2.BGX_PA, BGX_PD, BGX_PC, BGX_PD 用來描述我們的仿設反矩陣 Starting point是Q8格式的fixed-point，即[0:7]是小數部分，[8:26]是整數部分，[27]是sign bit PA、PB、PC、PD是Q8格式的fixed-point，即[0:7]是小數部分，[8:14]是整數部分，[15]是sign bit 基本上運算規則如下 BG_X與BG_Y就是仿射矩陣的平移部份了 就是這麼的樸實無華 且枯燥，用圖來看會像是這樣 我們之前有提到過在Affine BG下，map data都是1 byte，在這個狀態下只要把跟 除8，就可以得到map data的address了 順帶附上fixed-point乘法的程式碼 12345678int q_mul(int32_t a, int16_t b) { int32_t temp; temp = (int32_t)a * (int32_t)b; // result type is operand's type // Rounding; mid values are rounded up temp += (temp &gt;&gt; 7) &amp; 1; return temp &gt;&gt; 8;}","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"}]},{"title":"GBA圖形處理邏輯模擬 - Object tile memory","slug":"obj-tile-memory","date":"2022-08-03T16:06:57.000Z","updated":"2022-08-03T16:07:30.708Z","comments":true,"path":"obj-tile-memory/","link":"","permalink":"https://ggorz10227216.github.io/obj-tile-memory/","excerpt":"cover 相較於BG tile的排列是依靠map data描述，obj tile並不存在map data，我們會直接透過character name來存取obj tile，但obj tile memory實際上有兩種不同的排列方式，本文將會分別說明這兩種方式的細節","text":"cover 相較於BG tile的排列是依靠map data描述，obj tile並不存在map data，我們會直接透過character name來存取obj tile，但obj tile memory實際上有兩種不同的排列方式，本文將會分別說明這兩種方式的細節 1 Dimensional 1 Dimensional，又稱線性排列，指的就是8*8的tile data是依照記憶體位置一直往後排列，如下圖所述: 1d_layout 此排列方法雖然擁有比較高的空間效率，但並不便於美術人員設計obj 2 Dimensional 2 Dimensional，我稱呼它為平面排列，在這個模式下8*8的tile會依照真實obj所要求的樣子排列，如下圖所述: 2d_layout 也就是說整個obj tile memory被分割成了0x20個tile per line 要注意的一點是，雖然tile是2d排列，但是tile data卻還是一樣是線性的，也就是說每個tile中的第一行與第二行之間的記憶體位置差是byte per tile line(0x4 or 0x8)，而非byte per tile line * 0x20","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"}]},{"title":"GBA圖形處理邏輯模擬 - Object Attribute Memory(OAM)","slug":"oam","date":"2022-08-03T16:00:15.000Z","updated":"2022-08-06T14:05:06.015Z","comments":true,"path":"oam/","link":"","permalink":"https://ggorz10227216.github.io/oam/","excerpt":"cover 相較於BG在渲染時會依照Map memory中的Map data進行渲染，Object在渲染時則是依照OAM中的資訊來進行，本文將會對OAM特性進行說明","text":"cover 相較於BG在渲染時會依照Map memory中的Map data進行渲染，Object在渲染時則是依照OAM中的資訊來進行，本文將會對OAM特性進行說明 OAM layout 我們的OAM位於0x0700'0000 ~ 0x0700'03ff，總共可以分成128塊，每一塊為6 bytes 每一個6 bytes的實體又分為三部分 Attribute 0 y-coordinate: 描述此obj位於螢幕上的y座標 Rotation/Scaling Flag: 用於標示此obj是否需要旋轉縮放 OBJ Mode: obj有三種模式可以選擇 00: 正常的描繪此obj 01: 此obj需要進行alpha blending，詳見GBA圖形處理邏輯模擬 - Graphics effect 10: OBJ window: 將此obj用於描述window的形狀，詳見GBA圖形處理邏輯模擬 - Graphics effect 11: 無實際作用 OBJ Mosaic: 對OBJ套用mosaic特效，詳見GBA圖形處理邏輯模擬 - Graphics effect Color mode: 與bg map上的相同欄位功能類似，決定此obj要以16色還是256色繪製，關於tile詳見GBA圖形處理邏輯模擬 - Tile format OBJ Shape: 標示此obj的形狀特徵，詳見後面描述 Attribute 1 x-coordinate: 描述此obj在螢幕上的x座標 Rotation/scaling parameter selection: 若此obj有啟用rotation/scaling功能，則可透過此field指定要使用的旋轉縮放矩陣，詳見下方說明 Horizontal/Vertical flip flag: 若此obj沒有啟用rotation/scaling功能，則可利用此flag標明需要水平/垂直相反繪製，需要注意的是這兩個flag剛好與Rotation/scaling parameter重疊 OBJ Size: 與OBJ shape配合，用於決定obj的size，見下表說明 Attribute 2 Character name: 如同map data，這裡個character name也是一個offset number，將其乘上0x20後即為此obj的tile data起始位置，要特別注意的是在DISPCNT(0x0400'0000)中的OBJ Character VRAM Mapping Format控制著obj tile在memory裡投排列的方式，詳見GBA圖形處理邏輯模擬 - Object tile memory OBJ Rotation/Scaling Parameters 就如同先前在講Affine background時候提到的，OBJ也可以透過仿射矩陣來做旋轉與縮放，矩陣位於OAM之中，但是排列方式比較特殊，我們來回顧一下這張圖 oam_layout 我們可以發現運算所需要的PA、PB、PC、PD以6 bytes為間隔，分散存放，而旋轉方法大致上與GBA圖形處理邏輯模擬 - Affine background說明的一樣，但有幾點需要注意: - OBJ的旋轉是以自身中心點作為旋轉的基準，而非左上角","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"}]},{"title":"Linear transformations","slug":"linear-transformations","date":"2022-08-03T15:52:00.000Z","updated":"2022-08-08T02:21:32.741Z","comments":true,"path":"linear-transformations/","link":"","permalink":"https://ggorz10227216.github.io/linear-transformations/","excerpt":"image alt 有關於線性轉換的一些筆記，放在這裡以備不時之需","text":"image alt 有關於線性轉換的一些筆記，放在這裡以備不時之需 A transformation : maps in to in T is a linear transformation if Some linear transformation example: Rotation in Reflection in Some instresting transformation(but not linear!) Translation Length Question: Is any a linear transformation? Let's check it by definition We know $T(cv) = A(cv) = cA(v) = cT(v) The answer is: Yes Composition of two trasformations: It's possible to combine multiple linear transformation to one. If and are linear，their combination is also linear. Combination order matters， not always equal to Language of transformations is a transformation : domain, : codomain : the image of v kernel of = the set of in that Range of = = the set of all images If is a linear transformation We'll try to prove that by linear transformation's definition is a subspace of if , then if , then is a subspace of if , , then if , then = range of , Rank of = Nullify of = One to one The linear transformation is one to one if for any Onto A linear transformation is onto if Isomorphism(同形) A one-to-one linear transformation is onto is an isomorphism Linear trans. V.S. Matrix calculation Suppose , is = the set of 's that = Nullspace of = = the set of all images = column space of = == == Recall Rank theorem is one-to-one = = is full column rank(only one solution) T is onto = = = is full row rank(has solution) T is isomorphism A is full rank Coordinate systems and general vector spaces Recall unique representation theorem there exists one and only one way to express any in as a linear combination of Coordinate vecotr in the basis : Let's suppose a basis ，then we want to map a vecotr (which is within ) to ，and and are isomorphism We can achive that by: General vector spaces(optional) With defined vector addition and scalar multiplication exist a unique 0 satisfied for any , there exists , Matrices of linear transformations graph Suppose we have a vector in space Let's say is our input vector is space 's basis is the Input coordinate vector i.e. Then, is the basis of is our output vector i.e. One question is: Is there exist a matirx Satisfied ? (The red path in our figure) 我們可以回想一下定義 Input vector 把係數提出來就是, 所以 則Output vector 不要忘記線性轉換的基本定義! 而我們稱呼原本在基底空間中的座標向量為 為中的基底向量, 為中的係數 因此 我們可以思考一下，空間的基底向量經過轉換成中的向量後，一定可以被空間的基底組合出來 組合所使用的係數就可以說它是A矩陣的第一列(col)，把每一列係數放到一個矩陣裡，就是A矩陣! 所以結論就是: 所以圖表中的紅色路線的確存在!","categories":[],"tags":[{"name":"linear Algebra","slug":"linear-Algebra","permalink":"https://ggorz10227216.github.io/tags/linear-Algebra/"},{"name":"math","slug":"math","permalink":"https://ggorz10227216.github.io/tags/math/"}]},{"title":"Matrix calculation rules","slug":"basic-matrix-rule","date":"2022-08-03T13:21:09.000Z","updated":"2022-08-03T15:24:51.807Z","comments":true,"path":"basic-matrix-rule/","link":"","permalink":"https://ggorz10227216.github.io/basic-matrix-rule/","excerpt":"image alt The algebra of matrix follows some rules for addition and multiplication. Let us consider A, B and C are three different square matrices. A’ is the transpose and A-1 is the inverse of A. I is the identity matrix and c is a real number.","text":"image alt The algebra of matrix follows some rules for addition and multiplication. Let us consider A, B and C are three different square matrices. A’ is the transpose and A-1 is the inverse of A. I is the identity matrix and c is a real number. 神偷小吉從網路上偷來的線性代數小抄 Now as per the rules of laws of matrices: Also, see here rules for transposition of matrices: The inverse rules of matrices are as follows: prove:","categories":[],"tags":[{"name":"linear Algebra","slug":"linear-Algebra","permalink":"https://ggorz10227216.github.io/tags/linear-Algebra/"},{"name":"math","slug":"math","permalink":"https://ggorz10227216.github.io/tags/math/"}]},{"title":"Vector space","slug":"vector-space","date":"2022-08-03T09:27:02.000Z","updated":"2022-08-03T15:50:27.937Z","comments":true,"path":"vector-space/","link":"","permalink":"https://ggorz10227216.github.io/vector-space/","excerpt":"image alt 有關於向量空間的一些筆記，放在這裡以備不時之需","text":"image alt 有關於向量空間的一些筆記，放在這裡以備不時之需 Vector space &amp; subspaces = The set of all n-dimensional vectors. A subspace in the vector space must satisfies: If , in , is in If is in , is in = The set all combinations of &amp; Does equal to ? 我們可以試著證明看看是否還滿足封閉性 Column space &amp; Null space A is a matrix There are two important subspaces of A: Column space which is in any in Null space which is in We said that is solvable if and only if b can be expressed as combination of columns of A 換句話說，b要落在(的column space)中 就是vectors in Nullspace of () The set of all solutions to We know that is a subspace because: Let's suppose , are two vector in , that is has infinite solutions iff in other words, has exactly one sol. if Are all (which b is not zero)'s solution a subspace? NO If the solution set of has not path through the origin, that means we can combine two solutions of , then generate a new vector which is not in the solution set of Reduced row echelon form Is there a systematic way that can help us to find ? Yes. Suppose: Reduce A by Gauss Elimination，then get the (upper triangular form) matirx We notice that and are 1，which are pivot variables Let's analyse by formula's perspective: Let's say and are free variables , So the pivot variable are: , Finally, we can get the Complete solution Let's say that Complete solution is linear combination of Special solution, which is: = span of columns of Number of special sol. = number of free variable We know how to find N(A) now, but can we do it faster? Reduce row Echelon form Recall matrix, we'll keep reduce it by Jordan Elimination, finally get the matrix: Follow the step below to get N from R: we know the free variables are and , so fill the N like this(put the matrix into row 2 and row 4 of ): 2.Multiply remaining elements in by -1, then put them in N = #pivot of A #free variable = n - General solutions Suppose Ax = b, let's say x is General solution, which means: means complete homogeneous solution to is solution to which all free variables are 0 So, 這就代表只要存在，就一定會有解 如果存在，則有機會無限多解 如何檢驗? r = n r &lt; n r = m 1. 3. r &lt; m 2. 4. 的維度與相同，且也與未知數個數相同(無free variable) 唯一解， 的維度小於，且沒有free variable Full column rank 無解或者唯一解 的維度與相同，有free variable Full row rank 不僅存在，連也存在 無限多解 的維度小於，有free variable 無解或者無限多解 Independence, basis and dimension v1, v2, ..., vn are independent if only the trivial combination gives zero vector. otherwise, they are dependent. How to find the independent vectors in a span? Reduce the matrix to ，the column vector which has pivot is independent vector. We can also say that, a matrix is linear independet if full column rank A basis of a subspace is a set of vecotr v1, ..., vn are independent Dimension dim V = number of basis vecotrs in V conclusion The columns of are independent () rank = n(no free variable) 也就是說A中的向量剛剛好就是basis中的向量 , , , Column space Notation is In space The set of all combination of columns of Null space Notation is In space The set of solutions to Row space Notation is In space The set of all combination of rows of Left Nullspace Notation is In space The set of solutions of The reason why we call it \"Left\": , , 乘在A的左邊，使其為零，因此得名 Finding basis of these four space The basis of Pivot cols of The basis of Columns of the nullspace matrix = # free variables = The basis of Pivot rows of Notice that but The basis of There is a matrix call that can reduce to Rows of generating zero rows in are basis of 上述的內容即為The rank theory The invertible theorem is matrix(square) columns of form basis of columns of are independent 1, 2指的是沒有free variable，自然是唯一解 或從空間的角度來看，只要能夠在n為空間中提供n個pivot，那麼組成任意向量即可行 這一點與3,4,5,6,7說的是一樣的事情 應該說是，這7點其實都在講差不多的事情","categories":[],"tags":[{"name":"linear Algebra","slug":"linear-Algebra","permalink":"https://ggorz10227216.github.io/tags/linear-Algebra/"},{"name":"math","slug":"math","permalink":"https://ggorz10227216.github.io/tags/math/"}]},{"title":"GBA圖形處理邏輯模擬 (一)","slug":"GBA圖形處理邏輯模擬-一","date":"2022-07-21T16:13:05.000Z","updated":"2022-07-21T16:28:53.352Z","comments":true,"path":"GBA圖形處理邏輯模擬-一/","link":"","permalink":"https://ggorz10227216.github.io/GBA%E5%9C%96%E5%BD%A2%E8%99%95%E7%90%86%E9%82%8F%E8%BC%AF%E6%A8%A1%E6%93%AC-%E4%B8%80/","excerpt":"cover GBA模擬器的開發之路，如果說CPU部分是思考\"我到底該怎麼做才對\"，那圖形的部分就會是\"我到底要怎麼做才會快\" 本系列文將會把重點聚焦在如何正確的實作一個GBA的圖形系統模擬函式庫，並提出一些手法來提升模擬的效率","text":"cover GBA模擬器的開發之路，如果說CPU部分是思考\"我到底該怎麼做才對\"，那圖形的部分就會是\"我到底要怎麼做才會快\" 本系列文將會把重點聚焦在如何正確的實作一個GBA的圖形系統模擬函式庫，並提出一些手法來提升模擬的效率 GBA圖形系統規格 相較於近代的主機都普遍配有GPU來負責圖形渲染工作，GBA也有一塊獨立於CPU的處理邏輯負責圖形工作，也就是PPU(Pixel Processing Unit) 我們可以先來看一下PPU主要提供那些圖形處理功能: 1. 輸出畫面為240*160 pixels 2. 色彩格式為RGB555 3. 具有以下兩種渲染模式: - Tile based: 基於利用尺寸為8*8的tile組合畫面，具有渲染速度快，還可以利用硬體仿射變換功能 - Bitmap based: 直接由CPU將圖形資料以Pixel為單位寫入VRAM，自由度較高但效率差，須妥善利用DMA來實作 4. 最大支援128個Sprites於螢幕上顯示 5. 支援數種圖形特效: - Rotation/Scaling - alpha blending - fade-in/out - mosaic - window 記憶體區段 PPU的工作記憶體位於0x0500'0000~0x07ff'ffff，不同的段落具有不同的用途，描述如下: memory map Palette memory: 0x0500'0000 ~ 0x0500'03ff 功用為調色盤，一分為二，前半段為背景專用，後半段為OBJ使用 各具有256色，皆為RGB555格式 Bus為16 bit Video RAM(VRAM): 0x0600'0000 ~ 0x0601'7fff 圖形系統的主記憶體，內容會根據繪圖模式有所不同，後面會詳述 Bus為16 bit OBJ Attributes(OAM): 0x0700'0000 ~ 0x0700'03ff 用於描述各Sprite的屬性，以及Sprite在作仿射變換時所使用的矩陣內容 Bus為32 bit 聰明的小吉們應該有注意到一件事，我們在上面提到的address為0x0500'0000~0x07ff'ffff 但是下面再說明功能的時候，描述的範圍只有一部分，那剩下沒有涵蓋到(途中的黑色部分)的部分到底有沒有用??? 這裡就必須要提及GBA系統的Undefined behavior，其中的Memory mirror章節有提到GBA硬體的Bus在面對這些奇怪的R/W時會有那些行為 具體模擬的細節我會在MMU相關的文章內作說明 開發環境 我們的目標是要設計一個負責繪製GBA遊戲畫面的library，而非完全地將邏輯內嵌至模擬器主程式內，所以為了讓我們可以在沒有模擬除了PPU以外的功能的狀態下也能夠對PPU進行debug，我們勢必要開發一個前端，去調用PPU library所開出的介面來產生畫面 重點來了，阿你就沒有模擬整個系統，PPU怎麼會知道要繪製什麼東西??? pic 而問題的答案也很簡單，找另外一個模擬器，直接去dump他的memory再寫進我們的PPU memory即可 有一個除錯器NO$GBA可以幫我們做到這件事情，我們在後續的開發流程也會持續的使用這個工具來協助我們釐清問題 模擬流程 上面的說明中我有特別提到PPU在GBA系統中扮演的角色類似於我們現代電腦系統的GPU，但是其工作原理其實與GPU差異很大 現在的GPU基本上擅長一次處理大量的頂點或貼圖資料，但GBA的繪製流程是以scanline為單位，一條一條畫，同時繪圖狀態會根據H-Blank與V-Blank作變化 因此，我們並不會直接就利用GPU來繪製我們模擬器的遊戲畫面，而是先行使用CPU在main memory上產生出pixel format為RGB555的frame buffer後，緊接著一次做完整個畫面的RGB555 to RGBA8888的轉換，最後一步才是透過ImGUI把buffer的內容轉成texture，交由GPU渲染。","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"}]},{"title":"GBA的軟體中斷與其相對應的處理","slug":"hardirq","date":"2022-07-19T10:35:23.000Z","updated":"2022-07-21T16:17:12.347Z","comments":true,"path":"hardirq/","link":"","permalink":"https://ggorz10227216.github.io/hardirq/","excerpt":"cover GBA所使用的CPU ARM7TDMI要觸發中斷基本上有硬體中斷與軟體中斷兩種手段，兩種中斷的運作機制部份相似但在關鍵部份還是有所差異，若要正確模擬GBA的中斷就必須要將這兩種中斷的運作機制都搞清楚才行 換句話說，關於GBA的中斷沒有打模糊仗的空間，該讀的Spec就是要讀，該想的問題就是要想 本文會先就軟體中斷的部份作解說，硬體中斷會在另外一篇文章作描述","text":"cover GBA所使用的CPU ARM7TDMI要觸發中斷基本上有硬體中斷與軟體中斷兩種手段，兩種中斷的運作機制部份相似但在關鍵部份還是有所差異，若要正確模擬GBA的中斷就必須要將這兩種中斷的運作機制都搞清楚才行 換句話說，關於GBA的中斷沒有打模糊仗的空間，該讀的Spec就是要讀，該想的問題就是要想 本文會先就軟體中斷的部份作解說，硬體中斷會在另外一篇文章作描述 軟體中斷(SWI) 軟體中斷，顧名思義就是透過軟體觸發的中斷，更精確的說法是透過SWI指令所造成的一連串CPU Mode切換與Program Counter(PC)跳轉，大致上可以分解為以下數個步驟： 1. 切換CPU Operating mode到Supervisor(SVC)下，並將目前mode的CPSR保存到SPSR_svc，在這一步之後所有被操作的暫存器皆為svc專屬的bank(從datasheet的角度來講就是 **_svc結尾的register** ) 2. 將中斷結束後需要被執行的下一條指令(也就是PC - instructionLength)放入R14_svc(LR) 3. 無論目前的CPU mode為何，一律切換CPU mode到ARM mode 4. 將PC指定為中斷向量中軟體中斷的記憶體位置，依照慣例為0x08，緊接著重新填充管線 5. 為了防止執行軟體中斷的同時硬體中斷也被觸發，CPSR I bit(IRQ disable bit)也會在指令的最後被set 大致上SWI的工作流程我們可以從cycle table來看出個大概： Xn指的就是中斷向量的位置，值得一提的是即便最終管線有被重新填充，在指令的一開始我們還是有做instruction fetch，為了不要算錯cpu cycle，我們還是要針對PC + 2L所在的記憶體區段計算正確的N Cycle加到模擬器的cycle counter上 對了，後面會提的硬體中斷(IRQ)基本上也是類似的套路，直接將邏輯抽出來變成一個function是一個不錯的選擇 軟體中斷的跳轉與實際運作 講完了軟體中斷的進入，接下來是中間運作的機制: 1. 在CPU跳轉到0x08之後會看到一個branch指令，這次跳轉才會跳到BIOS中負責決定該去那一個handler的handler上(依照官方BIOS的設計，位置在0x140） 2. 透過讀取lr的方式取得剛剛很可憐，被CPU當成塑膠的comment field，並透過位於0x1c8的swi_handler_table作跳轉 3. 最後透過bx r12進入正確的handler 要注意的一點是，以上只是針對任天堂官方BIOS做了一個粗略的解釋，我省略了不少內容，因為這一個部份的邏輯只要指令實作正確，基本上模擬器層不需要多加擔心，不過我強烈建議一定要去看一下這一部份的反組譯 軟體中斷的結束與狀態恢復 最後當中斷結束時，我們必須要還原到中斷前的狀態: 1. GBA BIOS在執行軟體中斷時，會切換到system mode下(SVC-&gt;SYS)，在中斷結束時會切換回SVC 2. 切換回SVC bank之後，從stack上取得中斷前的CPSR,放入SPSR 3. 最後使用movs將LR寫回PC，mov指令當S bit set且dst為PC時會順帶將SPSR寫回CPSR，因此系統將會回復到中斷前的狀態，並重新填充管線 我們可以發現GBA BIOS的確有遵照著ARM7TDMI Datasheet回復中斷前的狀態(見SWI Return Instruction一欄) 小結 中斷處理一直以來在模擬器實作上都是一個棘手的問題，因為其牽涉到CPU本身的指令實做與記憶體存取功能兩者是否正確(換言之，今天有bug發生你不太好釐清是誰有錯) 當CPU與週邊裝置開始連動時(LCD Joypad audio.....)問題會變得更加複雜，因此強烈建議要做好測試，方便你後續釐清問題","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"ARM","slug":"ARM","permalink":"https://ggorz10227216.github.io/tags/ARM/"},{"name":"system programming","slug":"system-programming","permalink":"https://ggorz10227216.github.io/tags/system-programming/"}]}],"categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://ggorz10227216.github.io/tags/C/"},{"name":"CTAD","slug":"CTAD","permalink":"https://ggorz10227216.github.io/tags/CTAD/"},{"name":"Variadic template","slug":"Variadic-template","permalink":"https://ggorz10227216.github.io/tags/Variadic-template/"},{"name":"cpp_weekly_note","slug":"cpp-weekly-note","permalink":"https://ggorz10227216.github.io/tags/cpp-weekly-note/"},{"name":"c++","slug":"c","permalink":"https://ggorz10227216.github.io/tags/c/"},{"name":"linear Algebra","slug":"linear-Algebra","permalink":"https://ggorz10227216.github.io/tags/linear-Algebra/"},{"name":"math","slug":"math","permalink":"https://ggorz10227216.github.io/tags/math/"},{"name":"networking","slug":"networking","permalink":"https://ggorz10227216.github.io/tags/networking/"},{"name":"Boost","slug":"Boost","permalink":"https://ggorz10227216.github.io/tags/Boost/"},{"name":"asynchronous_IO","slug":"asynchronous-IO","permalink":"https://ggorz10227216.github.io/tags/asynchronous-IO/"},{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"},{"name":"ARM","slug":"ARM","permalink":"https://ggorz10227216.github.io/tags/ARM/"},{"name":"system programming","slug":"system-programming","permalink":"https://ggorz10227216.github.io/tags/system-programming/"}]}