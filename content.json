{"meta":{"title":"黃爸爸狗園","subtitle":"本園只有sanitizer，沒有狗籠","description":"","author":"0rzgg","url":"https://GGORZ10227216.github.io","root":"/"},"pages":[{"title":"categories","date":"2022-08-09T10:01:14.000Z","updated":"2022-08-09T10:01:14.853Z","comments":true,"path":"categories/index.html","permalink":"https://ggorz10227216.github.io/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2022-08-08T18:24:49.000Z","updated":"2022-08-08T18:54:45.327Z","comments":true,"path":"about/index.html","permalink":"https://ggorz10227216.github.io/about/index.html","excerpt":"","text":"歡迎來到我的狗園! 這裡基本上是我放各種技術筆記的地方，目前有以下幾個系列 線性代數筆記 GBA模擬器開發 稀奇古怪的C++筆記 CPP weekly筆記 關於園長 你可以用黃志傑這個名字在facebook上找到我(你現在知道為何這個網站叫做黃爸爸狗園了)，雖然我並不叫這個名字 大部分的時間都在寫C++，最近都在研究C++20跟C++23的新東西 熱衷於研究各種中大型軟體系統，特別是模擬器 最近正在寫GBA的圖形邏輯模擬 最喜歡的遊戲是Silent hill 2"},{"title":"實用連結","date":"2022-08-09T10:01:57.000Z","updated":"2022-08-10T17:01:13.857Z","comments":true,"path":"links/index.html","permalink":"https://ggorz10227216.github.io/links/index.html","excerpt":"","text":"本頁紀錄著一些我覺得很有用的網站，有興趣可以看看 Website, blog Hamilton Chang's Blog 我的一個主攻機器學習的朋友Hamiton的blog LearnCPP 個人相當推薦的C++學習資源，如果你對C++有興趣但不知從何下手，這會是一個不錯的選擇 Tools Compiler explorer 及時編譯C++的工具，可以快速的檢查出來的ASM是否符合預期 C++ Insights 線上展開C++語法糖以及template，用來分析複雜的C++ code很好用 Quick C++ Benchmark 用於對某一段程式碼做benchmark，有圖形化的介面可以分析效能差距 Youtube channel Cᐩᐩ Weekly With Jason Turner 每週會更新一集與C++特性相關的影片，是學習C++新特性or了解效能優化手段的好地方 Gamefromscratch 與遊戲設計較為相關，基本上圍繞著引擎還有工具相關的主題 偶爾會有一些asset store限時特價的消息 GamesWithGabe 有提及一些opengl跟glsl的內容，有一段時間沒更新了...... mCoding Python以及C++的相關內容，比較沒有特定方向 The Cherno 自幹遊戲引擎的大老，最近有一些Ray tracing的教學"},{"title":"Resume","date":"2022-08-09T10:13:33.000Z","updated":"2022-08-10T16:10:02.790Z","comments":true,"path":"resume/index.html","permalink":"https://ggorz10227216.github.io/resume/index.html","excerpt":"","text":"Education National Central University, M.E. in Software Engineering, Sept. 2017 - Aug. 2019 Chung Yuan Christian University, B.S. in Computer Science and Information Engineering, Sep. 2013 - June. 2017 Experience ASUSTeK Computer Inc, Camera BSP Engineer., Taiwan, Taipei Sep.2020-Jun.2022 C++/C/Python/System programming/Performance tuning Developed a high-performance and low-power consumption gyro sampling system for zenfone9 image stabilization function. Optimized and maintained the zenfone9 kernel driver to ensure robustness. Developed a python-based, automated, and scriptable camera system stress testing tool for ASUS mobile devices. Maintained HDR10+ recording feature and SELinux module for ROG Phone and Zenfone Competition Mediatek Connectivity Innovation Challenge, Team Leader, Jun.2016 - Nov.2016 C++/Qt/Video streaming/Networking Honorable Mention Developed a low-cost and scalable Location-Based Service(LBS) solution. Developed a high-throughput TCP server/client architecture on Mediatek's Linkit 7688 embedded system. Designed a Qt based, high performance MJPEG video streaming program. Projects Ggboy! Developed a Gameboy emulator with cycle accurate LR35902 CPU emulation written in C++. Implemented Retro-style grayscale LCD display. Ported sound emulation function. GgAdv2 Developed a Gameboy Advance(GBA) emulator written in C++. Designed a full functional ARM7TDMI CPU emulation with a high performance O(1) instruction decoder. Designed a robust MMU emulation mechanism. Implemented peripheral emulation: DMA controller, timer, EEPROM on cartridge. Libggafx Developed an experimental GBA PPU emulation library with an ImGui frontend. Developed debugging tools to display the actual state of the PPU in-game. Designed as a concise interface to be easily embedded. OurScheme Developed a portable Scheme interpreter written in C++. Designed for correctness and robustness."}],"posts":[{"title":"C++ Polymorphic allocator，花式記憶體管理 (四)","slug":"cpp-pmr-4","date":"2022-09-21T15:42:53.000Z","updated":"2022-09-21T15:43:44.217Z","comments":true,"path":"cpp-pmr-4/","link":"","permalink":"https://ggorz10227216.github.io/cpp-pmr-4/","excerpt":"本系列文為C++ Weekly PMR Series的筆記文之四 我們在上篇文章中說明了定義Allocator aware type所需的注意事項，以及其背後的機制 在本文中，我們將繼續介紹包含monotonic_buffer_resource在內的數種memory_resource的特性","text":"本系列文為C++ Weekly PMR Series的筆記文之四 我們在上篇文章中說明了定義Allocator aware type所需的注意事項，以及其背後的機制 在本文中，我們將繼續介紹包含monotonic_buffer_resource在內的數種memory_resource的特性 memory_resource與記憶體分配策略 我們在前文中有提過polymorphic allocator到底是使用那一種記憶體分配策略，是依靠其內部的memory_resource在控制 By default會是new_delete_resource，背後對應的就是heap allocation 我們也在前面的文章中幹過不少次把容器的allocator換成帶有monotonic_buffer_resource的allocator 接著我們討論到當memory_resource耗盡了內部的記憶體資源時，該層級的memory_resource就會使用它的upstream_resource來獲取另一塊記憶體 關鍵是，雖然預設upstream_resource會是new_delete_resource，但我們可以將其替換成不同的resource，藉此組合不同memory_resource的特性來達成目的 所以接下來我們就要來探討standard library提供的memory_resource有那些，而我們又該如何組合他們 各種memory_resoure null_memory_resource 顧名思義，就是一個什麼都沒有的memory_resource，我們在先前的文章中也看過他幾次 他的allocate()只要一被呼叫，就會立即拋出例外std::bad_alloc deallocate()則啥也不幹 所以我們會把null_memory_resource使用在那些常理來說不應該被耗盡的memory_resource上(透過指定upstream_resource的方式) 亦或者是將其指定為default_resource，避免有不被預期的allocation沒有被我們發現 monotonic_buffer_resource 其運作邏輯是，給定一塊buffer(不一定要是local buffer，我們也可以把他的upstream設為new_delete，讓他去管理heap上的buffer) 在這塊buffer上，我們永遠只會做allocation，絕對不做deallocation 藉此將memory allocation的overhead壓到最低 但其代價就是面對頻繁新增刪除的場景就會導致非常糟糕的記憶體使用效率 當它內部的buffer耗盡時，一樣也會透過upstream_resource去要一塊新的buffer 具體而言是透過monotonic_memory_resource::_M_new_buffer()這個function 但新的buffer會有多大，依照cppreference所述，看實作= = (un)synchronized_pool_resource 具體而言是synchronized_pool_resource跟unsynchronized_pool_resource 基本上差不多，但synchronized的版本是thread-safe，另一個不是 名字裡頭有個pool，所以資料都泡水嗎 並沒有，這裡的pool應該要加上s，他的意思是這個memory_resource內有很多不同用chunk size區分的資源池，有點像是spa中心那樣有很多不同的池 等到那天黃爸有工作了，一定要去spa中心轉轉 舉例來說，pool_resource會建立4 byte池，8 byte池...等資源池，每一個池子都是一塊獨立的buffer，由於每一個池子內部的資源大小都是固定的，因此我們新增以及修改元素就比較不容易造成記憶體破碎化問題 詳細有關pool的內部實作方式可以參考libstdc++ Pool的建構 -&gt; __pool_resource::_M_alloc_pools() 一個物件要進到pool，要先看他的size決定要去哪個pool -&gt; unsynchronized_pool_resource::_M_find_pool(size_t block_siz) 然後就是在do_allocate()裡頭呼叫剛剛找到的pool的allocate() 如果其中某個pool資源耗盡，則pool_resource會使用他的upstream_resource重新配置一塊buffer出來作為該pool的資源，新配置的buffer大小會與舊buffer呈現等比級數關係 new_delete_resource 我們的老朋友，沒啥好說的 Case study: unsynchronized_pool + monotonic 我們現在來仔細看一看範例，影片中的範例是操作string，有點不易觀察，我換成了uint8_t 12345678910111213141516171819202122232425262728293031int main() { spdlog::set_level(spdlog::level::trace); print_alloc default_alloc{\"Rogue PMR Allocation!\", std::pmr::null_memory_resource()}; std::pmr::set_default_resource(&amp;default_alloc); print_alloc oom{\"Out of Memory\", std::pmr::null_memory_resource()}; std::array&lt;std::uint8_t, 32768&gt; buffer{}; spdlog::debug(\"Buffer area: 0x{:x} ~ 0x{:x}\", (uint64_t)buffer.data(), (uint64_t)(buffer.data() + buffer.size())); std::pmr::monotonic_buffer_resource underlying_bytes(buffer.data(), buffer.size(), &amp;oom); print_alloc monotonic{\"Monotonic Array\", &amp;underlying_bytes}; spdlog::debug(\"Starting pool_resource construction\"); std::pmr::unsynchronized_pool_resource unsync_pool(&amp;monotonic); print_alloc pool(\"Pool\", &amp;unsync_pool); spdlog::debug(\"Starting vector construction\"); std::pmr::vector&lt;uint8_t&gt; vec(&amp;pool); vec.push_back(0x12); vec.push_back(0x34); vec.push_back(0x56); vec.push_back(0x78); spdlog::debug(\"Edit element\"); vec[1] = 0xaa; spdlog::debug(\"Exiting Main\");} 先來仔細看一看main() default_alloc是一個帶有null_memory_resource的allocator，設做default來避免不預期的allocation發生 oom是另外一個帶有null_memory_resource的allocator，作為underlying_bytes的upstream，表示帶有local buffer的monotonic resource不允許額外alloc(沒了就是沒了) 再來就是underlying_bytes跟monotonic，再來就是underlying_bytes跟monotonic underlying_bytes是一個monotonic_memory_resource，我們將它設為monotonic(他是print_alloc)的upstream monotonic就變得有點像是監視各種memory_resource的alloc &amp; dealloc的行為的中間人 仔細看一下這個範例中的print_alloc就能發現，他的do_allocate()跟do_deallocate()基本上就是印log跟轉發給upstream 最後則是unsync_pool，他是一個pool_resource 但是非常神奇的，他的upstream被設為了monotonic 這就代表unsync_pool裡頭所有的pool都會在一個連續的buffer上 我們使用了這個unsync_pool當作vector的resource，預期所有的資料都會在buffer上 對應的輸出為 1234567891011121314151617181920212223[2022-08-25 16:58:23.809] [debug] Buffer area: 0x7ffea942a700 ~ 0x7ffea9432700[2022-08-25 16:58:23.809] [debug] Starting pool_resource construction[2022-08-25 16:58:23.809] [trace] [Monotonic Array (alloc)] Size: 528 Alignment: 8 ...[2022-08-25 16:58:23.809] [trace] [Monotonic Array (alloc)] ... Address: 0x7ffea942a700[2022-08-25 16:58:23.809] [debug] Starting vector construction[2022-08-25 16:58:23.809] [trace] [Pool (alloc)] Size: 1 Alignment: 1 ...[2022-08-25 16:58:23.809] [trace] [Monotonic Array (alloc)] Size: 1024 Alignment: 8 ...[2022-08-25 16:58:23.809] [trace] [Monotonic Array (alloc)] ... Address: 0x7ffea942a910[2022-08-25 16:58:23.809] [trace] [Monotonic Array (alloc)] Size: 192 Alignment: 8 ...[2022-08-25 16:58:23.809] [trace] [Monotonic Array (alloc)] ... Address: 0x7ffea942ad10[2022-08-25 16:58:23.809] [trace] [Pool (alloc)] ... Address: 0x7ffea942a910[2022-08-25 16:58:23.809] [trace] [Pool (alloc)] Size: 2 Alignment: 1 ...[2022-08-25 16:58:23.809] [trace] [Pool (alloc)] ... Address: 0x7ffea942a918[2022-08-25 16:58:23.809] [trace] [Pool (dealloc)] Address: 0x7ffea942a910 Dealloc Size: 1 Alignment: 1 Data: 12[2022-08-25 16:58:23.809] [trace] [Pool (alloc)] Size: 4 Alignment: 1 ...[2022-08-25 16:58:23.809] [trace] [Pool (alloc)] ... Address: 0x7ffea942a910[2022-08-25 16:58:23.809] [trace] [Pool (dealloc)] Address: 0x7ffea942a918 Dealloc Size: 2 Alignment: 1 Data: 12 34[2022-08-25 16:58:23.809] [debug] Edit element[2022-08-25 16:58:23.809] [debug] Exiting Main[2022-08-25 16:58:23.809] [trace] [Pool (dealloc)] Address: 0x7ffea942a910 Dealloc Size: 4 Alignment: 1 Data: 12 aa 56 78[2022-08-25 16:58:23.809] [trace] [Monotonic Array (dealloc)] Address: 0x7ffea942a910 Dealloc Size: 1024 Alignment: 8 Data: 12 aa 56 78 00 00 00 00 12 34 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 &lt;truncated...&gt;[2022-08-25 16:58:23.809] [trace] [Monotonic Array (dealloc)] Address: 0x7ffea942ad10 Dealloc Size: 192 Alignment: 8 Data: 00 ad 42 a9 fe 7f 00 00 7e 00 00 00 00 04 00 00 10 a9 42 a9 fe 7f 00 00 00 00 00 00 00 00 00 00 00 &lt;truncated...&gt;[2022-08-25 16:58:23.809] [trace] [Monotonic Array (dealloc)] Address: 0x7ffea942a700 Dealloc Size: 528 Alignment: 8 Data: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 08 00 00 00 fc 00 00 00 00 00 00 00 00 00 00 00 00 &lt;truncated...&gt; 我們可以發現幾件事情 monotonic array的alloc總共發生了3次 0x7ffea942a700這個是屬於pool_resource的，其餘兩次都是vector 重點來了，怎麼換上了pool_resource之後，居然allocation被拆成兩次 原因是因為pool的特性，放uint8_t(1 byte, alignment 1)的以及放vector內部pointer type(8 byte, alignment 8)的被分去兩個pool 另外，pool的allocation情形也值得一看 由於是vector的關係，所以不會每一次push_back()都觸發alloc(記得capacity嗎?)，每次Pool(alloc)的size都會跟capacity相同 我們可以看到，在push_back的過程中pool有發生deallocation，但是unsync_pool的upstream是monotonic阿，照理說不應該發生deallocation 有趣的點在於，pool裏頭的memory雖然來自於monotonic，但是實際上歸unsync_pool管理(我們從log上看到的是Pool (dealloc)對吧)，因此dealloc的邏輯是照著unsynchronized_pool_resource::do_deallocate()走 unsynchronized_pool_resource::deallocate()並不是真的歸還記憶體，他是將此塊記憶體重新標示為可用，等到下次有人alloc時就會重新被給出去 而且受惠於upstream是monotonic的關係，pool的memory可以是local buffer，很酷吧! 小結 我們在本文介紹了以下數種memory_resource的特性 null_memory_resource monotonic_buffer_resource (un)synchronized_pool_resource new_delete_resource 並且實際操作了unsynchronized_pool_resource + monotonic_buffer_resource的組合 下一篇，嗯..... 可以把最後一支影片的JSON範例實際走一遍","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://ggorz10227216.github.io/tags/c/"},{"name":"cpp weekly note","slug":"cpp-weekly-note","permalink":"https://ggorz10227216.github.io/tags/cpp-weekly-note/"},{"name":"polymorphic_allocator","slug":"polymorphic-allocator","permalink":"https://ggorz10227216.github.io/tags/polymorphic-allocator/"}]},{"title":"C++ Polymorphic allocator，花式記憶體管理 (三)","slug":"cpp-pmr-3","date":"2022-09-21T15:42:13.000Z","updated":"2022-09-21T15:43:42.134Z","comments":true,"path":"cpp-pmr-3/","link":"","permalink":"https://ggorz10227216.github.io/cpp-pmr-3/","excerpt":"本系列文為C++ Weekly PMR Series的筆記文之三 我們在上篇文章中說明了自訂義memory_resource的方法，以及建構pmr容器的一些注意事項 接下來我們將繼續深入探討PMR的細節","text":"本系列文為C++ Weekly PMR Series的筆記文之三 我們在上篇文章中說明了自訂義memory_resource的方法，以及建構pmr容器的一些注意事項 接下來我們將繼續深入探討PMR的細節 還漏掉了一片拼圖 我們先前已經看過了pmr::vector跟pmr::string，還有pmr::vector&lt;pmr::string&gt; 我們使用了vector.emplace_back()來插入pmr::string，使得vector內部的所有string都依靠vector的allocator來建構 但問題來了，世界不是只有美國，C++也不是只有string 假設今天我們有一個自己寫的class S，我們要如何才可以讓S跟pmr::string一樣可以被放進pmr容器中，並且與容器使用相同的allocator呢? 要解決這個問題，我們得先分解問題為兩個部分 如何建構一個支援Polymorphic allocator的class S 如何讓容器裡的instance S與容器共用allocator 先來看一眼pmr這個namespace是何方神聖，我們寫了他很多次，但都沒仔細看過他 vector的定義 string的定義 我們可以看出無論是vector還是string，所謂的namespace pmr就只是把原本的Allocator&lt;T&gt;換成了polymorphic_allocator&lt;T&gt;而已 咦!?原本就有Allocator了? 那幹嘛我們還要再弄一個進去? Allocator&lt;T&gt; V.S. polymorphic_allocator&lt;T&gt; 會發生這種奇怪問題的原因是因為原本的allocator在設計上並不是考慮的非常周全，例如以下的情況 1234std::vector&lt;int&gt; std_vec {1, 2, 3} ; // same as std::vector&lt;int, std::allocator&lt;int&gt;&gt;std::vector&lt;int, custom_allocator&gt; custom_vec;custom_vec = std_vec ; // Error! 可以看到的是，在使用allocator的狀況下，不同allocator的vector他們具有不同的型別，一些vector與vector之間的操作就變得不好實作了 如同上面示範的assign，因為std_vec與custom_vec的型別不同了，因此編譯會失敗，你得自己徒手實作operator =才行 更麻煩的是，即便你寫了一個可以處理custom_vec的operator =，萬一我又寫了一個新的allocator(我們叫他bump allocator好了)，同樣的事情又要再來一遍，豈不是很惱人? 聰明的小吉肯定會想到要用template來解，的確，template可以解決掉這個問題 但代價是代碼膨脹以及編譯時間增加，就看你覺得值不值得 所以C++17引入了polymorphic_allocator，顧名思義，原本依靠不同的allocator&lt;T&gt;來切換記憶體管理策略的方式，現在一率都變成用繼承的方式來處理 你可以看到無論是先前提過的monotonic_buffer_resource，還是等等我們會介紹的unsynchronized_pool_resource，他們全部都繼承自std::pmr::memory_resource 反過來說，任何pmr容器內部都會有一個polymorphic_allocator&lt;T&gt;，透過其內部不同的memory_resource來實現不同的記憶體管理行為 但我們從外面看，容器型別都是一樣的(Allocator都是polymorphic_allocator&lt;T&gt;) 如此一來，Allcator&lt;T&gt;的問題就能夠被解決掉，但由於polymorphic_allocator背後是仰賴v_table機制運作，因此virtual function call的overhead就必須要被考慮 假設你很在乎的話啦... Allocator-Aware Types 在釐清完allocator的問題後，我們就要來實際來解決第一個問題: 建構一個支援Polymorphic allocator的class S 由於我們只打算讓class支援polymorphic allocator，所以可以直接一點，直接塞進constructor裏頭，就不用那麼麻煩搞一個namespace pmr了 我們沿用上一篇文章的範例，稍微修改一下(code在這) 123456789101112131415161718class S {public: S(const char* str) : _str(str) { } S(const char* str, const std::pmr::polymorphic_allocator&lt;&gt;&amp; allocator) : _str(str, allocator), _alloc(allocator) { } private: std::pmr::string _str = \"long long long long long long\"; std::pmr::polymorphic_allocator&lt;&gt; _alloc;}; 我們試著弄了一個class S，然後給他兩個constructor 一個普通的 跟一個可以塞pmr allocator的 看起來也沒有很難嘛，但是要接著解決下面的另一個問題: 讓容器裡的instance S與容器共用allocator 我們試著做一次之後就發現事情沒有想像的那麼容易... 123456789101112131415161718192021222324252627template &lt;typename Container, typename... Values&gt;auto create_container(auto *resource, Values&amp;&amp;... values) { Container result{resource}; result.reserve(sizeof...(values)); (result.emplace_back(std::forward&lt;Values&gt;(values)), ...); return result;}int main() { print_alloc mem; std::pmr::set_default_resource(&amp;mem); std::array&lt;std::uint8_t, 1024&gt; buffer{}; std::pmr::monotonic_buffer_resource mem_resource( buffer.data(), buffer.size() ); std::cout &lt;&lt; \"initializing vec&lt;S&gt;\\n\"; auto container = create_container&lt;std::pmr::vector&lt;S&gt;&gt; ( &amp;mem_resource, \"short string\", \"A really long string here\", \"Another really long string here\" ); std::cout &lt;&lt; \"exiting main\\n\";} // main() 對應的輸出為 123456initializing vec&lt;S&gt;Allocating 26Allocating 32exiting mainDeallocating 26: 'A really long string here'Deallocating 32: 'Another really long string here' vector內的所有具有long string的S通通都被print_alloc抓到了 我們在上篇文章中建立std::pmr::vector&lt;std::pmr::string&gt;還好端端的阿? 很明顯地這次的問題並不是出在initilizer_list上頭 那肯定跟我們的S有關 問題在於，我們的std::pmr::vector在初始化每一個內部的S物件時，並沒有順利的把mem_resource轉送給S的constructor 換言之，S沒有認到mem_resource，我們可以透過對make_container做一些修改來佐證我們的推論 12345678template &lt;typename Container, typename... Values&gt;auto create_container(auto *resource, Values&amp;&amp;... values) { Container result{resource}; result.reserve(sizeof...(values)); (result.emplace_back(std::forward&lt;Values&gt;(values), resource), ...); // ^ here return result;} 在修改後，我們就可以看到原本被print_alloc捕捉到的alloc &amp; dealloc行為消失了，所以的確問題就是S沒有成功的認到vector內的mem_resource 那為何std::pmr::string就可以在原本的make_container下被認到? 這...說來話長 簡單的來說，任何帶有using allocator_type的class，在allocation的過程中(uses_allocator_args.h::uses_allocator_construction_args()這一步)uses_allocator_v這個compile time check會是true 後面還有一個is_constructible_v檢查在確保給定的args真的可以建構出class 一定要通過這些檢查，我們給的allocator才會真的被拿起來用 否則就會被忽略，改用default_constructor 所以我們的目標就是要讓S上也有using allocator_type OK，事不宜遲，我們來看影片中改過的版本長怎樣 123456789101112131415161718192021222324252627282930313233struct S { std::pmr::string str; using allocator_type = std::pmr::polymorphic_allocator&lt;&gt;; // default constructor, delegate to aa constructor S(const char* sstr) : S(sstr, allocator_type{}) {} explicit S(const char* sstr, allocator_type alloc) : str(sstr, alloc) { } S(const S &amp;other, allocator_type alloc = {}) : str(other.str, alloc) { } S(S &amp;&amp;) = default; S(S &amp;&amp;other, allocator_type alloc) : str(std::move(other.str), alloc) {} S &amp;operator=(const S &amp;rhs) = default; S &amp;operator=(S &amp;&amp;rhs) = default; ~S() = default; allocator_type get_allocator() const { return str.get_allocator(); }}; 我們總共做了以下幾點修改 補上using allocator_type 根據rule of five，把該給的constructor跟destructor寫出來 Cool, 完整程式碼在此，來看看輸出 1234initializing vec&lt;S&gt;A really long string hereAnother really long string hereexiting main 現在所有的pmr::string都有乖乖地在local buffer上做allocation了 到這裡，我們就正式的完成了Allocator-Aware Types的建構 小結 我們在本篇文章中探討了Allocator-Aware Types的建構方式，並且實際利用一個class S來實驗結果是否符合預期 我們還探討了polymorphic_allocator與傳統allocator的不同，以及他們各自的優缺點 我們也簡單的研究了一下using allocator_type背後的機轉為何 下一篇文章我們就會正式開始探討不同的記憶體管理策略 有的時候我都在想，搞那麼複雜幹嘛呢...","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://ggorz10227216.github.io/tags/c/"},{"name":"cpp weekly note","slug":"cpp-weekly-note","permalink":"https://ggorz10227216.github.io/tags/cpp-weekly-note/"},{"name":"polymorphic_allocator","slug":"polymorphic-allocator","permalink":"https://ggorz10227216.github.io/tags/polymorphic-allocator/"}]},{"title":"C++ Polymorphic allocator，花式記憶體管理 (二)","slug":"cpp-pmr-2","date":"2022-09-21T15:39:22.000Z","updated":"2022-09-21T15:43:48.114Z","comments":true,"path":"cpp-pmr-2/","link":"","permalink":"https://ggorz10227216.github.io/cpp-pmr-2/","excerpt":"本系列文為C++ Weekly PMR Series的筆記文之二 讓我們接續先前的進度，繼續深入探討PMR","text":"本系列文為C++ Weekly PMR Series的筆記文之二 讓我們接續先前的進度，繼續深入探討PMR Custom memory resource 我們在上篇文章的結尾，探討了當local buffer耗盡時的種種問題，問題是我們似乎沒有一個很好的手段可以去監視記憶體配置的行為 也就是說，alloc與dealloc發生時並沒有一個很明確的feedback 我們有辦法...印個log? 來看一下影片中提到的memory_resource 12345678910111213141516171819202122232425// thanks to Rahil Baber// Prints if new/delete gets used.class print_alloc : public std::pmr::memory_resource { private: void* do_allocate(std::size_t bytes, std::size_t alignment) override { std::cout &lt;&lt; \"Allocating \" &lt;&lt; bytes &lt;&lt; '\\n'; return std::pmr::new_delete_resource()-&gt;allocate(bytes, alignment); } void do_deallocate(void* p, std::size_t bytes, std::size_t alignment) override { std::cout &lt;&lt; \"Deallocating \" &lt;&lt; bytes &lt;&lt; \": '\"; for (std::size_t i = 0; i &lt; bytes; ++i) { std::cout &lt;&lt; *(static_cast&lt;char*&gt;(p) + i); } std::cout &lt;&lt; \"'\\n\"; return std::pmr::new_delete_resource()-&gt;deallocate(p, bytes, alignment); } bool do_is_equal( const std::pmr::memory_resource&amp; other) const noexcept override { return std::pmr::new_delete_resource()-&gt;is_equal(other); }}; 雖然叫做print_alloc，但它並不是allocator，他是一個memory_resource 萬事起頭難，先來看一看cppreference是如何描述它的 std::pmr::memory_resource is an abstract interface to an unbounded set of classes encapsulating memory resources memory_resource作為一個介面(interface)存在，有下面三的virtual method需要我們去實作 do_allocate do_deallocate do_is_equal 接著再來仔細看看這三個method的描述 void* do_allocate(std::size_t bytes, std::size_t alignment) 負責從被管理的buffer(stack或是heap)中嘗試著分配一塊長度為bytes，並且memory address有對齊alignment的空間出來 好比說對齊8就是return address永遠會是8的倍數 void do_deallocate(void* p, std::size_t bytes, std::size_t alignment); 負責回收先前do_allocate()配置的記憶體，唯一一點要注意的是p必須是先前do_allocate()配置出來的 bool do_is_equal(const std::pmr::memory_resource&amp; other) const noexcept 負責判斷other跟當前的這個(*this)是否管理的是同一塊buffer Case study: vector of std::string 講是這樣講，但實際上還是要看實作怎麼做，所以我們仔細看一看我們的print_alloc print_alloc底下實作通通都是仰賴new_delete_resource，但至少在do_allocate()跟do_deallocate()裡頭多了std::cout來輸出一些訊息給我們 我們做了一個會在alloc跟dealloc時印log的memory_resource，然後呢? 我修改了一下影片中的範例，完整程式碼請看這裡，我們在這裡先將注意力放在main()上 1234567891011121314151617181920212223242526int main() { // remember initializer lists are broken. print_alloc mem; std::pmr::set_default_resource(&amp;mem); std::array&lt;std::uint8_t, 1024&gt; buffer{}; std::pmr::monotonic_buffer_resource mem_resource( buffer.data(), buffer.size() ); std::cout &lt;&lt; \"initializing vector\\n\"; std::pmr::vector&lt;std::string&gt; container({ \"short string\", \"A really long string here\", \"Another really long string here\" }, &amp;mem_resource) ; int idx = 0 ; for (const auto&amp; elem : container) { fmt::print(\"[{}] addr: 0x{:x},\\n\\t {}\\n\", idx++, (uint64_t)elem.data(), elem) ; } // for std::cout &lt;&lt; \"exiting main\\n\";} 我們將剛剛提到的print_alloc設置為default_resource，如此一來凡是沒有預先給定memory_resource的容器都會使用到我們的print_alloc 也就是說那些我們沒注意到的alloc跟dealloc行為現在都會印出Log來提醒我們了，好耶! 但從輸出看起來，並沒有那麼順利...... 12345678initializing vector[0] addr: 0x7ffe618514d0, short string[1] addr: 0x1874f20, A really long string here[2] addr: 0x1874f50, Another really long string hereexiting main 不僅所有long string的string data都跑去heap上，我們的print_alloc還完全沒有發揮出他該有的用途 奈A安捏? 冷靜的觀察一下輸出，很快的我們就會發現事有蹊蹺 第一個std::string，比較短的那個好端端地被配置到我們的local buffer上了 但是後面兩個比較長的全部失手 讓我們再多印點東西，看看能不能調查出什麼，緊接著修改一下用來dump內容物的for 1234for (const auto&amp; elem : container) { fmt::print(\"[{}] elem addr: 0x{:x}, data addr: 0x{:x},\\n\\t {}\\n\", idx++, (uint64_t)&amp;elem, (uint64_t)elem.data(), elem) ;} // for 對應的輸出為 12345678initializing vector[0] elem addr: 0x7ffedbcc5650, data addr: 0x7ffedbcc5660, short string[1] elem addr: 0x7ffedbcc5670, data addr: 0x1276f20, A really long string here[2] elem addr: 0x7ffedbcc5690, data addr: 0x1276f50, Another really long string hereexiting main 喔齁，每個物件(str::string)本身確實都好端端地放在local buffer上，但是長字串的data()卻被丟去了heap，怎麼會因為字串長了點就有這樣的差別阿 因為std::string具有所謂的Small Object Optimization機制 正如我們現在在做的，為了避免動不動就使用dynamic allocation，std::string對於短字串(至於到底以個字元以下才算短，不一定，要看實作)並不會真的乖乖配置heap 取而代之的是std::string內部會有一個std::array&lt;char&gt;，來存放短字串的內容 由於這個array也是std::string物件的一部分，因此不屬於dynamic allocation 仔細看，短字串的elem addr跟data addr不是正好都在local buffer上嗎? 另外每一個std::string的大小皆為0x20 bytes(你可以從elem addr的差看出來) 有興趣的話不妨留意一下libstdc++的basic_string裏頭的_M_local_buf 所以現在我們知道問題了 std::pmr::vector&lt;std::string&gt;裡頭的std::string的allocator沒有跟著一起被換成mem_resource OK，所以我們現在的目標就是讓std::string能夠吃到跟vector一樣的allocator 我們來修改一下vector的宣告 12345std::pmr::vector&lt;std::pmr::string&gt; container({ \"short string\", \"A really long string here\", \"Another really long string here\"}, &amp;mem_resource) ; 修改過後，其對應的輸出為 123456789101112initializing vectorAllocating 26Allocating 32Deallocating 32: 'Another really long string here'Deallocating 26: 'A really long string here'[0] elem addr: 0x7ffd2607d730, data addr: 0x7ffd2607d748, short string[1] elem addr: 0x7ffd2607d758, data addr: 0x7ffd2607d7a8, A really long string here[2] elem addr: 0x7ffd2607d780, data addr: 0x7ffd2607d7c2, Another really long string hereexiting main 好耶!現在三個std::\"pmr\"::string都在local buffer上了，但是看起來好像還是怪怪? 我們的new_delete_resource居然被觸發了，為啥? Initializer list的玄機 要解釋這個問題，我們得先來仔細端詳端詳我們對vector的初始化步驟，那個{}包起來的東東型別如下 1234567891011121314// What is this?// {// \"short string\",// \"A really long string here\",// \"Another really long string here\"// }std::initializer_list&lt; std::basic_string&lt; char, std::char_traits&lt;char&gt;, std::pmr::polymorphic_allocator&lt;char&gt; &gt; &gt; 型別有點長，但是我有先幫你format好喔 他是一個initializer_list，根據cppreference所述，其背後運作機制是這樣: 建構一個const T[N](在我們的例子中T=std::basic_string&lt;char, std::char_traits&lt;char&gt;, std::pmr::polymorphic_allocator&lt;char&gt;&gt;) 接著vector的初始化會拿T的begin跟end(也可能會是begin跟length)去做真正的初始化(local buffer上的string是這一步做出來的) 由於default_resource被我們換成print_alloc了，所以才抓的到const T[N]的allocation 如果我們今天沒有看log，還真的不會察覺到有這件事情發生，不過問題又來了，那怎樣初始化才是對的? push_back() V.S. emplace_back() 既然用initializer_list會有非必要的allocation發生，那換種方式總可以了吧 試試push_back()? 1234std::pmr::vector&lt;std::pmr::string&gt; container(&amp;mem_resource) ;container.push_back(\"short string\") ;container.push_back(\"A really long string here\");container.push_back(\"Another really long string here\"); 輸出為 1234Allocating 26Deallocating 26: 'A really long string here'Allocating 32Deallocating 32: 'Another really long string here' 雖然建構跟解構的順序不同了，但基本上還是沒有解決問題啊... 隨便亂試解決不了問題，看來得仔細想想背後到底出了什麼問題 就如同剛剛initializer list發生的事情一樣，我們都先建構了一個temp value，然後才用copy initialized的方式在local buffer上建構出正確的物件 push_back()也會做一樣的事情 有沒有辦法不要? 建構temp value並不是我們需要的步驟 How about emplace_back() emplace_back()做為跟push_back()相似的method，雖然目的差不多，但運作機制不太一樣 push_back()是接受一個已經建構好的物件，複製進容器 emplace_back()接受的是該物件的constructor所需的參數，內部會直接利用allocator建構出物件，最後放進容器 不正是我們要的? 手起刀落，馬上給他改下去 1234std::pmr::vector&lt;std::pmr::string&gt; container(&amp;mem_resource) ;container.emplace_back(\"short string\") ;container.emplace_back(\"A really long string here\");container.emplace_back(\"Another really long string here\"); 這樣做的確能達到我們要的效果，但總覺得有點麻煩阿，emplace_back連續寫好幾次 影片中給出的解法是用一個帶有parameter pack的function，裡面再去用fold expression去自動的生出一堆emplace_back()出來 123456789101112131415161718template &lt;typename Container, typename... Values&gt;auto create_container(auto *resource, Values&amp;&amp;... values) { Container result{resource}; result.reserve(sizeof...(values)); (result.emplace_back(std::forward&lt;Values&gt;(values)), ...); return result;}int main() { // ... auto container = create_container&lt;std::pmr::vector&lt;std::pmr::string&gt;&gt; ( &amp;mem_resource, \"short string\", \"A really long string here\", \"Another really long string here\" ) ; // ...} 雖然現在講這個有點後知後覺，不過關於為何pmr container是傳入memory_resource的pointer而非reference，以及內部的一些細節可以參考std::pmr::vector的參數危機 小結 我們在本篇文章中介紹了如何自定義一個memory_resource，用於監視alloc以及dealloc的發生 並且提到了std::string以及std::pmr::string的差異 還介紹了正確建構pmr容器的方式 關於PMR的相關細節還有不少沒有提到，所以我們會在下篇文章繼續講下去","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://ggorz10227216.github.io/tags/c/"},{"name":"cpp weekly note","slug":"cpp-weekly-note","permalink":"https://ggorz10227216.github.io/tags/cpp-weekly-note/"},{"name":"polymorphic_allocator","slug":"polymorphic-allocator","permalink":"https://ggorz10227216.github.io/tags/polymorphic-allocator/"}]},{"title":"C++ Polymorphic allocator，花式記憶體管理 (一)","slug":"cpp-pmr-1","date":"2022-09-21T15:35:56.000Z","updated":"2022-09-21T15:43:52.250Z","comments":true,"path":"cpp-pmr-1/","link":"","permalink":"https://ggorz10227216.github.io/cpp-pmr-1/","excerpt":"本系列文為C++ Weekly PMR Series的整理加上我的一些想法補充之類的 不得不說這真的是一個很有用但也很麻煩的主題，我會盡我所能把細節都描述清楚，盡量啦!","text":"本系列文為C++ Weekly PMR Series的整理加上我的一些想法補充之類的 不得不說這真的是一個很有用但也很麻煩的主題，我會盡我所能把細節都描述清楚，盡量啦! 3.5倍的免費性能提升，真的假的? 此系列開門見山的就拋出了3.5x這種極為誇張的效能提升數字，真的是嚇死人了，柬埔寨的薪水都沒有3.5倍那麼多 到底發生了什麼? 我們來看一下code 12345678910111213141516171819202122#include &lt;memory_resource&gt;#include &lt;list&gt;void StdList(benchmark::State&amp; state) { for (auto _ : state) { std::list&lt;int&gt; list{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}; benchmark::DoNotOptimize(list); }}// Register the function as a benchmarkBENCHMARK(StdList);void PmrList(benchmark::State&amp; state) { std::array&lt;std::byte, 1024&gt; buffer; for (auto _ : state) { std::pmr::monotonic_buffer_resource mem_resource(buffer.data(), buffer.size()); std::pmr::list&lt;int&gt; list({1, 2, 3, 4 , 5, 6, 7, 8, 9, 10}, &amp;mem_resource); benchmark::DoNotOptimize(list); }}// Register the function as a benchmarkBENCHMARK(PmrList); 在這個benchmark裡頭，我們分別在兩個測項內建構一個有10個int的list物件 差別在於一個是pmr::list另一個是一般常見的list 結果效能就有了天翻地覆的差異，How? 容器與動態記憶體配置 眾所周知，C++所提供的容器除了std::array以外，那些不用預先告知長度的容器在面對內部物件不斷增多的狀況時，就會透過operator new來向作業系統要一塊位於heap的記憶體資源 理所當然的，刪去一個物件時就會使用operator delete來歸還記憶體資源 老師有講過，dynamic allocation是system call對吧?會有overhead的...... 可想而知上面的regular list耗費在allocation上的時間有多少 那我們可不可以不要做dynamic allocation? 還真的可以 我們的詭計，PMR 我們現在知道問題在於我們花了太多時間在heap allocation上，所以我們的目標就是不要那樣做 假設我們在stack上建立一塊足夠大的buffer，嗯......我指的是std::array&lt;byte&gt; 要是我能夠讓容器裡頭的new跟delete都在這塊buffer上操作那該有多好? 這正是PMR的用途了，我們來看一下PmrList()做了啥? 123std::array&lt;std::byte, 1024&gt; buffer;std::pmr::monotonic_buffer_resource mem_resource(buffer.data(), buffer.size());std::pmr::list&lt;int&gt; list({1, 2, 3, 4 , 5, 6, 7, 8, 9, 10}, &amp;mem_resource); 在除去了benchmark相關的code後，實際上與pmr相關的部分如上，我們一行一行來看 我們建立了一個長度為1024*sizeof(byte)的local buffer 因為她就在我們的stack上，所以叫她local buffer 我們將這塊buffer交給monotonic_buffer_resource管理，現在mem_resource就如同遙控器一般，誰拿著他誰就能在這塊buffer上alloc &amp; dealloc記憶體資源 我們把這個遙控器交給std::pmr::list&lt;int&gt;，讓他能夠把內部物件配置到local buffer 現在只要物件沒有超過local buffer的大小，基本上我們就可以在沒有動態配置記憶體的狀態下操作容器了 我們在quick benchmark上看到的效能差距也正來自於這裡 monotonic_buffer_resource到底幹了啥? 很顯然的，關於monotonic_buffer_resource，我們對他的了解依然不夠透徹，他到底做了啥? 我們用另外一個例子來分析: 12345678910111213141516void growing_resources() { std::array&lt;std::uint8_t, 16&gt; buffer{}; std::pmr::monotonic_buffer_resource mem_resource(buffer.data(), buffer.size()); std::pmr::vector&lt;std::uint8_t&gt; vec1(&amp;mem_resource); vec1.push_back(1); print_buffer(\"1\", buffer, vec1); vec1.push_back(2); print_buffer(\"2\", buffer, vec1); vec1.push_back(3); print_buffer(\"3\", buffer, vec1); vec1.push_back(4); print_buffer(\"4\", buffer, vec1); vec1.push_back(5); print_buffer(\"5\", buffer, vec1);} 我們仔細觀察一下他的output，會發現一件很有意思的事情 我們知道此vector背後的記憶體空間已經不在heap上，而是在我們宣告在stack上的buffer中，但我們每push_back一個元素進去時，buffer內的狀態似乎不太對勁? push_back(1) -&gt; 1, 0, 0, ...... push_back(2) -&gt; 1, 1, 2, ...... (?) push_back(3) -&gt; 1, 1, 2, 1, 2, 3, 0 ...... push_back(4) -&gt; 1, 1, 2, 1, 2, 3, 4, 0 ...... (!?) 我們所預期的內容(1, 2, 3, 4, ...)，並沒有如我們所預期的出現，這牽涉到兩個問題 vector的capacity vector這個容器具有提前預留一塊空間備用的功能，跟list來一個要一個不同，這個提前要多少可以透過vector.capacity()得知，我們可以看一下每次呼叫push_back()之前的capacity capacity: 0 -&gt; push_back(1) -&gt; [1], 0, 0, ...... capacity: 1 -&gt; push_back(2) -&gt; 1, [1, 2], ...... capacity: 2 -&gt; push_back(3) -&gt; 1, 1, 2, [1, 2, 3, 0] ...... capacity: 4 -&gt; push_back(4) -&gt; 1, 1, 2, [1, 2, 3, 4], 0 ...... 如果當前的元素個數超過的capacity，則vector會向他的allocator(在這裡會是pmr)要一塊更大的記憶體空間，一般來說是2的次方，實際上要看實作 因為我們給了帶有local buffer的monotonic_buffer_resource，所以當超過capacity時，pmr::vector就會往local buffer要一塊更大的空間 關鍵是，沒有動用到dynamic allocation 另外一點是，我們之所以會在buffer內看到push_back()之前的容器狀態殘留在buffer內，是因為monotonic_buffer_resource對於dealloc行為的特性所致，我們來看一下cppreference 直奔重點，monotonic_buffer_resource的do_deallocate是no op，也就是啥也不幹，真正的記憶體釋放只會發生在他的destructor裏頭 真正意義上的帶著進棺材 這種特殊的記憶體分配法有另一個特殊的名字 Bump Allocator 由於Bump allocator容易造成空間浪費(尤其是用於vector的情況下)，若能預先調整capacity的話就可以減輕這個副作用帶來的影響 我指的就是vector.reserve(n)，在開始插入元素之前先行將capacity調整到一個合適的大小 OK，所以我們來做個整理，monotonic_buffer_resource特殊的地方有: 他不會在生命週期內釋放任何記憶體資源，唯一釋放資源的時機就是解構時 省去了deallocation的時間 但這也同時意味著他並不適合用於需要頻繁新增、刪除元素的場景 他可接受一個外部的buffer作為記憶體資源 省去了dynamic allocation的時間 萬一我們預先準備的buffer爆了，或者我們根本沒給，那還能動嗎? 我們還漏了一個東西沒有講: upstream_resource ## upstream_resource upstream_resource對於任何memory_resource(好比說monotonic)就如同水流的上游一般，當我這一個層級的memory_resource耗盡時，就會透過upstream_resource再要一塊 大部分預設的行為，upstream_resource會是一個new_delete_resource 也就是說回歸普通的heap allocation了 當然，如果你覺得記憶體資源耗盡是一個從設計上來看不應該發生的錯誤，一旦發生就必須拋出異常，那麼你該把upstream_resource設為null_memory_resource，請見此範例 12345678910111213141516171819void null_resources() { std::array&lt;std::uint8_t, 4&gt; buffer{}; std::pmr::monotonic_buffer_resource mem_resource( buffer.data(), buffer.size(), std::pmr::null_memory_resource()); std::pmr::vector&lt;std::uint8_t&gt; vec1(&amp;mem_resource); vec1.push_back(1); print_buffer(\"1\", buffer, vec1); vec1.push_back(2); print_buffer(\"2\", buffer, vec1); vec1.push_back(3); print_buffer(\"3\", buffer, vec1); vec1.push_back(4); print_buffer(\"4\", buffer, vec1); vec1.push_back(5); print_buffer(\"5\", buffer, vec1);} 我們刻意地把local buffer縮到很小，然後再將mem_resource的upstream_resource設為null_memory_resource(constructor #6) 其執行結果會在空間耗盡時直接拋出例外: 1terminate called after throwing an instance of 'std::bad_alloc'what(): std::bad_alloc 而倘若我們把null_memory_resource換成new_delete_resource，則在local buffer耗盡之後，所有原本的元素會被複製到經由operator new所分配的記憶體資源上 也就是說，vector要求多少capacity，就new一塊滿足大小要求的memory出來，然後把原本就有的元素丟上去，再放入被push_back的元素 我們來看一下上面的null_resources()，把null換成new_delete之後會發生什麼事 12345678910111213141516171819202122232425262728293031323334=============== 1 ==============Buffer Address Start: 0x7ffc73c09d6cvector.data(): 0x7ffc73c09d6c, vector.size(): 1, vector.capacity(): 1 Item Address: 0x7ffc73c09d6c=============== 2 ==============Buffer Address Start: 0x7ffc73c09d6cvector.data(): 0x7ffc73c09d6d, vector.size(): 2, vector.capacity(): 2 Item Address: 0x7ffc73c09d6d Item Address: 0x7ffc73c09d6e=============== 3 ==============Buffer Address Start: 0x7ffc73c09d6cvector.data(): 0x205fec0, vector.size(): 3, vector.capacity(): 4 Item Address: 0x205fec0 Item Address: 0x205fec1 Item Address: 0x205fec2=============== 4 ==============Buffer Address Start: 0x7ffc73c09d6cvector.data(): 0x205fec0, vector.size(): 4, vector.capacity(): 4 Item Address: 0x205fec0 Item Address: 0x205fec1 Item Address: 0x205fec2 Item Address: 0x205fec3=============== 5 ==============Buffer Address Start: 0x7ffc73c09d6cvector.data(): 0x205fec4, vector.size(): 5, vector.capacity(): 8 Item Address: 0x205fec4 Item Address: 0x205fec5 Item Address: 0x205fec6 Item Address: 0x205fec7 Item Address: 0x205fec8 在push_back(3)的時候發生了空間不足，因此mem_resource向他的upstream要了一塊記憶體當作新空間 從vector.data()可以看出來空間已經跑去heap了(因為位置很低) 看到這裡你就會發現local buffer等同於是廢了 在往後看就可以看出，這個vector已經退化成一個普通的vector了 自從我們耗盡了原本的local buffer之後，每次超過capacity，vector都會要一塊基於2的n次方計算出來的空間，然後把原先的元素複製過去 這跟原本的vector有啥不同啊? 因此結論就是，除非你知道你在幹嘛，否則把upstream_resource設為null_memory_resource會是一個比較好的選擇 小結 在本篇文章中，我們簡單的介紹了PMR的基本原理，以及monotonic_buffer_resource的特性 另外我們也提及了當資源耗盡時，兩種可行的upstream_resource null_memory_resource new_delete_resource 我們在之後的系列文章中會接著介紹更加複雜的PMR操作，以及如何設計一個支援PMR的class","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://ggorz10227216.github.io/tags/c/"},{"name":"cpp weekly note","slug":"cpp-weekly-note","permalink":"https://ggorz10227216.github.io/tags/cpp-weekly-note/"},{"name":"polymorphic_allocator","slug":"polymorphic-allocator","permalink":"https://ggorz10227216.github.io/tags/polymorphic-allocator/"}]},{"title":"The `constexpr` Problem That Took Me 5 Years To Fix!","slug":"compile-time-string-gen","date":"2022-08-14T18:44:09.000Z","updated":"2022-08-14T18:57:35.939Z","comments":true,"path":"compile-time-string-gen/","link":"","permalink":"https://ggorz10227216.github.io/compile-time-string-gen/","excerpt":"橫跨五年，穿越時空的問題，全靠神秘江湖一點訣瞬間爆破! 太勁爆了!","text":"橫跨五年，穿越時空的問題，全靠神秘江湖一點訣瞬間爆破! 太勁爆了! 所以到底是啥問題? 假設今天我們想要在編譯期使用一個const char*來生成一個std::string(通常會要做一些處理)，這件事情可行嗎? 從理論上應該是可行吧，畢竟constexpr std::string這東西已經喊了N百年了，總該實裝了吧 的確是實裝了沒錯，但沒有你想的那麼簡單 奇怪的是，我們可以編譯期求constexpr std::string的長度，但是死活都不能變出那個std::string...... 12345678910111213consteval auto make_string(std::string_view base, const int repeat) { std::string retval; for (int times = 0 ; times &lt; repeat ; ++times) retval += base ; return retval.size() ;} // make_string()int main () { constexpr auto result = make_string(\"hello world,\", 3) ; std::cout &lt;&lt; result &lt;&lt; std::endl ; return 0 ;} 執行結果會回傳36，符合預期，但是改成直接return std::string就翻車了...... 12345678910111213consteval auto make_string(std::string_view base, const int repeat) { std::string retval; for (int times = 0 ; times &lt; repeat ; ++times) retval += base ; return retval ;} // make_string()int main () { constexpr auto result = make_string(\"hello world,\", 3) ; std::cout &lt;&lt; result &lt;&lt; std::endl ; return 0 ;} 錯誤訊息為 12error: 'make_string(std::string_view, int)(3)' is not a constant expression because it refers to a result of 'operator new' return static_cast&lt;_Tp*&gt;(::operator new(__n * sizeof(_Tp))); refers to a result of 'operator new'，蛤? 不是都變成constexpr std::string了? compile time的東西到底算不算個\"東西\"? 問題出在那? 問題出在這個\"Hello world,\" repeat 3次的std::string，他的生成發生在compile time，問題來了 如果今天我們想要印出他(好比說透過std::cout)，那這個std::string勢必一定要出現在executable的某處(因為它是constexpr std::string) 所以我們要生成一個std::string出來，可是 std::string是不定長度的容器阿，想要生成一定要透過operator new這一關 所以問題有二 不知道這個constexpr std::string要放在binary的那裡 不知道該用多長的空間放它 所以一個解決問題的思路就是，不知道要放哪，那好辦我直接用一個std::array&lt;char, 超級大&gt;，O你娘塞爆不就解決了? 1234567891011121314151617consteval auto make_string(std::string_view base, const int repeat) { std::string retval; std::array&lt;char, 1024*1024*1024&gt; buffer; for (int times = 0 ; times &lt; repeat ; ++times) retval += base ; std::copy(retval.begin(), retval.end(), buffer.begin()); return buffer ;} // make_string()int main () { constexpr auto result = make_string(\"hello world,\", 3) ; std::cout &lt;&lt; std::string_view(result.begin(), result.end()) &lt;&lt; std::endl ; return 0 ;} 這確實會是一個辦法，但你仔細看出來的asm 12345678main: push rbp mov edx, 1073741824 xor esi, esi push rbx sub rsp, 1073741832 mov rdi, rsp call memset 大事不妙，我們明明就只要36 bytes的空間，居然要初始化那個超級大array，雖然縮小長度可以解決問題，但我們不禁要問 有沒有可以配置剛剛好大小的辦法呢? 還真的有，只是看起來有點廢 1234567891011121314151617181920212223242526272829303132constexpr auto make_data(std::string_view base, const int repeat) { std::string retval; for (int times = 0 ; times &lt; repeat ; ++times) retval += base ; return retval ;}consteval auto string_length(const std::string&amp; s) { return s.size();}template &lt;size_t LEN&gt;consteval auto make_array() { return std::array&lt;char, LEN&gt;{} ;}template &lt;size_t LEN&gt;constexpr auto make_string(const std::string&amp; str) { auto buffer = make_array&lt;LEN&gt;() ; std::copy(str.begin(), str.end(), buffer.begin()); return buffer ;} // make_string()int main () { constexpr static auto length = string_length(make_data(\"hello world,\", 3)) ; constexpr auto result = make_string&lt;length&gt;(make_data(\"hello world,\", 3)) ; std::cout &lt;&lt; result.size() &lt;&lt; ' ' &lt;&lt; std::string_view(result.begin(), result.end()) &lt;&lt; std::endl ; return 0 ;} 我們做了兩次相同的make_data()，一次為了知道長度，另外一次是為了實際生成一個array，然後把東西放進去 的確array的長度剛剛好了，但我們還能不能做得更好一點? 截至目前為止我們有兩個可行的辦法 O你娘塞爆法 同樣的演兩次法 各自有各自的缺陷，但似乎我們可以把這兩種方式做一個組合 12345678910111213141516171819202122constexpr auto make_data(std::string_view base, const int repeat) { std::string retval; for (int times = 0 ; times &lt; repeat ; ++times) retval += base ; return retval ;}constexpr auto make_string(const std::string&amp; str) { auto buffer = std::make_pair(std::array&lt;char, 1024*1024&gt;{}, str.size()); std::copy(str.begin(), str.end(), buffer.first.begin()); return buffer ;} // make_string()int main () { constexpr auto result = make_string(make_data(\"hello world,\", 3)) ; std::cout &lt;&lt; std::string_view(result.first.begin(), result.first.begin() + result.second) &lt;&lt; std::endl ; return 0 ;} 影片中是用一個struct來記array與size，我這裡換成了一個pair，雖然不用call兩遍了，但記憶體浪費的問題還是一樣沒有改變，我們得再繼續想想辦法 接下來該怎麼辦? 做到這邊，相信大家也跟我一樣想著要是能直接寫一個constexpr std::string，就直接全劇終了，根本不會有這麼多破事 有一個很讚的方法是，用一個workaround去繞他 1234567891011121314151617181920212223242526272829constexpr auto make_data(std::string_view base, const int repeat) { std::string retval; for (int times = 0 ; times &lt; repeat ; ++times) retval += base ; return retval ;}template &lt;typename Callable&gt;consteval auto make_string(Callable callable) { // constexpr auto str = callable() ; std::string str = callable() ; auto buffer = std::array&lt;char, callable().size()&gt;{}; std::copy(str.begin(), str.end(), buffer.begin()); return buffer ;} // make_string()int main () { auto str_gen = []() { return make_data(\"hello world,\", 3); } ; constexpr static auto result = make_string(str_gen) ; std::cout &lt;&lt; result.size() &lt;&lt; std::endl ; std::cout &lt;&lt; std::string_view(result.begin(), result.end()) &lt;&lt; std::endl ; return 0 ;} 我們知道constexpr function裡頭的std::string只能存在於compile time，他無法逃脫這個function 另外，你從外面把string作為parameter傳進去，同樣也不會被當成constant expression 123456/*行不通的 兄Day*/consteval auto make_string(const std::string&amp; str) { auto buffer = std::array&lt;char, str.size()&gt;{}; // 卡在這一步 std::copy(str.begin(), str.end(), buffer.begin()); return buffer ;} // make_string() 但很神奇的，我們可以傳一個lambda進去，只要那個lambda本身能夠在compile time被evaluate，那一切就沒毛病 影片中，Jason Turner還是繼續用一個大array裝data，之後再做一次shrink，我有點搞不清楚他的用意，姑且我就一步做完了，只要我們不去直接return那個std::string我們就不會翻車 Cool，如此一來基本上問題就解得差不多了，唯一只剩下main裡頭我們還要自己把array轉string_view很惱人這點 聰明的小吉可能馬上就會說:那簡單，直接在function裡頭轉string_view出來就好 1234567891011121314151617181920template &lt;typename Callable&gt;consteval auto make_string(Callable callable) {// constexpr auto str = callable() ; std::string str = callable() ; auto buffer = std::array&lt;char, callable().size()&gt;{}; std::copy(str.begin(), str.end(), buffer.begin()); return std::string_view(buffer.begin(), buffer.end()) ;} // make_string()int main (int argc, char* argv[]) { auto str_gen = []() { return make_data(\"hello world,\", 3); } ; constexpr static auto result = make_string(str_gen) ; std::cout &lt;&lt; result.size() &lt;&lt; std::endl ; std::cout &lt;&lt; result &lt;&lt; std::endl ; return 0 ;} 很可惜的，並不能這樣，抱歉惹洨吉QQ 問題出在於轉string_view的行為相當於要實體化本來只在compile time會出現的資料 要注意make_string()的範圍內都還是compile time的範圍，此時沒有任何一個物件存在 一直到main裡頭的constexpr static auto result = make_string(str_gen)我們的string data才會真的現身 那不就無解了? 仔細想想，之所以不能把buffer轉成string_view，是因為buffer在make_string()中並不存在實體(他是一個complie time的資源) 假設buffer是一個static array的話呢? constexpr function裡頭寫static一直到C++23才會出來，現階段還是沒有實作好的..... 那不就無解了!? make_static的奧秘 現在就差最後一部，我們必須要想點辦法變出一個static array出來，這時就要來隆重介紹此影片最精華，最魔幻，最庸人自擾(?)的手法，make_static() 12345678910111213141516template &lt;auto DATA&gt;consteval const auto&amp; make_static() { return DATA;}constexpr auto make_array(auto callable) { std::string str = callable(); auto buffer = std::array&lt;char, callable().size()&gt;{}; std::copy(str.begin(), str.end(), buffer.begin()); return buffer ;}consteval auto make_string(auto callable) { constexpr auto&amp; static_buf = make_static&lt;make_array(callable)&gt;() ; return std::string_view{static_buf.begin(), static_buf.end()} ;} // make_string() 對，真的就這樣 根據C++標準，非型別樣版參數（Non-Type Template Argument）具有static storage duration的特性 我們真的把static array變出來了，來看看asm出來什麼 12345template parameter object for std::array&lt;char, 36ul&gt;{char [36]{(char)104, (char)101, (char)108, (char)108, (char)111, (char)32, (char)119, (char)111, (char)114, (char)108, (char)100, (char)44, (char)104, (char)101, (char)108, (char)108, (char)111, (char)32, (char)119, (char)111, (char)114, (char)108, (char)100, (char)44, (char)104, (char)101, (char)108, (char)108, (char)111, (char)32, (char)119, (char)111, (char)114, (char)108, (char)100, (char)44}}: .ascii \"hello world,hello world,hello world,\"main::result: .quad 36 .quad template parameter object for std::array&lt;char, 36ul&gt;{char [36]{(char)104, (char)101, (char)108, (char)108, (char)111, (char)32, (char)119, (char)111, (char)114, (char)108, (char)100, (char)44, (char)104, (char)101, (char)108, (char)108, (char)111, (char)32, (char)119, (char)111, (char)114, (char)108, (char)100, (char)44, (char)104, (char)101, (char)108, (char)108, (char)111, (char)32, (char)119, (char)111, (char)114, (char)108, (char)100, (char)44}} 我們可以看到string data好好的變成了ascii string，太棒了! 重點是，即便我們用同樣的手法再搞一個main::result2，binary裡頭依然只會有一個template parameter object，不用擔心重複問題 而且現在我們有一個高彈性的手段，在compile time下產生字串了 完整的Code在這裡 參考資料 Stop Using constexpr (And Use This Instead!) 如果你不知道constexpr static是什麼咚咚的話可以先看看 Compiler support Template non-type arguments 小結 太魔幻了八，不對，C++你要是有實作好我們那需要這樣?","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://ggorz10227216.github.io/tags/c/"},{"name":"cpp weekly note","slug":"cpp-weekly-note","permalink":"https://ggorz10227216.github.io/tags/cpp-weekly-note/"}]},{"title":"C++在編譯期做出多重型別物件","slug":"compile-time-multi-type","date":"2022-08-09T09:18:03.000Z","updated":"2022-08-09T15:53:36.247Z","comments":true,"path":"compile-time-multi-type/","link":"","permalink":"https://ggorz10227216.github.io/compile-time-multi-type/","excerpt":"詳細的解說如何在編譯期做出一個具有多重型別的物件 神偷小吉從在S社工作的朋友K那裡幹來的程式碼","text":"詳細的解說如何在編譯期做出一個具有多重型別的物件 神偷小吉從在S社工作的朋友K那裡幹來的程式碼 Code在此，本文要來一步一步拆解這段code在幹嘛 123456789let i = 11;let b = false;let s = std::string{\"oh yes\"};let v = Multi{ [&amp;] { return i; }, [&amp;] { return b; }, [&amp;] { return s; },}; 首先我們可以看到本文主角Multi，一個神祕物件，初始化的時候吃了一個塞了三個不同return type的lambda的initialize list let的定義是#define let const auto 這個Multi是何方神聖? 12345678910111213template &lt;typename T&gt;struct To { template &lt;typename F&gt; To(F f) : f(std::move(f)) {} operator T() const { return f(); }; private: const std::function&lt;T()&gt; f;};template &lt;typename... Ts&gt;struct Multi : public To&lt;Ts&gt;... {}; Multi是一個struct，繼承了To 等等，這個如同財哥專業檳榔的繼承是怎麼回事? Keyword: variadic template 我們來看個範例 123456789101112131415161718192021struct A {};struct B { };struct C { };template &lt;typename... Ts&gt;struct Multi : public Ts... {};int main() { Multi&lt;A, B, C&gt; m ; return 0 ;} 基本上Ts...表示你可以給很多個type，他會幫你自動補上\",\"，like this 1234template&lt;&gt;struct Multi&lt;A, B, C&gt; : public A, public B, public C{}; 所以struct Multi : public To&lt;Ts&gt;...被轉換成了 struct Multi : public To&lt;Ts#1&gt;, To&lt;Ts#2&gt;, ...... 在這個例子中，Ts#n這些東西會變成什麼? struct Multi: public To&lt;lambda#A&gt;, To&lt;lambda#B&gt;嗎? 仔細看看To內部 12345template &lt;typename T&gt; struct To { // ... operator T() const { return f(); }; // ... T是一個return type，看起來絕對不會是lambda 中間似乎差了一個步驟......? User-defined deduction guides 我們仔細看一下有一段code 12template &lt;typename... Ts&gt;Multi(Ts...) -&gt; Multi&lt;std::invoke_result_t&lt;Ts&gt;...&gt;; 這到底是什麼東西? function prototype? 非也! 這個可是C++17的新特性Class template argument deduction (CTAD) 其中的一個概念:User-defined deduction guides 人為的去教compiler如何實例化你的type 所以上面那段code是什麼意思? 這段code的意思是如果今天出現了一個type Multi(Ts#1, Ts#2, ......)，我們會引導compiler把它變成 12345Multi&lt; std::invoke_result_t&lt;Ts#1&gt;, std::invoke_result_t&lt;Ts#2&gt;, ...&gt; invoke_result_t會在compile tile推導callable的return type 統整一下上面所述，整個轉換的流程為(對應我們範例程式碼的行數) const auto v = Multi { lambda, lambda, lambda } ; [30.] Multi(lambda, lambda, lambda) -&gt; Multi&lt;std::invoke_result_t, std::invoke_result_t, std::invoke_result_t&gt; [23.] Multi(lambda, lambda, lambda) -&gt; Multi&lt;int, bool, std::string&gt;[23.] Multi&lt;int, bool, std::string&gt; -&gt; struct Multi : public To&lt;int&gt;, To&lt;bool&gt;, To&lt;std::string&gt;[20.] 接下來情況就很明朗了，我們得到了一個有多重繼承的物件，最後就是看static_cast&lt;&gt;轉成誰，就會變成誰，Magic! 延伸閱讀 Class template argument deduction (CTAD) TJSW大師的好讀版 Parameter pack 比較多範例的版本 小結 我說完了，我說 完了","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://ggorz10227216.github.io/tags/C/"},{"name":"CTAD","slug":"CTAD","permalink":"https://ggorz10227216.github.io/tags/CTAD/"},{"name":"Variadic template","slug":"Variadic-template","permalink":"https://ggorz10227216.github.io/tags/Variadic-template/"}]},{"title":"Stop Using `constexpr` (And Use This Instead!)","slug":"constexpr-1","date":"2022-08-08T18:14:31.000Z","updated":"2022-08-09T09:35:09.908Z","comments":true,"path":"constexpr-1/","link":"","permalink":"https://ggorz10227216.github.io/constexpr-1/","excerpt":"這標題，真的很clickbait..... 這份筆記會針對constexpr與編譯期初始化的關聯做說明","text":"這標題，真的很clickbait..... 這份筆記會針對constexpr與編譯期初始化的關聯做說明 constexpr，一般來說會用在標示某個變數需要於編譯期(compile time)就完成初始化 12345678int get_val(int i) { return i*2;}int main() { int value = get_val(2) ; return value ;} 讓我們來看一看這個很簡單的範例出來的asm(x86_64 gcc -O0) 123456789101112131415161718get_val(int): push rbp mov rbp, rsp mov DWORD PTR [rbp-4], edi mov eax, DWORD PTR [rbp-4] add eax, eax pop rbp retmain: push rbp mov rbp, rsp sub rsp, 16 mov edi, 2 call get_val(int) mov DWORD PTR [rbp-4], eax mov eax, DWORD PTR [rbp-4] leave ret 基本上就是很老實地把數值算出來，但是如果啟用最佳化又會是什麼情況(x86_64 gcc -O3) 123456get_val(int): lea eax, [rdi+rdi] retmain: mov eax, 4 ret 數值直接在編譯的時候算出來，寫進code了 在影片裡頭提到constexpr到底會不會被編譯期初始化這一點永遠是不確定的，他會受到最佳化等級還有編譯器本身的影響 我自己的經驗是，多半都會，唯一你必須要確保你有加上constexpr 123456789101112131415#include &lt;array&gt;constexpr std::array&lt;int, 100&gt; get_val() {std::array&lt;int, 100&gt; result{}; for (int n = 0 ; n &lt; result.size() ; ++n) { result[ n ] = n ; } // for return result;}int main() { constexpr auto value = get_val()[45] ; return value ;} 此範例中的value，無論最佳化等級開多少，都會是編譯期求解 我們現在要來進一步探討constexpr variable的storage duration，我把影片中的例子人肉OCR出來了 here 看似沒什麼問題的程式碼，居然觸發了ASAN，到底是怎麼回事? 我們前面提到constexpr會讓變數在編譯期初始化但我們仔細看一下asm(in main()，為了簡潔我把ASAN關掉了) 1234lea rdi, [rbp - 4016]movabs rsi, offset .L__const.main.valuesmov edx, 4000call memcpy@PLT 驚人的事實是，array本身的確是constexpr，但是我們用了另外一個指標p去取他的值 然後還在scope裏頭，這下可好，p會指向我們從executable搬到stack上的array 你是不是發現了，即便宣告成constexpr，但她的storage duration依然不是static，這個constexpr的array居然是automatic(我指它的storage duration) 這個程式在-O3的時候，最佳化直接編譯求值了，所以不會被ASAN抓到 但是在-O0的時候我們有去做搬移的動作，然後就華麗的爆炸 所以結論是，我們原本所想的constexpr跟實際上的constexpr是有差異的 最接近我們所想的應該是static constexpr，我們把先前的範例改一改 在constexpr前加上static，你就會看到剛剛提到的那個搬移動作不見了 因為現在values的storage duration是static 我的老天鵝阿 延伸閱讀 Storage class specifiers constexpr specifier","categories":[],"tags":[{"name":"cpp_weekly_note","slug":"cpp-weekly-note","permalink":"https://ggorz10227216.github.io/tags/cpp-weekly-note/"},{"name":"c++","slug":"c","permalink":"https://ggorz10227216.github.io/tags/c/"}]},{"title":"Orthogonality","slug":"orthogonality","date":"2022-08-07T07:42:03.000Z","updated":"2022-08-08T02:10:34.023Z","comments":true,"path":"orthogonality/","link":"","permalink":"https://ggorz10227216.github.io/orthogonality/","excerpt":"有關於正交的一些筆記，放在這裡以備不時之需","text":"有關於正交的一些筆記，放在這裡以備不時之需 Orthogonal vector &amp; subspace Inner Product given two vector , , we can say the inner product of x, y is: Since is a scalar, that means The length of vector x = Orthogonal vecotrs x &amp; y are orthogonal iff recall Pythagoras theorem Orthogonal subspace Suppose &amp; are subspaces in &amp; are orthogonal if for every in , in Orthogonal complement Suppose is a subspace in The orthogonal complement of () is the set of all vecotrs orthogonal to Orthogonal subspaces of four subspace of , , 假設有一個向量，且，則 , ( in , in ) 對於所有在中的向量，在中只有唯一一個能夠滿足 我們可以假設還有另一個在中的向量滿足條件 也就是說，, 但同時 一個向量要同時存在於列空間與零空間只有一個可能 他自己是零向量 結論， Projection Projection onto a line find the vector on the line through , where is minimum Let's say 因為我們要找能夠產生最短長度的，上面那個長度方程式又剛好是二次方程式 最小值會在微分之後，斜率為零的位置 從上面的結論可以看出 p的長度只與跟夾角有關 整理一下式子 ()裡頭的是純量，但是[]裏頭的會是一個矩陣，我們給這個矩陣一個名字 的幾點性質 is another projection matrix, 假設現在，另有一向量，我們要找一向量，使得與距離最短 最短距離代表 is n by n, ，換言之對稱 if , let, But is also in ,因為y是A的線性組合 ， 講這麼多，我們只是要證明是full rank，可逆! projected vector projection matrix , , , ，只要滿足這兩個條件的矩陣就是投影矩陣 ，因為是的線性組合 Least-squares approximations A is (m is usually greater than n in pratice) has solutions if b in otherwise, the error vector We need to find s.t. is minimum is called the least squares solution We know that The normal equation: 如果無解 就代表b並不在中 但我們可以用投影(利用投影矩陣)的投過去，找到一個向量 也就是說 我們的誤差向量，重點是，因為我們希望要最小! 想像一下的正交互補空間是誰? ，所以我們的其實就在裡面 回想一下前面講的，所以 所以我們現在的等式變成 is our least squares solution Orthogonal matrices Orthonormal vectors The set of vecotrs is orthonormal if: Orthogonal matirces An orthogonal matrix is square and has orthonormal columns, such that: for example: Reflection matrix u到底是啥? 鏡射軸的法向量! 假設今天我們要對一個正交矩陣求解 The projected vecotr note only if Q is square The projection matrix is 檢查一下有沒有滿足投影矩陣的定義 P^T=P 有滿足 Gram-Schmidt process Suppose we have some vectors in ，and these vectors are linear independent we want to make these vectors orthonormal，is it possible? yes, by Gram-Schmidt process , is orthogonal and is our goal - orthonormal 先來看，我們鎖定作為，然後將投影到上，藉此來找出與垂直的, 我們可以整理一下計算的式子，因為跟都是純量，我們把它提出來 現在我們有兩個相互垂直的，接著處理 我們要把投影到上 因此我們的投影矩陣為: 所以 整理一下我們會得到通用式 用剛剛用過的那個抽出純量那招，我們可以得出一個結論 就是的線性組合 最後再把除上它的長度就會得到 經過Gram-Schmidt之後，我們有了就可以瘋狂內積求解了 還記得嗎? 我們剛剛有提到，是一個的線性組合 u跟q只有長度不一樣，換言之 這咚咚叫做QR factorization，也就是說 R is nn，and可逆 Least-squares solution 噫!又是你 前情提要，我們想解，但發現解不開，於是改找近似 error vector 與A裡面的所有向量垂直時，誤差最小 現在Gram-Schmidt超人幫你把A轉好了 ，謝謝你我D超人 R是上三角矩陣，可逆，所以我們消去，最後得到 ，因為R是上三角矩陣，所以超級好解開","categories":[],"tags":[{"name":"linear Algebra","slug":"linear-Algebra","permalink":"https://ggorz10227216.github.io/tags/linear-Algebra/"},{"name":"math","slug":"math","permalink":"https://ggorz10227216.github.io/tags/math/"}]},{"title":"Lambda vs std::function vs Function Pointer","slug":"cpp-callable-compare","date":"2022-08-06T13:44:14.000Z","updated":"2022-08-06T14:15:10.657Z","comments":true,"path":"cpp-callable-compare/","link":"","permalink":"https://ggorz10227216.github.io/cpp-callable-compare/","excerpt":"本文為C++ Weekly Ep 332的note","text":"本文為C++ Weekly Ep 332的note 這次我們要來看C++下三種傳遞function的方法: 1. function pointer 2. lambda 3. std::function function pointer 從原古C語言時代就存在的傳遞手段，基本上就是把function所在的address存起來，要呼叫的時候直接跳過去，我們來看個code: 12345678910// Type your code here, or load an example.int square(int num) { return num * num;}int main() { int (*func)(int) = square ; func(12) ; return 0 ;} // main() 上面的程式展示了最基本的function pointer使用方法，我們再進一步來看出來的asm長怎樣: 123456789101112131415161718192021square(int): # @square(int) push rbp mov rbp, rsp mov dword ptr [rbp - 4], edi mov eax, dword ptr [rbp - 4] imul eax, dword ptr [rbp - 4] pop rbp retmain: # @main push rbp mov rbp, rsp sub rsp, 16 mov dword ptr [rbp - 4], 0 movabs rax, offset square(int) mov qword ptr [rbp - 16], rax mov edi, 12 call qword ptr [rbp - 16] xor eax, eax add rsp, 16 pop rbp ret 上面的程式我為了方便說明原理，使用-O0編譯，我們不難看出function pointer的行為其實很簡單: 把square()的address放進rax 再放進[rbp - 16] call [rbp - 16] Cool, 基本上這就是最簡單的型態了，我們接著再來看看lambda會讓問題變複雜多少 lambda lambda是C++11引入的新功能，我們可以把它想像成一種匿名函數(Anonymous Function)，而且最酷的是lambda可以做到capture，不過我們先來看一個最基礎的lambda: 12345678int main() { auto func = [](int num) { return num*num; } ; func(12) ; return 0 ;} // main() 不過想要搞清楚到底發生了什麼，我們可以先從cpp insight的輸出開始看起: 12345678910111213141516171819202122232425int main() { class __lambda_2_17 { public: inline /*constexpr */ int operator()(int num) const { return num * num; } using retType_2_17 = int (*)(int); inline constexpr operator retType_2_17 () const noexcept { return __invoke; }; private: static inline /*constexpr */ int __invoke(int num) { return __lambda_2_17{}.operator()(num); } public: // /*constexpr */ __lambda_2_17() = default; }; __lambda_2_17 func = __lambda_2_17{}; func.operator()(12); return 0;} // main() 我們可以發現一件很酷的事情，lambda實際上是被轉換成一個class，我們去call一個lambda實際上是兩個步驟: 先宣告一個lambda物件func 去呼叫func的method \"operator()\" OK, 那實際上出來的asm會長怎樣? 123456789101112131415161718192021main: # @main push rbp mov rbp, rsp sub rsp, 16 mov dword ptr [rbp - 4], 0 lea rdi, [rbp - 8] mov esi, 12 call main::$_0::operator()(int) const xor eax, eax add rsp, 16 pop rbp retmain::$_0::operator()(int) const: # @\"main::$_0::operator()(int) const\" push rbp mov rbp, rsp mov qword ptr [rbp - 8], rdi mov dword ptr [rbp - 12], esi mov eax, dword ptr [rbp - 12] imul eax, dword ptr [rbp - 12] pop rbp ret 看起來與function pointer版本差不多，但這是因為我們沒有使用到capture的原因，那用了會怎樣? 我們來稍微修改一下lambda的內容 12345678910int main() { int num = 12 ; auto func = [&amp;]() { num += 1 ; return num*num; } ; func() ; return num ;} // main() 然後再看看出來的asm長怎樣: 1234567891011121314151617181920212223242526272829main: # @main push rbp mov rbp, rsp sub rsp, 16 mov dword ptr [rbp - 4], 0 mov dword ptr [rbp - 8], 12 lea rax, [rbp - 8] mov qword ptr [rbp - 16], rax lea rdi, [rbp - 16] call main::$_0::operator()() const mov eax, dword ptr [rbp - 8] add rsp, 16 pop rbp ret main::$_0::operator()() const: # @\"main::$_0::operator()() const\" push rbp mov rbp, rsp mov qword ptr [rbp - 8], rdi mov rcx, qword ptr [rbp - 8] mov rax, qword ptr [rcx] mov edx, dword ptr [rax] add edx, 1 mov dword ptr [rax], edx mov rax, qword ptr [rcx] mov eax, dword ptr [rax] mov rcx, qword ptr [rcx] imul eax, dword ptr [rcx] pop rbp ret 仔細看(8.)的mov，之所以會多出這一道指令是因為capture的實現方式是這樣的，我們來看cpp insight: 12345678910111213141516171819202122int main() {int num = 12; class __lambda_3_17 { public: inline /*constexpr */ int operator()() const { return num * num; } private: int &amp; num; // &lt;&lt; HERE! public: __lambda_3_17(int &amp; _num) : num{_num} // AND HERE! {} }; __lambda_3_17 func = __lambda_3_17{num}; func.operator()(); return 0;} // main() 原來capture是透過class member variable實現的，所以才會多出一個mov指令 另外，一個沒有capture的lambda是可以被隱式轉型成function pointer的，見以下範例: 1234567891011121314151617int main() { int (*fptr)(int) = nullptr ; auto func = [](int num) { num += 1 ; return num*num; } ; auto func_cap = [&amp;](int num) { num += 1 ; return num*num; } ; fptr = func ; // OK fptr = func_cap; // ERROR: cannot convert 'main()::&lt;lambda(int)&gt;' to 'int (*)(int)' in assignment return func(1) ;} // main() std::function std::function與上面提到的兩個東西有一個根本上的不同，std::function是一個function wrapper，實現原理可參見A Simplified std::function Implementation，這裡要提的是std::function可以包裝上面的兩個東西之外，任何具有operator()的牛鬼蛇神都可以包，為程式開發提供了極大的彈性 But, 如果我們沒有給std::function綁定一個callable就直接call他會怎樣? 123456789101112#include &lt;functional&gt;int main() { std::function&lt;int (int)&gt; func; auto numnum = [](int num) { num += 1 ; return num*num; } ; return func(1) ;} // main() 執行結果是直接拋出例外: terminate called after throwing an instance of 'std::bad_function_call' what(): bad_function_call 為了提供開發彈性，std::function背地裡做了很多......非常多的努力 確保你提供的callable的return type與std::function預期的相同 確保你提供的callable不會遇到生命週期的問題 根據實作的不同，有可能是把你的callable直接複製一份到heap上...... 可能比較厲害一點的實作會動用到SOO(small object optimization) 那到底用不用? 有需要就用，好比說...... 你在寫一個遊戲引擎，你需要用std::function來存你的script engine產生出的function(lua:叫我嗎?) 我要塞function進去container(vector, stack, std::array.....) 各種彈性 &gt; 效能的場景 延伸閱讀 First-class function What is the performance overhead of std::function? 結語","categories":[],"tags":[{"name":"cpp_weekly_note","slug":"cpp-weekly-note","permalink":"https://ggorz10227216.github.io/tags/cpp-weekly-note/"},{"name":"c++","slug":"c","permalink":"https://ggorz10227216.github.io/tags/c/"}]},{"title":"A Simplified std::function Implementation","slug":"simple-std-function","date":"2022-08-06T13:35:02.000Z","updated":"2022-08-06T14:12:42.380Z","comments":true,"path":"simple-std-function/","link":"","permalink":"https://ggorz10227216.github.io/simple-std-function/","excerpt":"本文為C++ Weekly Ep 333的note","text":"本文為C++ Weekly Ep 333的note 首先先來看code: - Compiler Explorer 這次的目標是要土炮一個精神上與std::function差不多的function class，就如同裏頭的std::function一樣，可以把任何callable都包起來 OK，讓我們一步一步來看這段code Primary template 首先我們必須先定義Primary template，後面會對function做partial template specialization 12template &lt;typename T&gt;class function; 也就是說一開始的typename T，在之後會被specialization成callable obj的type(好比說int (int,int)) class function 再來是我們的function物件 12345678910111213template &lt;typename Ret, typename ... Param&gt; class function&lt;Ret (Param...)&gt;{ public: template&lt;typename FunctionObject&gt; function(FunctionObject fo) : callable(std::make_unique&lt;callable_impl&lt;FunctionObject&gt;(std::move(fo))) {} Ret operator()(Param... param) {return callable-&gt;call(param...);} private: /*下面再講，這裡先不看*/ std::unique_ptr&lt;callable_interface&gt; callable ;}; 我們可以看到Ret (Param...)會被展開成int (int, int)，我們寫在main裏頭的: 12function&lt;int (int, int)&gt; func{f};// ^here typename FunctionObject會被換成你傳進去的callable object的type()，然後用你給的fo去初始化那個unique_ptr(為什麼要用unique_ptr等等會講) callable_interface &amp; callable_impl 然後整個class function最精華的地方來了，我們先定義一個pure virtual(又稱interface) callable_interface作為我們的base 123456789101112struct callable_interface { virtual Ret call(Param...) = 0; virtual ~callable_interface() = default;};template &lt;typename Callable&gt;struct callable_impl : callable_interface { callable_impl(Callable callable_) : callable(std::move(callable_)){} Ret call(Param... param) { return std::invoke(callable, param...);} Callable callable;}; 接下來讓callable_impl去繼承callable_interface，使其變成callable_interface的derived class，現在讓我們注意callable_impl的call()，讓我們來看一下cpp_insight的輸出 123456789101112131415161718192021222324252627282930313233343536373839404142template&lt;typename Callable&gt;struct callable_impl;/* First instantiated from: type_traits:1392 */#ifdef INSIGHTS_USE_TEMPLATEtemplate&lt;&gt;struct callable_impl&lt;int (*)(int, int)&gt; : public callable_interface{ inline callable_impl(int (*callable_)(int, int)) : callable_interface() , callable{std::move(callable_)} { } inline virtual int call(int __param0, int __param1) { return std::invoke(this-&gt;callable, __param0, __param1); } int (*callable)(int, int); // inline virtual constexpr ~callable_impl() noexcept = default;};#endif/* First instantiated from: type_traits:1392 */#ifdef INSIGHTS_USE_TEMPLATEtemplate&lt;&gt;struct callable_impl&lt;__lambda_39_36&gt; : public callable_interface{ inline callable_impl(__lambda_39_36 callable_) : callable_interface() , callable{__lambda_39_36(std::move(callable_))} { } inline virtual int call(int __param0, int __param1) { return std::invoke(this-&gt;callable, __param0, __param1); } __lambda_39_36 callable; // inline virtual constexpr ~callable_impl() noexcept = default;}; 我們可以發現: struct callable_impl&lt;int (*)(int, int)&gt; struct callable_impl&lt;__lambda_39_36&gt; 編譯器幫我們生出了一個raw function pointer，一個lambda的callable_impl，又因為call()是一個virtual，然後我們還使用了unique_ptr來記錄實際callable_impl的 ptr(所以這些物件都在heap上，吃的到virtual table) 這就代表無論我的FunctionObject最後是什麼，只要他能夠被call，callable_impl裏頭的call()一定就能夠透過std::invoke()產生出正確的呼叫程式碼 至此整個function object的原理就說明完了 結語 你各位要hold住阿","categories":[],"tags":[{"name":"cpp_weekly_note","slug":"cpp-weekly-note","permalink":"https://ggorz10227216.github.io/tags/cpp-weekly-note/"},{"name":"c++","slug":"c","permalink":"https://ggorz10227216.github.io/tags/c/"}]},{"title":"boost::asio + boost::fiber之上下文切換機制","slug":"autoecho","date":"2022-08-05T17:25:20.000Z","updated":"2022-08-08T04:13:55.309Z","comments":true,"path":"autoecho/","link":"","permalink":"https://ggorz10227216.github.io/autoecho/","excerpt":"最近剛好在研究boost::asio，在研究官方範例的時候發現與fiber連動的code，感覺有點玄妙，來寫篇筆記","text":"最近剛好在研究boost::asio，在研究官方範例的時候發現與fiber連動的code，感覺有點玄妙，來寫篇筆記 Autoecho autoecho.cpp 這個範例基本上就是在同一個process內開一個tcp server跟數個client，client會發送一個字串給server，然後server會把該字串echo回去 乍看之下蠻無聊的，但關鍵是這個程式只有一條thread在工作，所有的concurrency都是靠fiber在做 萬事起頭難，我們先來很快地審視過main()在幹嘛 1234567891011121314151617181920212223242526272829303132int main( int argc, char* argv[]) { try {//[asio_rr_setup std::shared_ptr&lt; boost::asio::io_context &gt; io_ctx = std::make_shared&lt; boost::asio::io_context &gt;(); boost::fibers::use_scheduling_algorithm&lt; boost::fibers::asio::round_robin &gt;( io_ctx);//] print( \"Thread \", thread_names.lookup(), \": started\");//[asio_rr_launch_fibers // server tcp::acceptor a( * io_ctx, tcp::endpoint( tcp::v4(), 9999) ); boost::fibers::fiber( server, io_ctx, std::ref( a) ).detach(); // client const unsigned iterations = 2; const unsigned clients = 3; boost::fibers::barrier b( clients); for ( unsigned i = 0; i &lt; clients; ++i) { boost::fibers::fiber( client, io_ctx, std::ref( a), std::ref( b), iterations).detach(); }//]//[asio_rr_run io_ctx-&gt;run();//] print( tag(), \": io_context returned\"); print( \"Thread \", thread_names.lookup(), \": stopping\"); std::cout &lt;&lt; \"done.\" &lt;&lt; std::endl; return EXIT_SUCCESS; } catch ( std::exception const&amp; e) { print(\"Exception: \", e.what(), \"\\n\"); } return EXIT_FAILURE;} 一開始先初始化io_context與設定fiber排成所用的algo為round robin，這沒有太大的問題 再來是把server fiber跟client fiber都建立好，detach()出來 最後是io_ctx-&gt;run()讓目前主fiber把執行權讓出來，排程器就會抓剛剛排入的fiber出來跑 async_something()的奧秘 我們可以從server()來切入問題 123456789101112131415161718192021void server( std::shared_ptr&lt; boost::asio::io_context &gt; const&amp; io_ctx, tcp::acceptor &amp; a) { print( tag(), \": echo-server started\"); try { for (;;) { socket_ptr socket( new tcp::socket( * io_ctx) ); boost::system::error_code ec; a.async_accept( * socket, boost::fibers::asio::yield[ec]); if ( ec) { throw boost::system::system_error( ec); //some other error } else { boost::fibers::fiber( session, socket).detach(); } } } catch ( std::exception const&amp; ex) { print( tag(), \": caught exception : \", ex.what()); } io_ctx-&gt;stop(); print( tag(), \": echo-server stopped\");} 我們的server fiber實體長這樣，但實際上只有做一個accept()動作而已 所以server()幹了啥? 使用我們在main裏頭準備好的acceptor a去等待client的連線，async_accept() 喔齁!? 來看一下async_accept()的signature，看看他是何方神聖 12345678template&lt; typename Protocol1, typename Executor1, typename AcceptToken = DEFAULT&gt;DEDUCED async_accept( basic_socket&lt; Protocol1, Executor1 &gt; &amp; peer, AcceptToken &amp;&amp; token = DEFAULT, typename constraint&lt; is_convertible&lt; Protocol, Protocol1 &gt;::value &gt;::type = 0); 所以async_accept()要一個socket跟一個AcceptToken socket沒問題，重點是那個AcceptToken到底是什麼咚咚? 簡單來說AcceptToken可以是一個callable，在未來的某一個時間點真的accept到東西的時候，接收來自kernel的error code來做後續處理 就是async_accept()的callback拉 但很顯然的，這個例子不是這樣 1a.async_accept(* socket, boost::fibers::asio::yield[ec]); 媽的貢丸，boost::fibers::asio::yield[ec]是啥玩意? 持續trace code，找到其定義 123456789101112131415161718namespace boost {namespace fibers {namespace asio { class yield_t { public: yield_t() = default; yield_t operator[]( boost::system::error_code &amp; ec) const { yield_t tmp; tmp.ec_ = &amp; ec; return tmp; } boost::system::error_code * ec_{ nullptr }; };thread_local yield_t yield{};}}} 好樣的，我們觸發了他的operator[]，具體只是把我們server()中的ec的addr綁到位於thread_local的yield上 然後作為AcceptToken傳遞給async_accept()，我的老天鵝，yield_t又沒有operator()，到底是怎麼樣變出callback的? 讓我們繼續往更深層跳...... 我們一路step in，會看到一個關鍵位置 1234567891011typedef typename boost::asio::async_result&lt; typename decay&lt;CompletionToken&gt;::type, Signature&gt;::completion_handler_type completion_handler_type; /*一些其他的code*/ explicit async_completion(CompletionToken&amp; token) : completion_handler(static_cast&lt;typename conditional&lt; is_same&lt;CompletionToken, completion_handler_type&gt;::value, completion_handler_type&amp;, CompletionToken&amp;&amp;&gt;::type&gt;(token)), result(completion_handler) { } 哇，酷喔，因為我們給的AcceptToken是yield_t，導致上面的completion_handler_type被推導成async_result&lt; boost::fibers::asio::yield_t, void(boost::system::error_code) &gt;::completion_handler_type 還真的有一個partial specialization長這樣 12345678910template&lt;&gt;class async_result&lt; boost::fibers::asio::yield_t, void(boost::system::error_code) &gt; : public boost::fibers::asio::detail::async_result_base { public: using return_type = void; using completion_handler_type = fibers::asio::detail::yield_handler&lt;void&gt;; explicit async_result( boost::fibers::asio::detail::yield_handler&lt; void &gt; &amp; h): boost::fibers::asio::detail::async_result_base{ h } {}}; 你，看到了嗎.....?那個潛伏在陰暗角落，蠢蠢欲動的completion_handler_type 講了那麼多，最後發現傳入yield_t之後，completion_handler最後會初始化成一個yield_handler 這個咚咚可就厲害了，它可是有operator()的!! 但不要忘記，他還有個base class，一樣也有一個operator() 先來看一下yield_handler的operator() 12345678void operator()(boost::system::error_code const&amp; ec, T t) { BOOST_ASSERT_MSG( value_, \"Must inject value ptr \" \"before caling yield_handler&lt;T&gt;::operator()()\"); * value_ = std::move( t); yield_handler_base::operator()(ec);} 我們可以看到value_(就是我們的socket)，會被assign t，這個t就是當async_accept()完成之後會得到的socket 接下來就會繼續call yield_handler_base的operator() 所以我們現在知道，AcceptToken給yield_t，最後async_accept()完事之後會呼叫的callback來自這裡 我們接著來看yield_handler_base的operator()做了啥? 12345678910111213141516171819202122232425262728293031class yield_handler_base { public: yield_handler_base( yield_t const&amp; y) : ctx_{ boost::fibers::context::active() }, yt_( y ) {} void operator()( boost::system::error_code const&amp; ec) { BOOST_ASSERT_MSG( ycomp_, \"Must inject yield_completion* \" \"before calling yield_handler_base::operator()()\"); BOOST_ASSERT_MSG( yt_.ec_, \"Must inject boost::system::error_code* \" \"before calling yield_handler_base::operator()()\"); yield_completion::lock_t lk{ ycomp_-&gt;mtx_ }; yield_completion::state_t state = ycomp_-&gt;state_; ycomp_-&gt;state_ = yield_completion::complete; * yt_.ec_ = ec; lk.unlock(); if ( yield_completion::waiting == state) { // wake the fiber fibers::context::active()-&gt;schedule( ctx_); } } boost::fibers::context * ctx_; yield_t yt_; yield_completion::ptr_t ycomp_{};}; 兩個重點 * yt_.ec_ = ec;會把真正的error code寫回我們給的yield_t yield_completion::waiting == state如果我們的server fiber在async_accept()之後沒有馬上就accept到連線(正常來說都是這樣)，那麼這個state就會是waiting，我們此時就會把server fiber的context排進排程裏頭，讓他盡快被跑起來 跑起來之後就會把已經accept的socket交遊session fiber去執行工作 但還有一個問題，我們在呼叫async_accept()之後，在我們正式accept到連線之前的這段時間內，執行權在誰手上 async_開頭的function都是non-blocking的，所以不會卡在原地 但看起來也不像是回到server fiber...... 我們可以在往下看，我們的async_accept()事實上背後接著一個async_initiate()，這個東西內部有一個玄機 12345678910111213141516171819template &lt;typename CompletionToken, BOOST_ASIO_COMPLETION_SIGNATURE Signature, typename Initiation, typename... Args&gt; inline typename enable_if&lt; !detail::async_result_has_initiate_memfn&lt;CompletionToken, Signature&gt;::value, BOOST_ASIO_INITFN_RESULT_TYPE(CompletionToken, Signature)&gt;::type async_initiate(BOOST_ASIO_MOVE_ARG(Initiation) initiation, BOOST_ASIO_NONDEDUCED_MOVE_ARG(CompletionToken) token, BOOST_ASIO_MOVE_ARG(Args)... args) { async_completion&lt;CompletionToken, Signature&gt; completion(token); BOOST_ASIO_MOVE_CAST(Initiation)(initiation)( BOOST_ASIO_MOVE_CAST(BOOST_ASIO_HANDLER_TYPE(CompletionToken, Signature))(completion.completion_handler), BOOST_ASIO_MOVE_CAST(Args)(args)...); return completion.result.get(); } 最後的那個completion.result.get()是關鍵，我們一個step進去看一看 123456789101112131415void get() { ycomp_-&gt;wait(); if ( ec_) { throw_exception( boost::system::system_error{ ec_ } ); }}/*再來直接看ycomp-&gt;wait()*/void wait() { lock_t lk{ mtx_ }; if ( complete != state_) { state_ = waiting; fibers::context::active()-&gt;suspend( lk); // !! }} 不看不知道，一看不得了，上面這段code說了啥? 假設我們呼叫get()的時候，ycomp的state不是complete(換言之，callback還沒有被跑過)，那基本上進去wait()就會觸發fibers::context::active()-&gt;suspend() 這個動作相當於是直接yield控制權，換言之，我們的async_accept()在呼叫後如果沒有馬上accept到連線的話，就會把控制權yield出來給其他fiber!! 一旦async_accept()讓出執行權後，在他完成之前，就會有其他的fiber被拉起來跑(client or session)，而當這兩個fiber各自也執行async action的時候，就會如同上面async_accept()一樣讓出執行權 如此我們就能只靠一條thread達到concurrency了 延伸閱讀 Then There’s Boost.Asio Boost.Asio overview Boost.fiber 愛麗絲與鮑伯 結論 想不到吧，Alice居然就是Bob!","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://ggorz10227216.github.io/tags/C/"},{"name":"networking","slug":"networking","permalink":"https://ggorz10227216.github.io/tags/networking/"},{"name":"Boost","slug":"Boost","permalink":"https://ggorz10227216.github.io/tags/Boost/"},{"name":"asynchronous_IO","slug":"asynchronous-IO","permalink":"https://ggorz10227216.github.io/tags/asynchronous-IO/"}]},{"title":"GBA圖形處理邏輯模擬(二) - Tile mode","slug":"Tile-mode","date":"2022-08-03T17:38:07.000Z","updated":"2022-08-03T17:54:44.088Z","comments":true,"path":"Tile-mode/","link":"","permalink":"https://ggorz10227216.github.io/Tile-mode/","excerpt":"cover 前文提到GBA的圖形繪製總共有兩種模式: Tile mode與Bitmap mode，這兩種繪圖模式雖然使用相同的記憶體區段但是工作原理大不相同，因此我們可以將其視為兩個獨立的邏輯分別開發 我們緊接著就要來探討GBA tile mode的基礎知識","text":"cover 前文提到GBA的圖形繪製總共有兩種模式: Tile mode與Bitmap mode，這兩種繪圖模式雖然使用相同的記憶體區段但是工作原理大不相同，因此我們可以將其視為兩個獨立的邏輯分別開發 我們緊接著就要來探討GBA tile mode的基礎知識 如何生成一幀畫面 背景與物件 先來看一個在Tile mode下繪製而成的遊戲畫面 Castlevania-Aria of sorrow, render by NO$GBA 畫面中所有看的到的東西基本上是由兩種東西疊合而成: 1. 背景(background, BG) 2. 物件(Object, OBJ) 他們之間的關係看起來會像是這樣: bg_and_sprite 你會注意到背景與物件各有四層圖層，我們可以將剛剛的遊戲畫面分層來看 BG_0 BG_1 BG_2 BG_3 OBJ(我疊合成一層了) Tile &amp; map 我們現在知道在Tile mode下，每一個畫面都是由背景跟物件所組成的了，那這些背景和物件又是如何被建構的呢? 要回答這個問題，我們必須從兩個方向來做分析: 用什麼東西組合 Tile mode下所有的東西基本上都是由Tile所組合而成的，我們這裡所說的tile，是一塊一塊由8*8個pixel所組成的圖形資料，類似這種(仔細看，這是骷髏騎士的劍柄) Tile的格式請參閱GBA圖形處理邏輯模擬 - Tile format 如何組合 另外一個需要釐清的問題是，我們該如何組合這些8*8的tile來產生我們想要的圖形，這就牽涉到我們現在是要繪製背景圖層還是物件，兩者的組合邏輯有些差異，詳細說明請參閱以下文章: GBA圖形處理邏輯模擬 - Background Map GBA圖形處理邏輯模擬 - Object Attribute Memory(OAM) Mode 0, Mode 1, Mode 2 Tile mode實質意義上指的是Mode 0, 1, 2這三個模式，因為這三種模式都使用tile建構畫面的基礎，因此統稱為tile mode 那這些mode有哪些特點呢，讓我們來仔細看一下這個表格: mode_table 根據表格，我們可以得知以下數點不同之處: 是否有支援Affine(Rotation &amp; Scaling)功能 詳細請參考GBA圖形處理邏輯模擬 - Affine background 最大可支援的Screen數量以及尺寸 詳細請參考GBA圖形處理邏輯模擬 - Background Map 最大可使用的Character(就是Tile)以及調色盤格式(palette) 詳細請參考GBA圖形處理邏輯模擬 - Tile format BG control register 前面有提到Tile mode下總共會有4層背景圖層，這四層圖層會受到當前的mode number影響，決定是否能夠被使用 layer_info text與rotation/scaling是? 如表格所示，BG0與BG1這兩個圖層僅支援Text mode 換言之就是沒有旋轉跟縮放的mode 而BG2與BG3則除了text mode之外，還可支援旋轉縮放 我會將rotation/scaling稱呼為affine 另外，這四層背景繪製時也會有一些可控的參數，描述如下，你可以依照下面給出的連結查閱他們的詳細資訊 bgcnt_info 對應四層圖層的register分別被mapping在(2 bytes each): BG0CNT(0x0400'0008) BG1CNT(0x0400'000A) BG2CNT(0x0400'000C) BG3CNT(0x0400'000E) 各欄位的詳細說明請參照: Priority Specification GBA圖形處理邏輯模擬 - Graphics effect(WIP) # blending Character Base Block GBA圖形處理邏輯模擬 - Tile format Mosaic GBA圖形處理邏輯模擬 - Graphics effect(WIP) #Mosaic Color Mode GBA圖形處理邏輯模擬 - Tile format Screen Base Block GBA圖形處理邏輯模擬 - Background Map Area Overflow Processing Flag 要注意這個flag對BG0與BG1無效 詳細請參考GBA圖形處理邏輯模擬 - Affine background Screen Size GBA圖形處理邏輯模擬 - Background Map","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"}]},{"title":"GBA圖形處理邏輯模擬 - Tile format","slug":"Tile-format","date":"2022-08-03T16:10:55.000Z","updated":"2022-08-03T16:14:58.355Z","comments":true,"path":"Tile-format/","link":"","permalink":"https://ggorz10227216.github.io/Tile-format/","excerpt":"cover 本文會專門針對GBA tile mode下所使用的tile format做詳細的說明","text":"cover 本文會專門針對GBA tile mode下所使用的tile format做詳細的說明 VRAM layout GBA的視訊記憶體VRAM總共有96KBytes，但是其中的佈局會根據當前的BG mode而有所改變，見下圖: 本系列文會以map data來稱呼任天堂官方手冊上的screen data，tile data稱呼character data 我們可以看到總共有四種不同的data: OBJ Character data 為存放組成obj所用的tile的記憶體位置，要注意的是tile mode下與bitmap mode下的OBJ tile area大小並不相同，這將會影響到最多能夠使用的tile數量 BG Screen data 描述一個背景圖層中所有tile的組成以及屬性，要注意此區域與BG tile共用，詳細規則見下方描述 BG Character data 存放組成BG圖層所用的tile的記憶體位置 Frame buffer bitmap mode下的繪製區域 VRAM layout under tile mode BG tile data以及BG map data在VRAM中的排列規則如下圖所述: tile_data_layout 我們可以看到除了OBJ tile data之外，BG的map data跟tile data是混在一起的，而每一個BG layer的tile data base address為 - 0x0600'0000 + BGXCNT中的Character base block欄位數值 0x4000 Tile data layout 讓我們使用一個8 8的tile來當作範例 tile_sample 這個tile的pixel在GBA中會有兩種可能的色彩表示方式: 16色模式 在這個模式下，1 byte可以表示2個pixel，也就是說每個pixel的palette color index範圍是種，而每個完整的tile為32 bytes 在此模式下可以透過修改Map data(或者是OAM)中的Color Palette field來實現調色盤切換，也就是各位十分熟悉的-2P色 256色模式 在此模式下，每一個pixel所佔的記憶體空間為1 byte，也就是說可以有 = 256種顏色，另外一個完整的tile為64 bytes 由於每一個pixel的color index都完全覆蓋住palette，因此不能夠調整palette number了 Palette memory 上面有提到tile data中存放的是color index，用於在調色盤(palette)中索引出正確的顏色，palette memory的特性如下: 位於0x0500'0000，共0x400(1024 bytes) 被分為兩部分，各512 bytes 前512 bytes為BG palette，bg tile data中的color index會對應到此 後512 bytes為OBJ palette, OBJ tile data的color index會對應到此 每一個顏色為2 bytes，故兩個palette都是512/2 = 256色，其色彩格式如下所述 Pixel format 眾所周知，如果你想要在電腦系統中顯示顏色，必定要利用一些格式來描述你最終顯示在螢幕上的每一個pixel的顏色，常見的格式有RGB、YUV、HSV等系統 而GBA所使用的色彩系統為RGB，讓我們從binary的角度來觀察每一個pixel的資料: pixel format 上圖很清楚地描述了GBA所使用的色彩格式，R、G、B是如何被儲存的，我們可以得出以下數點結論: 1. 每個顏色(我們叫他Color channel)的寬度為5bit，總共可以有種變化 2. 每個pixel為了記錄RGB，會消耗2 bytes的空間，並且最高位元是沒有作用的 3. 這種RGB各占5bit的格式有一個特殊的名字-BGR555 這裡一定要特別提，我沒有打錯!! 是BGR沒有錯 我們講RGB***指的是從MSB到LSB的排列方式為RGB，反之亦然 附上RGB565的示意圖以供參考 RGB565","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"}]},{"title":"GBA圖形處理邏輯模擬 - Background Map","slug":"Background-map","date":"2022-08-03T16:10:00.000Z","updated":"2022-08-05T18:03:37.190Z","comments":true,"path":"Background-map/","link":"","permalink":"https://ggorz10227216.github.io/Background-map/","excerpt":"cover GBA的VRAM中有數塊特殊的區域用來描述在一個BG中如何排列tile，我們將其稱呼為BG map memory，本文將會詳細說明其格式與特點","text":"cover GBA的VRAM中有數塊特殊的區域用來描述在一個BG中如何排列tile，我們將其稱呼為BG map memory，本文將會詳細說明其格式與特點 Map data format Map data內部紀錄了渲染一塊tile所需要知道的資訊，其格式根據BG為Text或者Affine會有所不同: Text BG 欄位功能描述如下: Character name 雖然叫做name，但實際上是一個offset，當你從BG_CNT上計算出tile block base之後，假設BG_CNT上標明這是一個4bpp tile，則此map data所對應的tile data的address為: base block addr + chara. name * 0x20(4bpp的一個完整tile size) 假若是8bpp，則tile data會位於 base block addr + chara. name * 0x40(8bpp的一個完整tile size) 有關tile data詳見GBA圖形處理邏輯模擬 - Tile format Affine BG 對，沒錯，真的就只有Character name，Affine BG的tile是強制256色的，考慮到Affine BG是利用仿射矩陣直接將screen pixel映射到map memory上，這樣的設計是最合理的 因為tile一定是0x40，所以tile data的位置算法就是8bpp算法 Horizontal flip flag 此tile在渲染時是否要左右顛倒，我這裡是直接將讀出來的tile data做inverse 考慮tile是4bpp的情況 12345678910111213if (xInverse) { // Swap the nibbles of each byte. buf = (buf &amp; 0x0F0F0F0F) &lt;&lt; 4 | (buf &amp; 0xF0F0F0F0) &gt;&gt; 4; // Swap the bytes of each byte pair. buf = (buf &amp; 0x00FF00FF) &lt;&lt; 8 | (buf &amp; 0xFF00FF00) &gt;&gt; 8; // Swap the byte pairs. buf = (buf &amp; 0x0000FFFF) &lt;&lt; 16 | (buf &amp; 0xFFFF0000) &gt;&gt; 16;} // if 8bpp會比較簡單 123456789if (xInverse) { // Swap the bytes of each byte pair. buf = (buf &amp; 0x00FF00FF) &lt;&lt; 8 | (buf &amp; 0xFF00FF00) &gt;&gt; 8; // Swap the byte pairs. buf = (buf &amp; 0x0000FFFF) &lt;&lt; 16 | (buf &amp; 0xFFFF0000) &gt;&gt; 16;} // if Vertical flip flag 此tile在渲染時是否要上下顛倒 Color palette 如果BG_CNT有聲明是4bpp，則最後tile在繪製時所參考的palette number就會是這個欄位所描述的 你可以把此欄位理解成row number，假設palette number是4，那tile就會變成全黑(因為tile 4所有16色都是黑色) Virtual screen Map memory基本上就是一塊由map data以二維排列而成的記憶體區塊，我們可以回顧一下這張表格: 其中我們可以注意到Character format BG screen下有一個size的欄位，裏頭描述幾種螢幕大小組合，但可以確定的是都與我們所知道的GBA螢幕大小240*160不同 這就是所謂的Virtual screen機制，我們可以把他想像成我們利用一個240*160的取景視窗，在一個很大的虛構區域內移動，接下來我們要來討論兩個重點: 虛構區域的大小 我們能夠移動的虛構區域大小是依靠BG_CNT中的Screen size控制的，其大小如下表所述: 圖表中明確提到了Text/Affine的狀態下，map data的尺寸與記憶體占用皆不同 如何移動可視範圍 我們在確認Virtual screen的大小後，下一步自然就是要把取景範圍移動到我們想要的地方，這一個步驟在Text BG與Affine BG下的操作方式並不相同: Text BG: 我們需要調整HOFS以及VOFS兩個register來移動取景範圍的左上角座標，如果這兩個暫存器的數值超過的virtual screen的尺寸的話，真正對應到的數值將會被 %screen size 不同的Screen size，移動時看起來會像是這樣 Affine BG:Affine模式下是直接依靠仿射矩陣來決定每一個螢幕上的pixel對應到的tile data，因此並不需要依靠HOFS以及VOFS，詳細請見GBA圖形處理邏輯模擬 - Affine background Address formula 最後附上一個Text BG計算某一個screen pixel，其所在的tile對應到那一個map data的計算公式: Physical screen X, Y = Sx, Sy Virtual Screen Width, Height = Vw, Vh Viewing area X = (Sx + HOFS) % Vw = S_vx, Viewing area Y = (Sy + VOFS) % Vh = S_vy Screen Base Block in BG_CNT = Sb map data address = 0x0600'0000 + (0x800 * Sb) + {((Vw / 8)*(S_vy / 8)) + (S_vx / 8)} * 2 每一個tile為8*8，所以S_v(x|y) / 8是為了把pixel XY轉換為tile XY 最後*2是因為Text BG每一個map data為2 bytes","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"}]},{"title":"GBA圖形處理邏輯模擬 - Affine background","slug":"Affine-background","date":"2022-08-03T16:08:15.000Z","updated":"2022-08-09T15:58:55.002Z","comments":true,"path":"Affine-background/","link":"","permalink":"https://ggorz10227216.github.io/Affine-background/","excerpt":"cover GBA除了能夠依照Map memory的排列，由左至右、由上到下的產生畫面外，還能夠使用矩陣運算，產生縮放&amp;旋轉過後的背景圖案，本文將會描述其原理，並且這部分的知識將與Affine object共通","text":"cover GBA除了能夠依照Map memory的排列，由左至右、由上到下的產生畫面外，還能夠使用矩陣運算，產生縮放&amp;旋轉過後的背景圖案，本文將會描述其原理，並且這部分的知識將與Affine object共通 仿射矩陣 根據維基百科的對仿射變換的定義: ::: success 仿射轉換（Affine transformation），又稱仿射映射，是指在幾何中，對一個向量空間進行一次線性轉換並接上一個平移，轉換為另一個向量空間。 ::: 言下之意，對於GBA的2D顯示來說，我們會需要一個矩陣來幫我們做這個轉換，這個矩陣會長得像是這樣，讓我們假設我們要逆時鐘旋轉然後X軸縮放倍，Y軸縮放倍，最後平移(x, y)，讓我們先來討論線性轉換的部分(旋轉與縮放) 這個矩陣其實就是由一個旋轉矩陣跟一個縮放矩陣組合而成 忘記怎麼計算矩陣了嗎? 請參考Matrix calculation rules 逆矩陣 酷，所以GBA的圖形硬體就是用上面的方式來實現旋轉縮放的囉? 很遺憾並不是，正確來說是完全相反 字面上意思的相反 我們剛剛所提及的方式，是將VRAM中的tile旋轉並縮放後，投射到螢幕上，但你仔細想想就會發現不太可行 我們可以思考一個問題，你放大之後，8*8的tile變成16*16，中間的插值是不是需要另外處理? 所以GBA的作法是將螢幕座標乘上仿射矩陣的逆矩陣，反著映射回VRAM，這下就保證每一個pixel都會有屬於它的data了 可想而知的，只要一轉下去，品質一定糟糕到受不了，不過GBA嘛......你也不能要求太多 因為上面的矩陣沒有平移(平移不是線性轉換)，所以可逆 實際上的渲染流程 我們的渲染流程並不難，先讓我們來看一下幾個重要的register 由於能支援仿射功能的圖層有兩個(BG2、BG3)，所以以下的register都會是兩組 1.BGX_L, BGX_H, BGY_L, BGY_H 用來定義texture space的起始點(Starting point)，因為格式不是integer而是fixed-point，因此長度會比較長，需要分兩塊來存 2.BGX_PA, BGX_PD, BGX_PC, BGX_PD 用來描述我們的仿設反矩陣 Starting point是Q8格式的fixed-point，即[0:7]是小數部分，[8:26]是整數部分，[27]是sign bit PA、PB、PC、PD是Q8格式的fixed-point，即[0:7]是小數部分，[8:14]是整數部分，[15]是sign bit 基本上運算規則如下 BG_X與BG_Y就是仿射矩陣的平移部份了 就是這麼的樸實無華 且枯燥，用圖來看會像是這樣 我們之前有提到過在Affine BG下，map data都是1 byte，在這個狀態下只要把跟 除8，就可以得到map data的address了 順帶附上fixed-point乘法的程式碼 12345678int q_mul(int32_t a, int16_t b) { int32_t temp; temp = (int32_t)a * (int32_t)b; // result type is operand's type // Rounding; mid values are rounded up temp += (temp &gt;&gt; 7) &amp; 1; return temp &gt;&gt; 8;}","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"}]},{"title":"GBA圖形處理邏輯模擬 - Object tile memory","slug":"obj-tile-memory","date":"2022-08-03T16:06:57.000Z","updated":"2022-08-03T16:07:30.708Z","comments":true,"path":"obj-tile-memory/","link":"","permalink":"https://ggorz10227216.github.io/obj-tile-memory/","excerpt":"cover 相較於BG tile的排列是依靠map data描述，obj tile並不存在map data，我們會直接透過character name來存取obj tile，但obj tile memory實際上有兩種不同的排列方式，本文將會分別說明這兩種方式的細節","text":"cover 相較於BG tile的排列是依靠map data描述，obj tile並不存在map data，我們會直接透過character name來存取obj tile，但obj tile memory實際上有兩種不同的排列方式，本文將會分別說明這兩種方式的細節 1 Dimensional 1 Dimensional，又稱線性排列，指的就是8*8的tile data是依照記憶體位置一直往後排列，如下圖所述: 1d_layout 此排列方法雖然擁有比較高的空間效率，但並不便於美術人員設計obj 2 Dimensional 2 Dimensional，我稱呼它為平面排列，在這個模式下8*8的tile會依照真實obj所要求的樣子排列，如下圖所述: 2d_layout 也就是說整個obj tile memory被分割成了0x20個tile per line 要注意的一點是，雖然tile是2d排列，但是tile data卻還是一樣是線性的，也就是說每個tile中的第一行與第二行之間的記憶體位置差是byte per tile line(0x4 or 0x8)，而非byte per tile line * 0x20","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"}]},{"title":"GBA圖形處理邏輯模擬 - Object Attribute Memory(OAM)","slug":"oam","date":"2022-08-03T16:00:15.000Z","updated":"2022-08-06T14:05:06.015Z","comments":true,"path":"oam/","link":"","permalink":"https://ggorz10227216.github.io/oam/","excerpt":"cover 相較於BG在渲染時會依照Map memory中的Map data進行渲染，Object在渲染時則是依照OAM中的資訊來進行，本文將會對OAM特性進行說明","text":"cover 相較於BG在渲染時會依照Map memory中的Map data進行渲染，Object在渲染時則是依照OAM中的資訊來進行，本文將會對OAM特性進行說明 OAM layout 我們的OAM位於0x0700'0000 ~ 0x0700'03ff，總共可以分成128塊，每一塊為6 bytes 每一個6 bytes的實體又分為三部分 Attribute 0 y-coordinate: 描述此obj位於螢幕上的y座標 Rotation/Scaling Flag: 用於標示此obj是否需要旋轉縮放 OBJ Mode: obj有三種模式可以選擇 00: 正常的描繪此obj 01: 此obj需要進行alpha blending，詳見GBA圖形處理邏輯模擬 - Graphics effect 10: OBJ window: 將此obj用於描述window的形狀，詳見GBA圖形處理邏輯模擬 - Graphics effect 11: 無實際作用 OBJ Mosaic: 對OBJ套用mosaic特效，詳見GBA圖形處理邏輯模擬 - Graphics effect Color mode: 與bg map上的相同欄位功能類似，決定此obj要以16色還是256色繪製，關於tile詳見GBA圖形處理邏輯模擬 - Tile format OBJ Shape: 標示此obj的形狀特徵，詳見後面描述 Attribute 1 x-coordinate: 描述此obj在螢幕上的x座標 Rotation/scaling parameter selection: 若此obj有啟用rotation/scaling功能，則可透過此field指定要使用的旋轉縮放矩陣，詳見下方說明 Horizontal/Vertical flip flag: 若此obj沒有啟用rotation/scaling功能，則可利用此flag標明需要水平/垂直相反繪製，需要注意的是這兩個flag剛好與Rotation/scaling parameter重疊 OBJ Size: 與OBJ shape配合，用於決定obj的size，見下表說明 Attribute 2 Character name: 如同map data，這裡個character name也是一個offset number，將其乘上0x20後即為此obj的tile data起始位置，要特別注意的是在DISPCNT(0x0400'0000)中的OBJ Character VRAM Mapping Format控制著obj tile在memory裡投排列的方式，詳見GBA圖形處理邏輯模擬 - Object tile memory OBJ Rotation/Scaling Parameters 就如同先前在講Affine background時候提到的，OBJ也可以透過仿射矩陣來做旋轉與縮放，矩陣位於OAM之中，但是排列方式比較特殊，我們來回顧一下這張圖 oam_layout 我們可以發現運算所需要的PA、PB、PC、PD以6 bytes為間隔，分散存放，而旋轉方法大致上與GBA圖形處理邏輯模擬 - Affine background說明的一樣，但有幾點需要注意: - OBJ的旋轉是以自身中心點作為旋轉的基準，而非左上角","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"}]},{"title":"Linear transformations","slug":"linear-transformations","date":"2022-08-03T15:52:00.000Z","updated":"2022-08-08T02:21:32.741Z","comments":true,"path":"linear-transformations/","link":"","permalink":"https://ggorz10227216.github.io/linear-transformations/","excerpt":"image alt 有關於線性轉換的一些筆記，放在這裡以備不時之需","text":"image alt 有關於線性轉換的一些筆記，放在這裡以備不時之需 A transformation : maps in to in T is a linear transformation if Some linear transformation example: Rotation in Reflection in Some instresting transformation(but not linear!) Translation Length Question: Is any a linear transformation? Let's check it by definition We know $T(cv) = A(cv) = cA(v) = cT(v) The answer is: Yes Composition of two trasformations: It's possible to combine multiple linear transformation to one. If and are linear，their combination is also linear. Combination order matters， not always equal to Language of transformations is a transformation : domain, : codomain : the image of v kernel of = the set of in that Range of = = the set of all images If is a linear transformation We'll try to prove that by linear transformation's definition is a subspace of if , then if , then is a subspace of if , , then if , then = range of , Rank of = Nullify of = One to one The linear transformation is one to one if for any Onto A linear transformation is onto if Isomorphism(同形) A one-to-one linear transformation is onto is an isomorphism Linear trans. V.S. Matrix calculation Suppose , is = the set of 's that = Nullspace of = = the set of all images = column space of = == == Recall Rank theorem is one-to-one = = is full column rank(only one solution) T is onto = = = is full row rank(has solution) T is isomorphism A is full rank Coordinate systems and general vector spaces Recall unique representation theorem there exists one and only one way to express any in as a linear combination of Coordinate vecotr in the basis : Let's suppose a basis ，then we want to map a vecotr (which is within ) to ，and and are isomorphism We can achive that by: General vector spaces(optional) With defined vector addition and scalar multiplication exist a unique 0 satisfied for any , there exists , Matrices of linear transformations graph Suppose we have a vector in space Let's say is our input vector is space 's basis is the Input coordinate vector i.e. Then, is the basis of is our output vector i.e. One question is: Is there exist a matirx Satisfied ? (The red path in our figure) 我們可以回想一下定義 Input vector 把係數提出來就是, 所以 則Output vector 不要忘記線性轉換的基本定義! 而我們稱呼原本在基底空間中的座標向量為 為中的基底向量, 為中的係數 因此 我們可以思考一下，空間的基底向量經過轉換成中的向量後，一定可以被空間的基底組合出來 組合所使用的係數就可以說它是A矩陣的第一列(col)，把每一列係數放到一個矩陣裡，就是A矩陣! 所以結論就是: 所以圖表中的紅色路線的確存在!","categories":[],"tags":[{"name":"linear Algebra","slug":"linear-Algebra","permalink":"https://ggorz10227216.github.io/tags/linear-Algebra/"},{"name":"math","slug":"math","permalink":"https://ggorz10227216.github.io/tags/math/"}]},{"title":"Matrix calculation rules","slug":"basic-matrix-rule","date":"2022-08-03T13:21:09.000Z","updated":"2022-08-03T15:24:51.807Z","comments":true,"path":"basic-matrix-rule/","link":"","permalink":"https://ggorz10227216.github.io/basic-matrix-rule/","excerpt":"image alt The algebra of matrix follows some rules for addition and multiplication. Let us consider A, B and C are three different square matrices. A’ is the transpose and A-1 is the inverse of A. I is the identity matrix and c is a real number.","text":"image alt The algebra of matrix follows some rules for addition and multiplication. Let us consider A, B and C are three different square matrices. A’ is the transpose and A-1 is the inverse of A. I is the identity matrix and c is a real number. 神偷小吉從網路上偷來的線性代數小抄 Now as per the rules of laws of matrices: Also, see here rules for transposition of matrices: The inverse rules of matrices are as follows: prove:","categories":[],"tags":[{"name":"linear Algebra","slug":"linear-Algebra","permalink":"https://ggorz10227216.github.io/tags/linear-Algebra/"},{"name":"math","slug":"math","permalink":"https://ggorz10227216.github.io/tags/math/"}]},{"title":"Vector space","slug":"vector-space","date":"2022-08-03T09:27:02.000Z","updated":"2022-08-03T15:50:27.937Z","comments":true,"path":"vector-space/","link":"","permalink":"https://ggorz10227216.github.io/vector-space/","excerpt":"image alt 有關於向量空間的一些筆記，放在這裡以備不時之需","text":"image alt 有關於向量空間的一些筆記，放在這裡以備不時之需 Vector space &amp; subspaces = The set of all n-dimensional vectors. A subspace in the vector space must satisfies: If , in , is in If is in , is in = The set all combinations of &amp; Does equal to ? 我們可以試著證明看看是否還滿足封閉性 Column space &amp; Null space A is a matrix There are two important subspaces of A: Column space which is in any in Null space which is in We said that is solvable if and only if b can be expressed as combination of columns of A 換句話說，b要落在(的column space)中 就是vectors in Nullspace of () The set of all solutions to We know that is a subspace because: Let's suppose , are two vector in , that is has infinite solutions iff in other words, has exactly one sol. if Are all (which b is not zero)'s solution a subspace? NO If the solution set of has not path through the origin, that means we can combine two solutions of , then generate a new vector which is not in the solution set of Reduced row echelon form Is there a systematic way that can help us to find ? Yes. Suppose: Reduce A by Gauss Elimination，then get the (upper triangular form) matirx We notice that and are 1，which are pivot variables Let's analyse by formula's perspective: Let's say and are free variables , So the pivot variable are: , Finally, we can get the Complete solution Let's say that Complete solution is linear combination of Special solution, which is: = span of columns of Number of special sol. = number of free variable We know how to find N(A) now, but can we do it faster? Reduce row Echelon form Recall matrix, we'll keep reduce it by Jordan Elimination, finally get the matrix: Follow the step below to get N from R: we know the free variables are and , so fill the N like this(put the matrix into row 2 and row 4 of ): 2.Multiply remaining elements in by -1, then put them in N = #pivot of A #free variable = n - General solutions Suppose Ax = b, let's say x is General solution, which means: means complete homogeneous solution to is solution to which all free variables are 0 So, 這就代表只要存在，就一定會有解 如果存在，則有機會無限多解 如何檢驗? r = n r &lt; n r = m 1. 3. r &lt; m 2. 4. 的維度與相同，且也與未知數個數相同(無free variable) 唯一解， 的維度小於，且沒有free variable Full column rank 無解或者唯一解 的維度與相同，有free variable Full row rank 不僅存在，連也存在 無限多解 的維度小於，有free variable 無解或者無限多解 Independence, basis and dimension v1, v2, ..., vn are independent if only the trivial combination gives zero vector. otherwise, they are dependent. How to find the independent vectors in a span? Reduce the matrix to ，the column vector which has pivot is independent vector. We can also say that, a matrix is linear independet if full column rank A basis of a subspace is a set of vecotr v1, ..., vn are independent Dimension dim V = number of basis vecotrs in V conclusion The columns of are independent () rank = n(no free variable) 也就是說A中的向量剛剛好就是basis中的向量 , , , Column space Notation is In space The set of all combination of columns of Null space Notation is In space The set of solutions to Row space Notation is In space The set of all combination of rows of Left Nullspace Notation is In space The set of solutions of The reason why we call it \"Left\": , , 乘在A的左邊，使其為零，因此得名 Finding basis of these four space The basis of Pivot cols of The basis of Columns of the nullspace matrix = # free variables = The basis of Pivot rows of Notice that but The basis of There is a matrix call that can reduce to Rows of generating zero rows in are basis of 上述的內容即為The rank theory The invertible theorem is matrix(square) columns of form basis of columns of are independent 1, 2指的是沒有free variable，自然是唯一解 或從空間的角度來看，只要能夠在n為空間中提供n個pivot，那麼組成任意向量即可行 這一點與3,4,5,6,7說的是一樣的事情 應該說是，這7點其實都在講差不多的事情","categories":[],"tags":[{"name":"linear Algebra","slug":"linear-Algebra","permalink":"https://ggorz10227216.github.io/tags/linear-Algebra/"},{"name":"math","slug":"math","permalink":"https://ggorz10227216.github.io/tags/math/"}]},{"title":"GBA圖形處理邏輯模擬 (一)","slug":"GBA圖形處理邏輯模擬-一","date":"2022-07-21T16:13:05.000Z","updated":"2022-07-21T16:28:53.352Z","comments":true,"path":"GBA圖形處理邏輯模擬-一/","link":"","permalink":"https://ggorz10227216.github.io/GBA%E5%9C%96%E5%BD%A2%E8%99%95%E7%90%86%E9%82%8F%E8%BC%AF%E6%A8%A1%E6%93%AC-%E4%B8%80/","excerpt":"cover GBA模擬器的開發之路，如果說CPU部分是思考\"我到底該怎麼做才對\"，那圖形的部分就會是\"我到底要怎麼做才會快\" 本系列文將會把重點聚焦在如何正確的實作一個GBA的圖形系統模擬函式庫，並提出一些手法來提升模擬的效率","text":"cover GBA模擬器的開發之路，如果說CPU部分是思考\"我到底該怎麼做才對\"，那圖形的部分就會是\"我到底要怎麼做才會快\" 本系列文將會把重點聚焦在如何正確的實作一個GBA的圖形系統模擬函式庫，並提出一些手法來提升模擬的效率 GBA圖形系統規格 相較於近代的主機都普遍配有GPU來負責圖形渲染工作，GBA也有一塊獨立於CPU的處理邏輯負責圖形工作，也就是PPU(Pixel Processing Unit) 我們可以先來看一下PPU主要提供那些圖形處理功能: 1. 輸出畫面為240*160 pixels 2. 色彩格式為RGB555 3. 具有以下兩種渲染模式: - Tile based: 基於利用尺寸為8*8的tile組合畫面，具有渲染速度快，還可以利用硬體仿射變換功能 - Bitmap based: 直接由CPU將圖形資料以Pixel為單位寫入VRAM，自由度較高但效率差，須妥善利用DMA來實作 4. 最大支援128個Sprites於螢幕上顯示 5. 支援數種圖形特效: - Rotation/Scaling - alpha blending - fade-in/out - mosaic - window 記憶體區段 PPU的工作記憶體位於0x0500'0000~0x07ff'ffff，不同的段落具有不同的用途，描述如下: memory map Palette memory: 0x0500'0000 ~ 0x0500'03ff 功用為調色盤，一分為二，前半段為背景專用，後半段為OBJ使用 各具有256色，皆為RGB555格式 Bus為16 bit Video RAM(VRAM): 0x0600'0000 ~ 0x0601'7fff 圖形系統的主記憶體，內容會根據繪圖模式有所不同，後面會詳述 Bus為16 bit OBJ Attributes(OAM): 0x0700'0000 ~ 0x0700'03ff 用於描述各Sprite的屬性，以及Sprite在作仿射變換時所使用的矩陣內容 Bus為32 bit 聰明的小吉們應該有注意到一件事，我們在上面提到的address為0x0500'0000~0x07ff'ffff 但是下面再說明功能的時候，描述的範圍只有一部分，那剩下沒有涵蓋到(途中的黑色部分)的部分到底有沒有用??? 這裡就必須要提及GBA系統的Undefined behavior，其中的Memory mirror章節有提到GBA硬體的Bus在面對這些奇怪的R/W時會有那些行為 具體模擬的細節我會在MMU相關的文章內作說明 開發環境 我們的目標是要設計一個負責繪製GBA遊戲畫面的library，而非完全地將邏輯內嵌至模擬器主程式內，所以為了讓我們可以在沒有模擬除了PPU以外的功能的狀態下也能夠對PPU進行debug，我們勢必要開發一個前端，去調用PPU library所開出的介面來產生畫面 重點來了，阿你就沒有模擬整個系統，PPU怎麼會知道要繪製什麼東西??? pic 而問題的答案也很簡單，找另外一個模擬器，直接去dump他的memory再寫進我們的PPU memory即可 有一個除錯器NO$GBA可以幫我們做到這件事情，我們在後續的開發流程也會持續的使用這個工具來協助我們釐清問題 模擬流程 上面的說明中我有特別提到PPU在GBA系統中扮演的角色類似於我們現代電腦系統的GPU，但是其工作原理其實與GPU差異很大 現在的GPU基本上擅長一次處理大量的頂點或貼圖資料，但GBA的繪製流程是以scanline為單位，一條一條畫，同時繪圖狀態會根據H-Blank與V-Blank作變化 因此，我們並不會直接就利用GPU來繪製我們模擬器的遊戲畫面，而是先行使用CPU在main memory上產生出pixel format為RGB555的frame buffer後，緊接著一次做完整個畫面的RGB555 to RGBA8888的轉換，最後一步才是透過ImGUI把buffer的內容轉成texture，交由GPU渲染。","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"}]},{"title":"GBA的軟體中斷與其相對應的處理","slug":"hardirq","date":"2022-07-19T10:35:23.000Z","updated":"2022-07-21T16:17:12.347Z","comments":true,"path":"hardirq/","link":"","permalink":"https://ggorz10227216.github.io/hardirq/","excerpt":"cover GBA所使用的CPU ARM7TDMI要觸發中斷基本上有硬體中斷與軟體中斷兩種手段，兩種中斷的運作機制部份相似但在關鍵部份還是有所差異，若要正確模擬GBA的中斷就必須要將這兩種中斷的運作機制都搞清楚才行 換句話說，關於GBA的中斷沒有打模糊仗的空間，該讀的Spec就是要讀，該想的問題就是要想 本文會先就軟體中斷的部份作解說，硬體中斷會在另外一篇文章作描述","text":"cover GBA所使用的CPU ARM7TDMI要觸發中斷基本上有硬體中斷與軟體中斷兩種手段，兩種中斷的運作機制部份相似但在關鍵部份還是有所差異，若要正確模擬GBA的中斷就必須要將這兩種中斷的運作機制都搞清楚才行 換句話說，關於GBA的中斷沒有打模糊仗的空間，該讀的Spec就是要讀，該想的問題就是要想 本文會先就軟體中斷的部份作解說，硬體中斷會在另外一篇文章作描述 軟體中斷(SWI) 軟體中斷，顧名思義就是透過軟體觸發的中斷，更精確的說法是透過SWI指令所造成的一連串CPU Mode切換與Program Counter(PC)跳轉，大致上可以分解為以下數個步驟： 1. 切換CPU Operating mode到Supervisor(SVC)下，並將目前mode的CPSR保存到SPSR_svc，在這一步之後所有被操作的暫存器皆為svc專屬的bank(從datasheet的角度來講就是 **_svc結尾的register** ) 2. 將中斷結束後需要被執行的下一條指令(也就是PC - instructionLength)放入R14_svc(LR) 3. 無論目前的CPU mode為何，一律切換CPU mode到ARM mode 4. 將PC指定為中斷向量中軟體中斷的記憶體位置，依照慣例為0x08，緊接著重新填充管線 5. 為了防止執行軟體中斷的同時硬體中斷也被觸發，CPSR I bit(IRQ disable bit)也會在指令的最後被set 大致上SWI的工作流程我們可以從cycle table來看出個大概： Xn指的就是中斷向量的位置，值得一提的是即便最終管線有被重新填充，在指令的一開始我們還是有做instruction fetch，為了不要算錯cpu cycle，我們還是要針對PC + 2L所在的記憶體區段計算正確的N Cycle加到模擬器的cycle counter上 對了，後面會提的硬體中斷(IRQ)基本上也是類似的套路，直接將邏輯抽出來變成一個function是一個不錯的選擇 軟體中斷的跳轉與實際運作 講完了軟體中斷的進入，接下來是中間運作的機制: 1. 在CPU跳轉到0x08之後會看到一個branch指令，這次跳轉才會跳到BIOS中負責決定該去那一個handler的handler上(依照官方BIOS的設計，位置在0x140） 2. 透過讀取lr的方式取得剛剛很可憐，被CPU當成塑膠的comment field，並透過位於0x1c8的swi_handler_table作跳轉 3. 最後透過bx r12進入正確的handler 要注意的一點是，以上只是針對任天堂官方BIOS做了一個粗略的解釋，我省略了不少內容，因為這一個部份的邏輯只要指令實作正確，基本上模擬器層不需要多加擔心，不過我強烈建議一定要去看一下這一部份的反組譯 軟體中斷的結束與狀態恢復 最後當中斷結束時，我們必須要還原到中斷前的狀態: 1. GBA BIOS在執行軟體中斷時，會切換到system mode下(SVC-&gt;SYS)，在中斷結束時會切換回SVC 2. 切換回SVC bank之後，從stack上取得中斷前的CPSR,放入SPSR 3. 最後使用movs將LR寫回PC，mov指令當S bit set且dst為PC時會順帶將SPSR寫回CPSR，因此系統將會回復到中斷前的狀態，並重新填充管線 我們可以發現GBA BIOS的確有遵照著ARM7TDMI Datasheet回復中斷前的狀態(見SWI Return Instruction一欄) 小結 中斷處理一直以來在模擬器實作上都是一個棘手的問題，因為其牽涉到CPU本身的指令實做與記憶體存取功能兩者是否正確(換言之，今天有bug發生你不太好釐清是誰有錯) 當CPU與週邊裝置開始連動時(LCD Joypad audio.....)問題會變得更加複雜，因此強烈建議要做好測試，方便你後續釐清問題","categories":[],"tags":[{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"ARM","slug":"ARM","permalink":"https://ggorz10227216.github.io/tags/ARM/"},{"name":"system programming","slug":"system-programming","permalink":"https://ggorz10227216.github.io/tags/system-programming/"}]}],"categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://ggorz10227216.github.io/tags/c/"},{"name":"cpp weekly note","slug":"cpp-weekly-note","permalink":"https://ggorz10227216.github.io/tags/cpp-weekly-note/"},{"name":"polymorphic_allocator","slug":"polymorphic-allocator","permalink":"https://ggorz10227216.github.io/tags/polymorphic-allocator/"},{"name":"C++","slug":"C","permalink":"https://ggorz10227216.github.io/tags/C/"},{"name":"CTAD","slug":"CTAD","permalink":"https://ggorz10227216.github.io/tags/CTAD/"},{"name":"Variadic template","slug":"Variadic-template","permalink":"https://ggorz10227216.github.io/tags/Variadic-template/"},{"name":"cpp_weekly_note","slug":"cpp-weekly-note","permalink":"https://ggorz10227216.github.io/tags/cpp-weekly-note/"},{"name":"linear Algebra","slug":"linear-Algebra","permalink":"https://ggorz10227216.github.io/tags/linear-Algebra/"},{"name":"math","slug":"math","permalink":"https://ggorz10227216.github.io/tags/math/"},{"name":"networking","slug":"networking","permalink":"https://ggorz10227216.github.io/tags/networking/"},{"name":"Boost","slug":"Boost","permalink":"https://ggorz10227216.github.io/tags/Boost/"},{"name":"asynchronous_IO","slug":"asynchronous-IO","permalink":"https://ggorz10227216.github.io/tags/asynchronous-IO/"},{"name":"GBA","slug":"GBA","permalink":"https://ggorz10227216.github.io/tags/GBA/"},{"name":"emulator","slug":"emulator","permalink":"https://ggorz10227216.github.io/tags/emulator/"},{"name":"graphics","slug":"graphics","permalink":"https://ggorz10227216.github.io/tags/graphics/"},{"name":"ARM","slug":"ARM","permalink":"https://ggorz10227216.github.io/tags/ARM/"},{"name":"system programming","slug":"system-programming","permalink":"https://ggorz10227216.github.io/tags/system-programming/"}]}